<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux查看端口使用情况]]></title>
    <url>%2F2018%2F09%2F20%2FLinux%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[Linux 查看监听端口 netstatnetstat命令常用参数说明（有事没事man netstat查看完整参数）123456789-n：直接使用ip地址，而不通过域名服务器 -l：仅显示监控中的服务器的Socket -p：显示进程PID和进程名称 -t：显示TCP端口 -u：显示UDP端口 常用命令配合grep可以很方便查看当前服务器上监听的端口，方便查询服务是否正常启动1netstat -npl | grep 5001 查看5001端口使用情况 1netstat -nplt 查看所所有TCP协议端口使用情况]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>netstat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter分布式环境搭建]]></title>
    <url>%2F2018%2F09%2F17%2FJmeter%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Jmeter分布式环境搭建 本地机器配置限制，并发线程数达不到性能要求时候，就要考虑搭建jmeter分布式环境来进行压测 原理1、Jmeter分布式测试时，选择其中一台作为调度机(master)，其它机器做为执行机(slave)。 2、执行时，master会把脚本发送到每台slave上，slave 拿到脚本后就开始执行，slave执行时不需要启动GUI，我理解它应该是通过命令行模式执行的。 3、执行完成后，slave会把结果回传给master，master会收集所有slave的信息并汇总。 示例有三台机器，ip分别为：192.168.3.1,192.168.3.2,192.168.3.3；其中192.168.3.3作为调度机，启动GUI界面 执行机（slave）配置前提条件是执行机所在服务器已经搭建好jmeter执行环境，并且有安装jmeter（建议执行机和调度机jmeter版本完全一致，省的麻烦）进行执行机中（192.168.3.1,192.168.3.2）jmeter安装目录1，编辑jmeter.properties，找到server_port=1099，以及server.rmi.localport=1099修改端口；该端口就是启动jmeter-server.bat之后，控制台显示的端口，也是调度机调度的端口 2，启动jmeter-server.bat，控制台打印信息类似：12Created remote object: UnicastServerRef2 [liveRef: [endpoint:[192.168.3.1:1099]local),objID:[1bfcefd1:165e6dc02e3:-7fff, 2154557740781192439]]] 调度机（master）配置1，找到bin目录下的jmeter.properties，修改配置：1remote_hosts=192.168.3.1:1099,192.168.3.2:1099 保存退出2，启动GUI（jmeter.bat），打开测试脚本，点击菜单栏的运行，选择远程启动全部（或者指定某台执行机） 备注1，如果进行了参数化，需要在执行机上和调度机一模一样的路径放置参数化文件 2，启动执行机时候如果有报错：rmi-keystore.jks（系统找不到指定文件）解决办法：编辑jmeter.properties，修改参数：server.rmi.ssl.disable=true即可]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql开启全SQL执行记录]]></title>
    <url>%2F2018%2F09%2F13%2FMysql%E5%BC%80%E5%90%AF%E5%85%A8SQL%E6%89%A7%E8%A1%8C%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[MySQL记录全执行SQL语句 遇到性能问题时候，排查到数据库部分，一般都是看慢sql，但是有的时候慢sql也看不出什么东西，这个时候，如果可以有办法记录所有执行的sql，那排查起来可以更方便点。 开启日志查询功能1SHOW VARIABLES LIKE &apos;general%&apos;; 返回结果：1234567+------------------+----------------------------------------------+| Variable_name | Value |+------------------+----------------------------------------------+| general_log | OFF || general_log_file | /data/mysql_data/izuf65tvx7it01x88bzbp4z.log |+------------------+----------------------------------------------+2 rows in set (0.00 sec) 可以看出，当前是关闭状态，开启即可：1set GLOBAL general_log=&apos;ON&apos;; 再查一下：1SHOW VARIABLES LIKE &apos;general%&apos;; 返回结果：1234567+------------------+----------------------------------------------+| Variable_name | Value |+------------------+----------------------------------------------+| general_log | ON || general_log_file | /data/mysql_data/izuf65tvx7it01x88bzbp4z.log |+------------------+----------------------------------------------+2 rows in set (0.00 sec) 搞定，这下，调接口之后就会有完成的sql看了。 binlog嗯，这个方式，怎么说呢，自己level太低，不是很看得懂里面记录的，不过binlog文件里记录的的确是全部的sql，最全。binlog使用mysqlbinlog工具来查看。查看binlog状态：1show variables like &quot;%log_bin%&quot;; 返回结果：1234567891011+---------------------------------+----------------------------------+| Variable_name | Value |+---------------------------------+----------------------------------+| log_bin | ON || log_bin_basename | /data/mysql_data/mysql-bin || log_bin_index | /data/mysql_data/mysql-bin.index || log_bin_trust_function_creators | ON || log_bin_use_v1_row_events | OFF || sql_log_bin | ON |+---------------------------------+----------------------------------+6 rows in set (0.00 sec) 就能看见binlog状态以及保存路径了]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter+Ant+Jenkins接口自动化搭建]]></title>
    <url>%2F2018%2F09%2F12%2FJmeter-Ant-Jenkins%E6%8E%A5%E5%8F%A3%E8%87%AA%E5%8A%A8%E5%8C%96%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Jenkins+Ant+Jmeter接口自动化实践 虽然之前就搭过了，也用word写过手册，blog因为不放图片就一直没更新，想想还是稍微记录点简单的过程，方便自己以后想起来。 这边记录的只有Ant+Jmeter，jenkins部分，还是有图比较直观，就不写了，不过那部分也很简单。 环境搭建环境不限，linux，Windows都可以 需要工具ant–下载地址：http://ant.apache.org/bindownload.cgijmeter–下载地址：http://jmeter.apache.org/download_jmeter.cgijenkins–下载地址：https://jenkins.io/jdk—下载地址http://www.oracle.com/technetwork/java/javase/downloads/index.html 工具安装1， Jenkins也就解压缩，tomcat或者jar启动2， Jdk安装，配环境变量（JAVA_HOME,path,classpath）(验证：java –version/javac)3， Ant配环境变量（ANT_HOME,path,classpath）(验证：ant –version/ant) Jmeter+Ant首先是扩展包将jmeter\extras下ant-jmeter-1.1.1.jar的jar包拷到ant的lib目录下 配置Ant本地创建接口自动化项目保存路径，例如：E:\InterfaceAutoTestCode\Quartz进入路径目录，手工创建build.xml(ant按照build.xml文件内容执行)build.xml文件内容:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project name=&quot;ant-jmeter-test&quot; default=&quot;run&quot; basedir=&quot;.&quot;&gt; &lt;tstamp&gt; &lt;format property=&quot;time&quot; pattern=&quot;yyyyMMddhhmm&quot; /&gt; &lt;/tstamp&gt; &lt;!-- 需要改成自己本地的 Jmeter 目录--&gt; &lt;property name=&quot;jmeter.home&quot; value=&quot;D:\QA\apache-jmeter-4.0&quot; /&gt; &lt;property name=&quot;report.title&quot; value=&quot;接口测试&quot;/&gt; &lt;!-- jmeter生成jtl格式的结果报告的路径--&gt; &lt;property name=&quot;jmeter.result.jtl.dir&quot; value=&quot;E:\InterfaceAutoTestCode\Quartz\report\jtl&quot; /&gt; &lt;!-- jmeter生成html格式的结果报告的路径--&gt; &lt;property name=&quot;jmeter.result.html.dir&quot; value=&quot;E:\InterfaceAutoTestCode\Quartz\report\html&quot; /&gt; &lt;!--详细报告--&gt; &lt;property name=&quot;detail&quot; value=&quot;_detail&quot; /&gt; &lt;!-- 生成的报告的前缀--&gt; &lt;property name=&quot;ReportName&quot; value=&quot;SmokeReport&quot; /&gt; &lt;property name=&quot;jmeter.result.jtlName&quot; value=&quot;$&#123;jmeter.result.jtl.dir&#125;/$&#123;ReportName&#125;$&#123;time&#125;.jtl&quot; /&gt; &lt;property name=&quot;jmeter.result.htmlName&quot; value=&quot;$&#123;jmeter.result.html.dir&#125;/$&#123;ReportName&#125;$&#123;time&#125;.html&quot; /&gt; &lt;property name=&quot;jmeter.result.jtlNamedetail&quot; value=&quot;$&#123;jmeter.result.jtl.dir&#125;/$&#123;ReportName&#125;$&#123;time&#125;.jtl&quot; /&gt; &lt;property name=&quot;jmeter.result.htmlNamedetail&quot; value=&quot;$&#123;jmeter.result.html.dir&#125;/$&#123;ReportName&#125;$&#123;time&#125;$&#123;detail&#125;.html&quot; /&gt; &lt;target name=&quot;run&quot;&gt; &lt;antcall target=&quot;test&quot; /&gt; &lt;antcall target=&quot;report&quot; /&gt; &lt;/target&gt; &lt;target name=&quot;test&quot;&gt; &lt;taskdef name=&quot;jmeter&quot; classname=&quot;org.programmerplanet.ant.taskdefs.jmeter.JMeterTask&quot; /&gt; &lt;jmeter jmeterhome=&quot;$&#123;jmeter.home&#125;&quot; resultlog=&quot;$&#123;jmeter.result.jtlName&#125;&quot;&gt; &lt;!-- 声明要运行的脚本。&quot;*.jmx&quot;指包含此目录下的所有jmeter脚本--&gt; &lt;testplans dir=&quot;E:\InterfaceAutoTestCode\Quartz&quot; includes=&quot;*.jmx&quot; /&gt; &lt;property name=&quot;jmeter.save.saveservice.output_format&quot; value=&quot;xml&quot;/&gt; &lt;/jmeter&gt; &lt;/target&gt; &lt;path id=&quot;xslt.classpath&quot;&gt; &lt;fileset dir=&quot;$&#123;jmeter.home&#125;/lib&quot; includes=&quot;xalan*.jar&quot;/&gt; &lt;fileset dir=&quot;$&#123;jmeter.home&#125;/lib&quot; includes=&quot;serializer*.jar&quot;/&gt; &lt;/path&gt; &lt;target name=&quot;report&quot;&gt; &lt;tstamp&gt; &lt;format property=&quot;report.datestamp&quot; pattern=&quot;yyyy/MM/dd HH:mm&quot; /&gt;&lt;/tstamp&gt; &lt;xslt classpathref=&quot;xslt.classpath&quot; force=&quot;true&quot; in=&quot;$&#123;jmeter.result.jtlName&#125;&quot; out=&quot;$&#123;jmeter.result.htmlName&#125;&quot; style=&quot;$&#123;jmeter.home&#125;/extras/jmeter-results-detail-report_21.xsl&quot;&gt; &lt;param name=&quot;dateReport&quot; expression=&quot;$&#123;report.datestamp&#125;&quot;/&gt; &lt;/xslt&gt; &lt;xslt classpathref=&quot;xslt.classpath&quot; force=&quot;true&quot; in=&quot;$&#123;jmeter.result.jtlNamedetail&#125;&quot; out=&quot;$&#123;jmeter.result.htmlNamedetail&#125;&quot; style=&quot;$&#123;jmeter.home&#125;/extras/jmeter-results-shanhe-me.xsl&quot;&gt; &lt;param name=&quot;dateReport&quot; expression=&quot;$&#123;report.datestamp&#125;&quot;/&gt; &lt;/xslt&gt; &lt;!-- 因为上面生成报告的时候，不会将相关的图片也一起拷贝至目标目录，所以，需要手动拷贝 --&gt; &lt;copy todir=&quot;$&#123;jmeter.result.html.dir&#125;&quot;&gt; &lt;fileset dir=&quot;$&#123;jmeter.home&#125;/extras&quot;&gt; &lt;include name=&quot;collapse.png&quot; /&gt; &lt;include name=&quot;expand.png&quot; /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/target&gt;&lt;/project&gt; 将需要运行的jmeter脚本，拷到该目录下，cmd，进入该目录，执行ant即可 更详细教程]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
        <tag>Ant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】Linux性能监控与分析]]></title>
    <url>%2F2018%2F08%2F29%2F%E3%80%90%E8%BD%AC%E3%80%91Linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Linux性能监控与分析 Linux服务器性能查看CPU性能查看查看物理CPU个数：1cat /proc/cpuinfo |grep &quot;physical id&quot;|sort|uniq|wc -l 查看每个物理CPU中的core个数：1cat /proc/cpuinfo |grep &quot;cpu cores&quot;|wc -l 逻辑CPU个数1cat /proc/cpuinfo |grep &quot;processor&quot;|wc -l 物理cpu个数*核数=逻辑cpu个数（不支持超线程技术的情况下） 内存查看查看内存使用情况12345678910111213141516171819#free -m total used free shared buffers cachedMem: 3949 2519 1430 0 189 1619-/+ buffers/cache: 710 3239Swap: 3576 0 3576total：内存总数used：已经使用的内存数free：空闲内存数shared：多个进程共享的内存总额- buffers/cache：(已用)的内存数，即used-buffers-cached+ buffers/cache：(可用)的内存数，即free+buffers+cachedBuffer Cache用于针对磁盘块的读写；Page Cache用于针对文件inode的读写，这些Cache能有效地缩短I/O系统调用的时间。对操作系统来说free/used是系统可用/占用的内存；对应用程序来说-/+ buffers/cache是可用/占用内存,因为buffers/cache很快就会被使用。 硬盘查看查看硬盘及分区信息1fdisk -l 查看文件系统的磁盘空间占用情况：1df -h 查看硬盘的I/O性能（每隔一秒显示一次，显示五次）1iostat -x 1 5 iostat是含在套装systat中的,可以用yum -y install systat来安装常关注的参数：12如%util接近100%,说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如idle小于70%，I/O的压力就比较大了，说明读取进程中有较多的wait。 查看linux下某目录的大小1du -sh 目录 如发现某个分区空间接近用完，可以进入该分区的挂载点，用以下命令找出占用空间最多的文件或目录，然后按照从达到小的顺序，找出系统中占用最多空间的前10个文件或目录：1du -cksh *|sort -rn|head -n 10 查看平均负载有时候系统响应很慢，又找不到原因，这是就要查看平均负载，看它是否有大量的进程在排队等待最简单的命令：1uptime--查看过去的1分钟、5分钟和15分钟内进程队列中的平均进程数量。 还有动态命令top我们只关心以下部分：12345top - 21:33:09 up 1:00, 1 user, load average: 0.00, 0.01, 0.05如果每个逻辑cpu当前的活动进程不大于3，则系统性能良好；如果每个逻辑cpu当前的活动进程不大于4，表示可以接受；如果每个逻辑cpu当前的活动进程大于5，则系统性能问题严重。 一般计算方法：负载值/逻辑CPU个数还可以结合vmstat命令来判断是否繁忙，其中：123456789101112131415161718192021222324252627procsr：等待运行的进程数。b：处在非中断睡眠状态的进程数。w：被交换出去的可运行的进程数。memeoryswpd：虚拟内存使用情况，单位为KB。free：空闲的内存，单位为KB。buff：被用来作为缓存的内存数，单位为KB。swapsi：从磁盘交换到内存的交换页数量，单位为KB。so：从内存交换到磁盘的交换页数量，单位为KB。iobi：发送到块设备的块数，单位为KB。bo：从块设备接受的块数，单位为KB。systemin：每秒的中断数，包括时钟中断。cs：每秒的环境切换次数。cpu按cpu的总使用百分比来显示。us：cpu使用时间。sy：cpu系统使用时间。id：闲置时间。 其他参数1234567891011121314151617查看内核版本号：uname -a简化命令：uname -r查看系统是32位还是64位的：file /sbin/init查看发行版：cat /etc/issue或lsb_release -a查看系统已载入的相关模块：lsmod查看pci设置：lspci Linux 服务器性能评估影响Linux服务器性能的因素操作系统1234CPU内存磁盘I/O带宽网络I/O带宽 程序应用级系统性能评估标准 影响性能因素 好 坏 糟糕 CPU user% + sys%&lt; 70% user% + sys%= 85% user% + sys% &gt;=90% 内存 Swap In（si）＝0 Swap Out（so）＝0 Per CPU with 10 page/s More Swap In &amp; Swap Out 磁盘 iowait % &lt; 20% iowait % =35% iowait % &gt;= 50% 其中：12345%user：表示CPU处在用户模式下的时间百分比。%sys：表示CPU处在系统模式下的时间百分比。%iowait：表示CPU等待输入输出完成时间的百分比。swap in：即si，表示虚拟内存的页导入，即从SWAP DISK交换到RAMswap out：即so，表示虚拟内存的页导出，即从RAM交换到SWAP DISK 系统性能分析工具常用系统命令：vmstat,sar,iostat,netstat,free,top常用组合方式：1234vmstat、sar、iostat检测是否是CPU瓶颈free、vmstat检测是否是内存瓶颈iostat检测是否是磁盘I/O瓶颈netstat检测是否是网络带宽瓶颈 Linux性能评估与优化系统整体性能评估（uptime命令）uptime116:38:00 up 118 days, 3:01, 5 users,load average: 1.22, 1.02, 0.91 注意： load average三值大小一般不能大于系统CPU的个数。 1系统有8个CPU,如load average三值长期大于8，说明CPU很繁忙，负载很高，可能会影响系统性能。 但偶尔大于8，一般不会影响系统性能。 如load average输出值小于CPU个数，则表示CPU有空闲时间片，比如本例中的输出，CPU是非常空闲的 CPU性能评估vmstat监控CPU显示系统各资源之间相关性能简要信息，主要看CPU负载情况下面是vmstat输出结果：123456[root@izuf6b0a7e5agj4lm7aj3mz ~]# vmstat 2 3procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 3 0 0 12267888 166640 1863724 0 0 1 41 72 88 3 1 96 0 0 2 0 0 12267872 166640 1863724 0 0 0 0 66000 163918 15 17 68 0 0 2 0 0 12267872 166640 1863724 0 0 0 158 18689 43630 40 5 55 0 0 r–运行和等待cpu时间片的进程数，这个值如果长期大于系统CPU的个数，说明CPU不足，需要增加CPUb–在等待资源的进程数，比如正在等待I/O、或者内存交换等。CPUus用户进程消耗的CPU时间百分比us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，就需要考虑优化程序或算法。 sy内核进程消耗的CPU时间百分比，Sy的值较高时，说明内核消耗的CPU资源很多根据经验，us+sy的参考值为80%，如果大于80%可能存在CPU资源不足。 sar命令监控系统CPUsar对系统每个方面进行单独统计，但会增加系统开销，不过开销可以评估，对系统的统计结果不会有很大影响下面是sar命令对系统CPU的统计输出：12345678910[root@izuf6b0a7e5agj4lm7aj3mz ~]# sar -u 3 5Linux 3.10.0-693.2.2.el7.x86_64 (izuf6b0a7e5agj4lm7aj3mz) 08/29/2018 _x86_64_ (4 CPU)03:05:20 PM CPU %user %nice %system %iowait %steal %idle03:05:23 PM all 0.08 0.00 0.08 0.08 0.00 99.7503:05:26 PM all 0.08 0.00 0.00 0.00 0.00 99.9203:05:29 PM all 0.08 0.00 0.08 0.00 0.00 99.8303:05:32 PM all 0.33 0.00 0.08 0.00 0.00 99.5803:05:35 PM all 0.08 0.00 0.08 0.00 0.00 99.83Average: all 0.13 0.00 0.07 0.02 0.00 99.78 输出解释如下：123456%user列显示了用户进程消耗的CPU 时间百分比。%nice列显示了运行正常进程所消耗的CPU 时间百分比。%system列显示了系统进程消耗的CPU时间百分比。%iowait列显示了IO等待所占用的CPU时间百分比%steal列显示了在内存相对紧张的环境下pagein强制对不同的页面进行的steal操作 。%idle列显示了CPU处在空闲状态的时间百分比。 问题：你是否遇到过系统CPU整体利用率不高，而应用缓慢的现象？1在一个多CPU的系统中，如果程序使用了单线程，会出现一个现象，CPU的整体使用率不高，但是系统应用却响应缓慢，这可能是由于程序使用单线程的原因，单线程只使用一个CPU，导致这个CPU占用率为100%，无法处理其他请求，而其他CPU却闲置，这就导致了整体CPU使用率不是很高，而应用缓慢 内存性能评估free监控内存free是监控Linux内存使用情况的最常用指令：1234[root@izuf6b0a7e5agj4lm7aj3mz ~]# free -m total used free shared buff/cache availableMem: 15886 1925 11977 0 1983 13651Swap: 0 0 0 经验公式：123应用程序可用内存/系统物理内存&gt;70%，表示系统内存资源非常充足，不影响系统性能;应用程序可用内存/系统物理内存&lt;20%，表示系统内存资源紧缺，需要增加系统内存;20% &lt; 应用程序可用内存/系统物理内存 &lt; 70%，表示系统内存资源基本能满足应用需求，暂时不影响系统性能 vmstat 监控内存123456[root@izuf6b0a7e5agj4lm7aj3mz ~]# vmstat 2 3procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 12264516 166640 1864120 0 0 1 41 73 89 3 1 96 0 0 0 0 0 12264624 166640 1864120 0 0 0 6 489 459 0 0 99 1 0 0 0 0 12264624 166640 1864120 0 0 0 0 466 434 0 0 100 0 0 memory1234swpd--切换到内存交换区的内存数量（k为单位)。如swpd值偶尔非0，不影响系统性能free--当前空闲的物理内存数量（k为单位）buff--buffers cache的内存数量，一般对块设备的读写才需要缓冲cache--page cached的内存数量 1一般作为文件系统cached，频繁访问的文件都会被cached，如cache值较大，说明cached的文件数较多，如果此时IO中bi比较小，说明文件系统效率比较好。 swap12si--由磁盘调入内存，也就是内存进入内存交换区的数量。so--由内存调入磁盘，也就是内存交换区进入内存的数量。 si、so的值长期不为0，表示系统内存不足。需增加系统内存。 磁盘I/O性能评估磁盘存储基础频繁访问的文件或数据尽可能用内存读写代替直接磁盘I/O，效率高千倍。将经常进行读写的文件与长期不变的文件独立出来，分别放置到不同的磁盘设备上。1对于写操作频繁的数据，可以考虑使用裸设备代替文件系统 裸设备优点：123数据可以直接读写，不需要经过操作系统级缓存，节省内存资源，避免内存资源争用；避免文件系统级维护开销，如文件系统需维护超级块、I-node等；避免操作系统cache预读功能，减少了I/O请求 裸设备缺点：1数据管理、空间管理不灵活，需要很专业的人来操作 iostat 评估磁盘性能1234567891011121314[root@izuf6b0a7e5agj4lm7aj3mz ~]# iostat -d 2 3Linux 3.10.0-693.2.2.el7.x86_64 (izuf6b0a7e5agj4lm7aj3mz) 08/29/2018 _x86_64_ (4 CPU)Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnvda 21.91 2.71 161.83 243237 14531624vdb 0.00 0.02 0.00 2080 0Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnvda 0.00 0.00 0.00 0 0vdb 0.00 0.00 0.00 0 0Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnvda 0.00 0.00 0.00 0 0vdb 0.00 0.00 0.00 0 0 字段解释：1234Blk_read/s--每秒读取数据块数Blk_wrtn/s--每秒写入数据块数Blk_read--读取的所有块数Blk_wrtn--写入的所有块数 可通过Blk_read/s和Blk_wrtn/s值对磁盘的读写性能有一个基本的了解如Blk_wrtn/s值很大，表示磁盘写操作很频繁，考虑优化磁盘或程序如Blk_read/s值很大，表示磁盘直接读操作很多，可将读取的数据放入内存 规则遵循：1长期的、超大的数据读写，肯定是不正常的，这种情况一定会影响系统性能 sar 评估磁盘性能sar -d，可以对系统的磁盘IO做一个基本的统计：123456789101112131415161718[root@izuf6b0a7e5agj4lm7aj3mz ~]# sar -d 2 3Linux 3.10.0-693.2.2.el7.x86_64 (izuf6b0a7e5agj4lm7aj3mz) 08/29/2018 _x86_64_ (4 CPU)03:24:10 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util03:24:12 PM dev253-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:24:12 PM dev253-16 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:24:12 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util03:24:14 PM dev253-0 0.50 0.00 16.00 32.00 0.00 0.00 0.00 0.0003:24:14 PM dev253-16 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:24:14 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util03:24:16 PM dev253-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:24:16 PM dev253-16 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00Average: DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %utilAverage: dev253-0 0.17 0.00 5.33 32.00 0.00 0.00 0.00 0.00Average: dev253-16 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 参数含义：123await--平均每次设备I/O操作等待时间（毫秒）svctm--平均每次设备I/O操作的服务时间（毫秒）%util--一秒中有百分之几的时间用于I/O操作 对磁盘IO性能评判标准：正常svctm应小于await值，而svctm和磁盘性能有关，CPU、内存符合也会对svctm值造成影响，过多的情趣也会间接导致svctm值的增加1234await值取决于svctm和I/O队列长度以及I/O请求模式如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。 %util–衡量磁盘I/O重要指标：1如%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满符合工作，该磁盘可能存在瓶颈 可优化程序或者通过更换更高、更快的磁盘 网络性能评估1234（1）通过ping命令检测网络的连通性（2）通过netstat –i组合检测网络接口状况（3）通过netstat –r组合检测系统的路由表信息（4）通过sar –n组合显示系统的网络运行状态 Linux服务器性能调优为磁盘I/O调整Linux内核电梯算法选择文件系统之后，该算法可以平衡低延时需求，搜集足够数据，有效组织对磁盘读写请求 禁用不必要的守护进程，节省内存和CPU资源123许多守护进程或服务通常非必需，消耗宝贵内存和CPU时间，将服务器置于险地。禁用可加快启动时间，释放内存减少CPU要处理的进程数 一些被禁用的Linux守护进程，默认自动启动：Apmd 高级电源管理守护进程Nfslock 用于NFS文件锁定Isdn ISDN Moderm支持Autofs 在后台自动挂载文件系统(如自动挂载CD-ROM)Sendmail 邮件传输代理Xfs X Window的字体服务器 关掉GUI清理不需要的模块或功能服务器软件包中太多被启动的功能或模块实际上是不需要的（如Apache中的许多功能模块），禁用掉有助于提高系统内存可用量，腾出资源给哪些真正需要的软件 禁用控制面板在Linux中，有许多流行的控制面板，如Cpanel，Plesk，Webmin和phpMyAdmin等，禁用释放出大约120MB内存 改善Linux Exim服务器性能使用DNS缓存守护进程，可降低解析DNS记录需要的带宽和CPU时间，DNS缓存通过消除每次都从根节点开始查找DNS记录的需求，从而改善网络性能。 Djbdns是一个非常强大的DNS服务器，它具有DNS缓存功能，Djbdns比BIND DNS服务器更安全，性能更好，可以直接通过http://cr.yp.to/下载，或通过Red Hat提供的软件包获得。 使用AES256增强gpg文件加密安全为提高备份文件或敏感信息安全，许多Linux系统管理员都使用gpg进行加密，在使用gpg时，最好指定gpg使用AES256加密算法，AES256使用256位密钥，它是一个开放的加密算法，美国国家安全局(NSA)使用它保护绝密信息 远程备份服务安全安全是选择远程备份服务最重要的因素，大多数系统管理员都害怕两件事：(黑客)可以删除备份文件，不能从备份恢复系统。 为了保证备份文件100%的安全，备份服务公司提供远程备份服务器，使用scp脚本或RSYNC通过SSH传输数据，这样，没有人可以直接进入和访问远程系统，因此，也没有人可以从备份服务删除数据。在选择远程备份服务提供商时，最好从多个方面了解其服务强壮性，如果可以，可以亲自测试一下。 更新默认内核参数设置为了顺利和成功运行企业应用程序，如数据库服务器，可能需要更新一些默认的内核参数设置，例如，2.4.x系列内核消息队列参数msgmni有一个默认值(例如，共享内存，或shmmax在Red Hat系统上默认只有33554432字节)，它只允许有限的数据库并发连接，下面为数据库服务器更好地运行提供了一些建议值(来自IBM DB2支持网站)： kernel.shmmax=268435456 (32位)kernel.shmmax=1073741824 (64位)kernel.msgmni=1024fs.file-max=8192kernel.sem=”250 32000 32 1024″ 优化TCP优化TCP协议有助于提高网络吞吐量，跨广域网的通信使用的带宽越大，延迟时间越长时，建议使用越大的TCP Linux大小，以提高数据传输速率，TCP Linux大小决定了发送主机在没有收到数据传输确认时，可以向接收主机发送多少数据 选择正确的文件系统1使用ext4文件系统代替ext3 Ext4是ext3文件系统的增强版，扩展了存储限制 具有日志功能，保证高水平的数据完整性(在非正常关闭事件中) 非正常关闭和重启时，它不需要检查磁盘(这是一个非常耗时的动作) 更快的写入速度，ext4日志优化了硬盘磁头动作 使用noatime文件系统挂载选项在文件系统启动配置文件fstab中使用noatime选项，如果使用了外部存储，这个挂载选项可以有效改善性能。 调整Linux文件描述符限制Linux限制了任何进程可以打开的文件描述符数量，默认限制是每进程1024，这些限制可能会阻碍基准测试客户端(如httperf和apachebench)和Web服务器本身获得最佳性能，Apache每个连接使用一个进程，因此不会受到影响，但单进程Web服务器，如Zeus是每连接使用一个文件描述符，因此很容易受默认限制的影响。 打开文件限制是一个可以用ulimit命令调整的限制，ulimit -aS命令显示当前的限制，ulimit -aH命令显示硬限制(在未调整/proc中的内核参数前，你不能增加限制)。 Linux第三方应用程序性能技巧 对于运行在Linux上的第三方应用程序，一样有许多性能优化技巧，这些技巧可以帮助你提高Linux服务器的性能，降低运行成本。 正确配置Mysql为了给MySQL分配更多的内存，可设置MySQL缓存大小，要是MySQL服务器实例使用了更多内存，就减少缓存大小，如果MySQL在请求增多时停滞不动，就增加MySQL缓存。 正确配置Apache检查Apache使用了多少内存，再调整StartServers和MinSpareServers参数，以释放更多的内存 分析Linux服务器性能提高系统效率最好的办法是找出导致整体速度下降的瓶颈并解决掉，下面是找出系统关键瓶颈的一些基本技巧： 当大型应用程序，如OpenOffice和Firefox同时运行时，计算机可能会开始变慢，内存不足的出现几率更高 如果启动时真的很慢，可能是应用程序初次启动需要较长的加载时间，一旦启动好后运行就正常了，否则很可能是硬盘太慢了。 CPU负载持续很高，内存也够用，但CPU利用率很低，可以使用CPU负载分析工具监控负载时间。 学习5个linux性能命令使用几个命令就可以管理Linux系统的性能了，下面列出了5个最常用的Linux性能命令，包括top、vmstat、iostat、free和sar，它们有助于系统管理员快速解决性能问题。 将日志文件转移到内存中当一台机器处于运行中时，最好是将系统日志放在内存中，当系统关闭时再将其复制到硬盘，当你运行一台开启了syslog功能的笔记本电脑或移动设备时，ramlog可以帮助你提高系统电池或移动设备闪存驱动器的寿命，使用ramlog的一个好处是，不用再担心某个守护进程每隔30秒向syslog发送一条消息，放在以前，硬盘必须随时保持运转，这样对硬盘和电池都不好。 先打包，后写入在内存中划分出固定大小的空间保存日志文件，这意味着笔记本电脑硬盘不用一直保持运转，只有当某个守护进程需要写入日志时才运转，注意ramlog使用的内存空间大小是固定的，否则系统内存会很快被用光，如果笔记本使用固态硬盘，可以分配50-80MB内存给ramlog使用，ramlog可以减少许多写入周期，极大地提高固态硬盘的使用寿命 一般调优技巧尽可能使用静态内容替代动态内容，如果你在生成天气预告，或其它每隔1小时就必须更新的数据，最好是写一个程序，每隔1小时生成一个静态的文件，而不是让用户运行一个CGI动态地生成报告。 为动态应用程序选择最快最合适的API，CGI可能最容易编程，但它会为每个请求产生一个进程，通常，这是一个成本很高，且不必要的过程，FastCGI是更好的选择，和Apache的mod_perl一样，都可以极大地提高应用程序的性能。 转自原博客]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7搭建SonarQube]]></title>
    <url>%2F2018%2F08%2F23%2FCentos7%E6%90%AD%E5%BB%BASonarQube%2F</url>
    <content type="text"><![CDATA[Centos7搭建代码质量管理平台SonarQube SonarQube是当前比较热门的代码质量管理平台，平台开源，支持多种语言。 搭建之前首先，要确保当前安装服务器已经安装了jdk（最好1.8+），以及MySQL数据库安装jdk：1yum install java-1.8.0-openjdk* -y 安装MySQL1234567891011下载源包：wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm安装mysql源:yum localinstall mysql57-community-release-el7-8.noarch.rpm检查是否安装成功：yum repolist enabled | grep &quot;mysql.*-community.*&quot;安装yum install mysql-community-server 下载安装包 sonarqube下载地址sonar-runner下载地址sonar-scanner下载扫描器地址 搭建SonarQube首先：SonarQube是服务器端，它主要有两个功能：1.分析源代码；2.因为它内嵌了Apache模块，所以提供Web端的界面访问。SonarQube Runner是一个利用SonarQube服务端分析代码的命令行工具，可以把它简单理解为客户端。所以，为了安装和调试方便，建议SonarQube和SonarQube Runner都下载。 创建sonar数据库mysql -uroot -p进入控制台，创建sonar用户及数据库：123456789CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci;CREATE USER &apos;sonar&apos; IDENTIFIED BY &apos;Sonar_1234&apos;;GRANT ALL PRIVILEGES ON `sonar`.* TO &apos;sonar&apos;@&apos;%&apos; IDENTIFIED BY &apos;Sonar_1234&apos;;GRANT ALL PRIVILEGES ON `sonar`.* TO &apos;sonar&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;Sonar_1234&apos;;FLUSH PRIVILEGES; 安装SonarQube进入安装目录，这边用的是/usr/local，rz（yum install lrzsz）将下载的sonarqube-6.7.5.zip,sonar-runner-dist-2.4.zip,sonar-scanner-cli-3.0.3.778-linux.zip上传到服务器，解压sonarqube-6.7.5.zip1unzip sonarqube-6.7.5.zip 顺便其他两个也解压了：123unzip sonar-runner-dist-2.4.zipunzip sonar-scanner-cli-3.0.3.778-linux.zip 配置环境变量vim /etc/profile，到文件底部，添加环境变量：123export SONAR_HOME=/usr/local/sonarqube-6.7.5export SONAR_RUNNER_HOME=/usr/local/sonar-runner-2.4PATH=$PATH:$SONAR_HOME/bin:$SONAR_RUNNER_HOME/bin 生效配置：source /etc/profile 验证：1sonar-runner -v 1234[root@localhost workflow]# sonar-runner -vSonarQube Runner 2.4Java 1.8.0_181 Oracle Corporation (64-bit)Linux 3.10.0-862.9.1.el7.x86_64 amd64 修改配置文件配置SonarQube进入配置文件mulu：cd /usr/local/sonarqube-6.7.5/conf修改配置文件：vim sonar.properties，修改内容如下：123456789sonar.jdbc.username=sonar （第16行）sonar.jdbc.password=Sonar_1234 （第17行）sonar.jdbc.url=jdbc:mysql://127.0.0.1:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false （第26行）sonar.web.host=192.168.0.91 （第105行）sonar.web.port=9000 （第111行） 配置 sonar-runner进入目录cd /usr/local/sonar-runner-2.4/conf，修改配置文件：vim sonar-runner.properties修改内容：12345678910111213141516171819202122232425262728#Configure here general information about the environment, such as SonarQube DB details for example 2 #No information about specific project should appear here 3 4 #----- Default SonarQube server 5 sonar.host.url=http://192.168.0.91:9000 6 7 #----- PostgreSQL 8 #sonar.jdbc.url=jdbc:postgresql://localhost/sonar 9 10 #----- MySQL11 sonar.jdbc.url=jdbc:mysql://127.0.0.1:3306/sonar?useUnicode=true&amp;amp;characterEncoding=utf812 13 #----- Oracle14 #sonar.jdbc.url=jdbc:oracle:thin:@localhost/XE15 16 #----- Microsoft SQLServer17 #sonar.jdbc.url=jdbc:jtds:sqlserver://localhost/sonar;SelectMethod=Cursor18 19 #----- Global database settings20 sonar.jdbc.username=sonar21 sonar.jdbc.password=Sonar_123422 23 #----- Default source code encoding24 #sonar.sourceEncoding=UTF-825 26 #----- Security (when &apos;sonar.forceAuthentication&apos; is set to &apos;true&apos;)27 sonar.login=admin28 sonar.password=admin 启动sonarqubesonarqube需要普通用户才能启动，不能使用root用户，这个比较好办，新建用户和组，更改属组就可以：12useradd -g elasticsearch elasticsearch （前一个elasticsearch是组，后一个是用户）chown -R elasticsearch：elasticsearch sonarqube-6.7.5 修改elasticsearch配置cd /usr/local/sonarqube-6.7.5/elasticsearch/config，修改配置为：123456#network.host: 192.168.0.91## Set a custom port for HTTP:#http.port: 9200 启动cd /usr/local/sonarqube-6.7.5/bin/linux-x86-64./sonar.sh start启动完成~ 项目部署在没有用到jenkins以及git情况下，只有手动将代码上传到服务器进行打分，后期再弄CI，这边介绍的也就是最简单的上传代码的形式。首先，有一个项目需要sonar进行分析，将代码上传到sonar服务器自定义存放代码的位置，例如/root/sourceCode，上传的项目为QATest，然后在项目根目录创建sonar-runner的配置文件sonar-project.properties1vim sonar-project.properties 内容：1234567891011121314# must be unique in a given SonarQube instancesonar.projectKey=my:project# this is the name displayed in the SonarQube UIsonar.projectName=My projectsonar.projectVersion=1.0 # Path is relative to the sonar-project.properties file. Replace &quot;\&quot; by &quot;/&quot; on Windows.# Since SonarQube 4.2, this property is optional if sonar.modules is set. # If not set, SonarQube starts looking for source code from the directory containing # the sonar-project.properties file.sonar.sources=. # Encoding of the source code. Default is default system encoding#sonar.sourceEncoding=UTF-8 保存退出。 启动sonar-runner：sonar-runner -e -X(打印详细日志) 进入SonarQube查看分析结果：http://192.168.0.91:9000/projects（账密：admin/admin）]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>SonarQube</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7搭建influxdb+chronograf]]></title>
    <url>%2F2018%2F08%2F20%2FCentos7%E6%90%AD%E5%BB%BAinfluxdb-chronograf%2F</url>
    <content type="text"><![CDATA[Centos7搭建influxdb+Chronograf elasticsearch实验过后，今天尝试了另一种时序数据库influxdb 安装Influxdbcentos7 64位：12wget https://dl.influxdata.com/influxdb/releases/influxdb-1.6.1.x86_64.rpmsudo yum localinstall influxdb-1.6.1.x86_64.rpm (附卸载方式，曾经想卸载东西，找半天：ipm包：rpm -qa xxxx(查询安装包)rpm -e xxxx（卸载） yum install 安装的包：yum remove xxx) 配置安装完成后，相应配置文件位于：/usr/bin12345influxd influxdb服务器influx influxdb命令行客户端influx_inspect 查看工具influx_stress 压力测试工具influx_tsm 数据库转换工具（将数据库从b1或bz1格式转换为tsm1格式） 数据文件夹：/var/lib/influxdb123data 存放最终存储的数据，文件以.tsm结尾meta 存放数据库元数据wal 存放预写日志文件 以及，配置文件：1/etc/influxdb/influxdb.conf 启动1234加自启动：systemctl enable influxdb启服务：systemctl start influxdb 非服务方式启动：1234[root@localhost influxdb]# influxConnected to http://localhost:8086 version 1.6.1InfluxDB shell version: 1.6.1&gt; 安装Chronograf好像是1.4版本（具体不记得了），influxdb就去掉了自带的web页面（influxdb.conf中没有admin栏），想要从web页面查看数据，可以安装官方配套的展示工具Chronograf，用着感觉和grafana很像。 Cnetos 7下安装：12wget https://dl.influxdata.com/chronograf/releases/chronograf-1.6.1.x86_64.rpmsudo yum localinstall chronograf-1.6.1.x86_64.rpm 启动：systemctl start chronograf默认开启8888端口，浏览器访问http://IP:8888即可（若是在虚拟机安装，打不开，可以尝试用nginx转服务） 简单语法influxdb与传统数据库的比较 influxdb MySQL database 数据库 measurement 数据库中的表 points 表里面的一行数据 influxdb数据的构成：Point由时间戳（time）、数据（field）、标签（tags）组成。 Point属性 传统数据库中的概念 time 每个数据记录时间，是数据库中的主索引(会自动生成) fields 各种记录值（没有索引的属性）也就是记录的值：温度， 湿度 tags 各种有索引的属性：地区，海拔 简单操作influx进入命令行模式：1234567891011121314151617181920#创建数据库create database &quot;db_name&quot;#显示所有的数据库show databases#删除数据库drop database &quot;db_name&quot;#使用数据库use db_name#显示该数据库中所有的表show measurements#创建表，直接在插入数据的时候指定表名insert test,host=127.0.0.1,monitor_name=test count=1#删除表drop measurement &quot;measurement_name&quot; 123INSERT cpu,host=serverA,region=us_west value=0.64 //在cpu表中插入相关的数据SELECT * FROM cpu ORDER BY time DESC LIMIT 3 //查询最近的三条数据delete from cpu where time=1480235366557373922 //删除某条数据 用户操作：12345678910111213用户管理可以通过Chronograf页面做操作，也可以命令行。#显示用户 show users#创建用户create user &quot;username&quot; with password &apos;password&apos;#创建管理员权限用户create user &quot;username&quot; with password &apos;password&apos; with all privileges#删除用户drop user &quot;username&quot; 导入测试数据CREATE DATABASE NOAA_water_database下载官方数据集：1curl https://s3.amazonaws.com/noaa.water-database/NOAA_data.txt -o NOAA_data.txt 写数据1influx -import -path=./NOAA_data.txt -precision=s -database=NOAA_water_database 配置文件参考 influxdb.conf]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>influxdb</tag>
        <tag>Chronograf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些常用网站]]></title>
    <url>%2F2018%2F08%2F15%2F%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[记一些常用的网站 zabbix 模板大全 zabbix各模板 APM鼻祖论文 APM平台的鼻祖 正则表达式 在线正则表达式工具 网页测试工具 WebPagetest Pingdom 论坛 stackoverflow testerhome 51CTO 掘金 思否（segmentfault） 电子书网站 稀酷客Project Gutenberg 数据科学项目练习 Kaggle python 3 cookbook Python3 cookbook Hacker News Hacker News 免费图片 Pixabay 运维 运维生存时间 运维网 Rancher Rancher 娱乐部分 ACG动漫种子 52破解 蜂鸟摄影 TO BE CONTINUED …]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>lives</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7开启nginx status]]></title>
    <url>%2F2018%2F08%2F15%2FCentos7%E5%BC%80%E5%90%AFnginx-status%2F</url>
    <content type="text"><![CDATA[Centos 7开启nginx status 这段时间需要研究APM相关，整理到中间件部分，想到用zabbix来监控Nginx，一般情况下，中间件都有自己的计数器，我们只需要获取计数器的数值即可完成监控。 安装nginx还是啰嗦一下，安装nginx，一条命令即可：1yum install nginx 配置文件路径：默认配置：/etc/nginx/nginx.conf可自建配置:/etc/nginx/conf.d/yourAPP.conf(需要修改nginx.conf最后的配置文件路径) 开启nginx status开启很简单，在配置中增加：1234567location /ngx_status &#123; stub_status on; access_log off; allow 127.0.0.1; deny all; &#125; 即可；由于之前有帮开发搭建了.net core的环境，就直接在之前搭建的配置文件（LiabTest.conf）里面改了：原文件：1234567891011server &#123; listen 80; location / &#123; proxy_pass http://localhost:5000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection keep-alive; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 增加status之后：123456789101112131415161718server &#123; listen 80; location / &#123; proxy_pass http://localhost:5000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection keep-alive; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125; location /ngx_status &#123; stub_status on; access_log off; allow 127.0.0.1; deny all; &#125;&#125; 查看效果重启nginx：1systemctl restart nginx 查看status:1curl http://127.0.0.1/ngx_status 看到信息：12345[root@gtp1 conf.d]# curl http://127.0.0.1/ngx_statusActive connections: 1199 server accepts handled requests 158761 158761 158757 Reading: 0 Writing: 1195 Waiting: 4 nginx status详解12345active connections – 活跃的连接数量server accepts handled requests — 总共处理了158761个连接 , 成功创建158761次握手, 总共处理了158757个请求reading — 读取客户端的连接数.writing — 响应数据到客户端的数量waiting — 开启 keep-alive 的情况下,这个值等于 active – (reading+writing), 意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接.]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK环境搭建及测试数据导入]]></title>
    <url>%2F2018%2F08%2F09%2FELK%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%2F</url>
    <content type="text"><![CDATA[ELK一些前期准备 前面已经搭建过elasticsearch了，和它配套的，L和K：Logstash，Kibana三者关系：Logstash搜集日志，elasticsearch存储，kibana展示 搭建Logstash、kibana首先是官网下载安装包： elasic.co 下载对应的安装包：kibana-6.3.2-linux-x86_64.tar.gzlogstash-6.3.2.tar.gz 安装logstash解压缩下载的安装包logstash-6.3.2.tar.gz，进入logstash-6.3.2/config目录，创建配置文件logstash.conf1vim logstash.conf 内容：123456789101112131415161718input &#123; file &#123; type =&gt; &quot;log&quot; path =&gt; &quot;/logs/*.log&quot; start_position =&gt; &quot;beginning&quot; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#123; &#125; &#125; elasticsearch &#123; hosts =&gt; &quot;es地址IP，例如192.168.0.91&quot; index =&gt; &quot;log-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 保存退出，进入bin目录，启动：1./logstash -f ../config/logstash.conf 安装Kibana解压缩安装包，修改config下配置文件：kibana.yml12345678910111213141516171819202122server.host: &quot;192.168.0.91&quot;# Enables you to specify a path to mount Kibana at if you are running behind a proxy.# Use the `server.rewriteBasePath` setting to tell Kibana if it should remove the basePath# from requests it receives, and to prevent a deprecation warning at startup.# This setting cannot end in a slash.#server.basePath: &quot;&quot;# Specifies whether Kibana should rewrite requests that are prefixed with# `server.basePath` or require that they are rewritten by your reverse proxy.# This setting was effectively always `false` before Kibana 6.3 and will# default to `true` starting in Kibana 7.0.#server.rewriteBasePath: false# The maximum payload size in bytes for incoming server requests.#server.maxPayloadBytes: 1048576# The Kibana server&apos;s name. This is used for display purposes.#server.name: &quot;your-hostname&quot;# The URL of the Elasticsearch instance to use for all your queries.elasticsearch.url: &quot;http://192.168.0.91:9200&quot; 需要更改的是两个地方：server.host和elasticsearch.url，更改保存退出~进bin目录，启动服务~ 添加测试数据官方教程 ElasticSearch的sample data： account.zipshakespeare.jsonlogs.json1.gz 首先加载account数据：1curl -H &quot;Content-Type: application/json&quot; -XPOST &apos;localhost:9200/bank/account/_bulk?pretty&amp;refresh&apos; --data-binary &quot;@accounts.json&quot; shaekspeare和logs，先做mapping1234567891011121314curl -X PUT &quot;192.168.0.91:9200/shakespeare&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;mappings&quot;: &#123; &quot;doc&quot;: &#123; &quot;properties&quot;: &#123; &quot;speaker&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;play_name&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;line_id&quot;: &#123;&quot;type&quot;: &quot;integer&quot;&#125;, &quot;speech_number&quot;: &#123;&quot;type&quot;: &quot;integer&quot;&#125; &#125; &#125; &#125;&#125;&apos; logs1234567891011121314151617curl -X PUT &quot;localhost:9200/logstash-2015.05.18&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125;&apos; 1234567891011121314151617curl -X PUT &quot;localhost:9200/logstash-2015.05.19&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125;&apos; 1234567891011121314151617curl -X PUT &quot;localhost:9200/logstash-2015.05.20&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125;&apos; 导入数据一样：123curl -H &apos;Content-Type: application/x-ndjson&apos; -XPOST &apos;localhost:9200/bank/account/_bulk?pretty&apos; --data-binary @accounts.jsoncurl -H &apos;Content-Type: application/x-ndjson&apos; -XPOST &apos;localhost:9200/shakespeare/doc/_bulk?pretty&apos; --data-binary @shakespeare_6.0.jsoncurl -H &apos;Content-Type: application/x-ndjson&apos; -XPOST &apos;localhost:9200/_bulk?pretty&apos; --data-binary @logs.jsonl 结束~]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>logstash</tag>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 6变更记录]]></title>
    <url>%2F2018%2F08%2F01%2Felasticsearch-6%E5%8F%98%E6%9B%B4%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[elasticsearch 6变更内容记录 原来没怎么接触过es，找了个教程，本来是按着教程上敲的练练手的，然后就我靠了，又回到当初碰Django时候的懵逼状态，新版本改好多。。 No handler for type [string] declared on field本来练手练得好好的：123456789101112131415161718PUT http://192.168.0.91:9200/index_test&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 2 &#125;, &quot;mappings&quot;: &#123; &quot;Testlog&quot;: &#123; &quot;properties&quot;: &#123; &quot;logType&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125; &#125; &#125;&#125; 然后就是悲剧：1234567&quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;mapper_parsing_exception&quot;, &quot;reason&quot;: &quot;No handler for type [string] declared on field [logType]&quot; &#125; ], 研究半天，JSON没啥错啊，教程里就是这么干的啊，回忆起Django的版本悲剧，搜了下版本变更，唉~ElasticSearch 5.x开始就取消了string类型，取代的事text和keyward，text用于全文搜索的, 而keyword用于关键词搜索 找了段网上的解释：这个变动的根本原因是string类型会给我们带来很多困惑: 因为ElasticSearch对字符串拥有两种完全不同的搜索方式. 你可以按照整个文本进行匹配, 即关键词搜索(keyword search), 也可以按单个字符匹配, 即全文搜索(full-text search). 对ElasticSearch稍有了解的人都知道, 前者的字符串被称为not-analyzed字符, 而后者被称作analyzed字符串. 事实上, 同一种类型用于应对两种不同的使用场景是会让人崩溃的, 因为有些选项只对其一的场景设置有效.例如position_increment_gap对not-analyzed字符就不会起作用, 而像ignore_above对于analyzed字符串就很难区分它到底是对整个字符串的值有效还是对单独的每个分词有效(在这种场景, ignore_above确实只对整个字符串值有效, 而对单个分词的限制可以使用limit设置)，同样，index现在也只需要boolean的两种状态，所以可以修改为：12345678910111213141516&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 2 &#125;, &quot;mappings&quot;: &#123; &quot;gaialog&quot;: &#123; &quot;properties&quot;: &#123; &quot;logType&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;false&quot; &#125; &#125; &#125; &#125;&#125; as the final mapping would have more than 1 type原因是6.x开始，取消了mapping type…具体原因可以看官方的解释：removal of mapping type需要的一些解释是：首先，很多人会把es和关系型数据库进行类比；1234index ——&gt; 数据库（database）type ——&gt; 表（table）document ——&gt; 数据记录（data）filed ——&gt; 列（column） 其实这样理解是有问题的，在关系型数据库中，每个表的列都是相互独立的，即使是同样列名的列，也毫无关系；但是在像es这样的映射型数据库中，即使是在不同的type下的field，只要field名字一样，它们所指向的Lucene字段都是同一个，所以是有影响的。在ES中，之前有type的情况下，在不同的type下可以建同样名字的field，比如test，type1下的field是string类型，type2下的field是boolean类型，由于同一个名字的field对应的Lucene字段一样，所以在进行field删除时，系统就会出错，不知道具体应该删的是哪个field。官方为了避免这样的情况，就直接开始了不要type~~~]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos 7安装elasticsearch head]]></title>
    <url>%2F2018%2F08%2F01%2FCentos-7%E5%AE%89%E8%A3%85elasticsearch-head%2F</url>
    <content type="text"><![CDATA[ElasticSearch安装可视化插件ElasticSearch head 依赖node.js首先是安装node.js 方案一可以用yum装：1yum install -y nodejs 再装npm：1npm install -g cnpm --registry=https://registry.npm.taobao.org 方案二或者是源码安装首先安装gcc用于编译：1yum -y install gcc gcc-c++ kernel-devel 开始安装node.js12wget https://nodejs.org/dist/v4.5.0/node-v4.5.0.tar.gztar -xf node-v4.5.0.tar.gz 解压缩之后，进入目录，编译：1234cd node-v4.5.0./configuremakemake install 完成！验证：12node -vnpm 安装完成的是4.5的版本，升级：12npm install -g nn stable 安装grunt1npm install -g grunt 可以查看版本1grunt -version 安装ES head下载git下载源码，可以直接到github下，也可以命令行weg或者git clone下载源码地址|：https://github.com/mobz/elasticsearch-head/建议要是在本地下载的zip包，传服务器时候，切换到es用户操作，使得head文件属主是es用户。然后解压：12unzip elasticsearch-head-master.zipcd elasticsearch-head-master 安装1npm install 配置首先要停掉ES服务 配置http对外服务修改elasticsearch.yml1vim config/elasticsearch.yml 添加：12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 修改host进入elasticsearch-head文件夹，修改Gruntfile.js1vim Gruntfile.js 找到connect：server，添加hostname为你的静态IP，完成~12345678910connect: &#123; server: &#123; options: &#123; hostname: &apos;192.168.0.91&apos;, port: 9100, base: &apos;.&apos;, keepalive: true &#125; &#125; &#125; 启动先启动ES，再起ES headES head有两种启动方式：` grunt server 或者进入es head目录 npm run start浏览器访问:http://IP:9100即可打开页面]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>elasticsearch head</tag>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下搭建ElasticSearch]]></title>
    <url>%2F2018%2F07%2F31%2FCentos%E4%B8%8B%E6%90%AD%E5%BB%BAElasticSearch%2F</url>
    <content type="text"><![CDATA[Centos 7下搭建ElasticSearch JDK首先，ES是java开发的，所以，通性，懂得，装JDK，好在linux下一条命令行就可以解决：12# 安装1.8.0的所有文件yum install java-1.8.0-openjdk* -y 校验：12java -versionjavac 123openjdk version &quot;1.8.0_181&quot;OpenJDK Runtime Environment (build 1.8.0_181-b13)OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode) 很正常，完成。 ElasticSearch下载下载很简单：1wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.zip 然后解压缩就可以了1unzip elasticsearch-6.3.2.zip 启动12cd elasticsearch-6.3.2/bin./elasticsearch 嗯，然后问题就开始了~ 配置用root用户登录的系统，启es，会报错：123456789101112131415[2018-01-28T22:00:31,358][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:125) ~[elasticsearch-6.1.2.jar:6.1.2] at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:112) ~[elasticsearch-6.1.2.jar:6.1.2] at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-6.1.2.jar:6.1.2] at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-6.1.2.jar:6.1.2] at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-6.1.2.jar:6.1.2] at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-6.1.2.jar:6.1.2] at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:85) ~[elasticsearch-6.1.2.jar:6.1.2]Caused by: java.lang.RuntimeException: can not run elasticsearch as root at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:104) ~[elasticsearch-6.1.2.jar:6.1.2] at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:171) ~[elasticsearch-6.1.2.jar:6.1.2] at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:322) ~[elasticsearch-6.1.2.jar:6.1.2] at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:121) ~[elasticsearch-6.1.2.jar:6.1.2] ... 6 more 很明显，人家不让你用root启服务 创建es用户不让用root就创建一个es的用户：1234# 创建es组groupadd elasticsearch# 在es组下创建es用户，并设置密码为elasticsearchuseradd elasticsearch -g elasticsearch -p elasticsearch 然后将前面下载的elasticsearch-6.3.2.zip包拷贝到es家目录下：1cp elasticsearch-6.3.2.zip /home/elasticsearch 解压缩：1unzip elasticsearch-6.3.2.zip 更改文件夹属主和属组：1chown -R elasticsearch:elasticsearch elasticsearch-6.1.2/ 然后切换到es用户，启服务：12su - elasticsearch./bin/elasticsearch 然后就可以看见服务基本是正常起来了：12345678910111213141516171819202122232425262728293031[2018-07-31T22:11:06,918][INFO ][o.e.n.Node ] [] initializing ...[2018-07-31T22:11:07,161][INFO ][o.e.e.NodeEnvironment ] [qR5cyzh] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [12.5gb], net total_space [17.6gb], types [rootfs][2018-07-31T22:11:07,162][INFO ][o.e.e.NodeEnvironment ] [qR5cyzh] heap size [1015.6mb], compressed ordinary object pointers [true][2018-07-31T22:11:07,163][INFO ][o.e.n.Node ] node name [qR5cyzh] derived from node ID [qR5cyzhRQUix7PbCNFViTw]; set [node.name] to override[2018-07-31T22:11:07,163][INFO ][o.e.n.Node ] version[6.1.2], pid[7200], build[5b1fea5/2018-01-10T02:35:59.208Z], OS[Linux/3.10.0-514.el7.x86_64/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_141/25.141-b15][2018-07-31T22:11:07,163][INFO ][o.e.n.Node ] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/home/elasticsearch/elasticsearch-6.1.2, -Des.path.conf=/home/elasticsearch/elasticsearch-6.1.2/config][2018-07-31T22:11:09,295][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [aggs-matrix-stats][2018-07-31T22:11:09,295][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [analysis-common][2018-07-31T22:11:09,295][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [ingest-common][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [lang-expression][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [lang-mustache][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [lang-painless][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [mapper-extras][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [parent-join][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [percolator][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [reindex][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [repository-url][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [transport-netty4][2018-07-31T22:11:09,296][INFO ][o.e.p.PluginsService ] [qR5cyzh] loaded module [tribe][2018-07-31T22:11:09,297][INFO ][o.e.p.PluginsService ] [qR5cyzh] no plugins loaded[2018-07-31T22:11:13,791][INFO ][o.e.d.DiscoveryModule ] [qR5cyzh] using discovery type [zen][2018-07-31T22:11:14,926][INFO ][o.e.n.Node ] initialized[2018-07-31T22:11:14,927][INFO ][o.e.n.Node ] [qR5cyzh] starting ...[2018-07-31T22:11:15,582][INFO ][o.e.t.TransportService ] [qR5cyzh] publish_address &#123;127.0.0.1:9300&#125;, bound_addresses &#123;[::1]:9300&#125;, &#123;127.0.0.1:9300&#125;[2018-07-31T22:11:15,598][WARN ][o.e.b.BootstrapChecks ] [qR5cyzh] max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2018-07-31T22:11:15,598][WARN ][o.e.b.BootstrapChecks ] [qR5cyzh] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144][2018-07-31T22:11:18,915][INFO ][o.e.c.s.MasterService ] [qR5cyzh] zen-disco-elected-as-master ([0] nodes joined), reason: new_master &#123;qR5cyzh&#125;&#123;qR5cyzhRQUix7PbCNFViTw&#125;&#123;wRzc-CVaRmmdLNnPfT_LTA&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125;[2018-07-31T22:11:18,920][INFO ][o.e.c.s.ClusterApplierService] [qR5cyzh] new_master &#123;qR5cyzh&#125;&#123;qR5cyzhRQUix7PbCNFViTw&#125;&#123;wRzc-CVaRmmdLNnPfT_LTA&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125;, reason: apply cluster state (from master [master &#123;qR5cyzh&#125;&#123;qR5cyzhRQUix7PbCNFViTw&#125;&#123;wRzc-CVaRmmdLNnPfT_LTA&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125; committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])[2018-07-31T22:11:19,028][INFO ][o.e.g.GatewayService ] [qR5cyzh] recovered [0] indices into cluster_state[2018-07-31T22:11:19,097][INFO ][o.e.h.n.Netty4HttpServerTransport] [qR5cyzh] publish_address &#123;127.0.0.1:9200&#125;, bound_addresses &#123;[::1]:9200&#125;, &#123;127.0.0.1:9200&#125;[2018-07-31T22:11:19,097][INFO ][o.e.n.Node ] [qR5cyzh] started 验证：1curl &quot;127.0.0.1:9200&quot; 1234567891011121314151617&#123; &quot;name&quot; : &quot;snZNWBu&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;9k1xyJl4S6uoosA_Ua0XEQ&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.3.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;zip&quot;, &quot;build_hash&quot; : &quot;053779d&quot;, &quot;build_date&quot; : &quot;2018-07-20T05:20:23.451332Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.3.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 更改静态IP本地是可以用，但是试了下，由于centos是在虚拟机里面，在外面机器，访问虚拟机ip就打不开es了，没办法，将es设置成静态IP修改配置文件/confif/elasticsearch.yml，修改IP为静态IP：1234567891011# ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#network.host: 192.168.0.91## Set a custom port for HTTP:#http.port: 9200## For more information, consult the network module documentation. 然后重启es，发现，嗯，还是起不来，又报了俩错：123ERROR: [2] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]切到root下，修改对应配置文件：12345cd /etc/security/# 日常备份cp limits.conf limits.conf.bak# 修改配置vim limits.conf 增加内容：123456# elasticsearch config start* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096# elasticsearch config end max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]也是切root改配置123cd /etccp sysctl.conf sysctl.conf.bakvim sysctl.conf 增加内容：123# elasticsearch config startvm.max_map_count=262144# elasticsearch config end 重启系统 然后切到es用户，重启服务，完成~可以到本地浏览器试试访问”http://IP:9200“]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海贼王TV版目录]]></title>
    <url>%2F2018%2F07%2F19%2F%E6%B5%B7%E8%B4%BC%E7%8E%8BTV%E7%89%88%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[来点和技术无关的~作为最爱的动漫，没有之一，整理的一点TV版目录，大海贼！ 一 海贼和小偸（BOSS：小丑巴基。SPECIAL：海军克比）新船员：路飞 索隆 娜美 1:我是路飞,未来的海贼王.2:大剑客现身.海贼猎人_罗罗亚索隆.3:蒙卡VS路飞,神秘的美少年是谁?4:路飞的过去。红发登场!5:恐怖.神奇的力量,海贼小丑巴基船长.6:史上最厉害的怪人.催眠师杰克斯.7:绝命追杀.骑兽师摩奇VS路飞.8:壮烈战斗.剑客索隆VS杂技卡巴吉. 9:谁是胜者.恶魔果实能力者大对决. 二 不虚假的事（BOSS：船长洛克。SPECIAL：可雅）新船员：骗人布 梅利 10:正义的骗子?骗人布船长.11:揭发阴谋.海贼管家洛克船长12:正面冲突!黑猫海贼团斜坡大攻防13:恐怖2人组,黑猫兄弟VS索隆14:路飞复活.可雅小姐冒死奋战15:打倒洛克.骗人布男子的决心16:保护可雅.骗人布海贼团大展身手17:怒气冲天.洛克VS路飞18:你就是珍禽异兽.卡蒙和奇妙的伙伴.19:3刀流的过去.索隆与克伊娜的誓言. 三 ALL BLUE之梦（BOSS：克利克。SPECIAL：红脚哲普）新船员：山治 20:招牌厨师.海上餐厅的山治21:不速之客.山治的饭与啊金的恩.22:最强海贼滥队.克利克提督23:保卫芭拉缔.大海贼_红脚哲普.24:鹰眼米霍克.剑豪索隆命丧大海.25:必杀足技招爆发,山治VS铁壁帕路26:路飞和山治的梦想.梦幻般的ALL BIUE27:冷酷无情的鬼人.海贼滥队总队长啊金28:不会死的.路飞VS克利克的激战29:死斗的结果!肚皮里的一把枪30:起程.海上厨师和路飞他们一起出发 四 橘子和风车（BOSS：鱼人阿龙。SPECIAL：贝尔梅尔）新船员：娜美 31:东海最坏的男人.鱼人海贼恶龙32:可可亚西存的魔女.恶龙的女干部33:骗人布死了?路飞还没登陆吗.34:全员集合,骗人布道出娜美的实情35:不为人知的过去.女战士_贝尔梅尔36:求生.妈妈贝尔梅尔与娜美的亲情.37:路飞站出来.食言的结果38:路飞危险.鱼人VS路飞海贼团39:路飞沉入海底.索隆VS章鱼小八40:伟大的战士.激战山治与骗人布.41:路飞动力全开.娜美的决心与草帽42:爆裂.鱼人恶龙来自海底的猛攻.43:终结鱼人帝国.娜美是我的伙伴44:带着笑容的起航.再见了故乡可可亚西村.45:悬赏犯.草帽路飞闻名全世界 番外编 小巴基大冒险 46:追捕草帽小子.小丑巴基的大冒险.47:久等咯.巴基船长复活. 五 伟大的传说开始（SPECIAL：达斯琪） 48:开始与结束的镇.登陆罗格镇.49:3代鬼撤和雪走.索隆的新刀和女上士.50:骗人布对带小孩的达迪.正午的决斗51:炽热的料理比赛!香吉士VS美人厨师52:巴其复仇!在死刑台上笑的男人Special:路飞落下!秘境.海肚脐之大冒险53:传说开始!目标伟大的航路 TV原创 千年龙的传说 54:全新冒险的预感!神秘少女阿碧丝55:奇迹般的生物!阿碧丝的秘密和传说之岛56:艾力克出击!突破重围冲出军舰岛57:绝海孤岛!传说中的失落之岛58:废墟的决斗!紧张的索隆VS艾力克59:路飞完全包围!尼尔森提督的秘招60:在天空中飞舞!苏醒的千年传说 六 进入伟大航路 开端（SPECIAL：鲸鱼拉布）新船员：薇薇公主 超卡鲁鸭卡鲁 61:愤怒的决斗!跨越红土大陆62:第一道难关!出现巨大的鲸鱼拉布63:男人的约定!路飞与鲸鱼再会的誓言64:欢迎海贼的小镇!登陆威士忌山峰65:三刀流爆发!索隆VS巴洛克工作社66:一决胜负!路飞VS索隆谜样的大决斗67:护送薇薇公主!路飞海贼团出航 番外编 海军奋斗记 68:加油!克比,贝鲁梅伯海军奋斗记69:克比,贝鲁梅伯的决心!格普中将的父母心 七 巨人的小花园 （BOSS：MR.3。SPECIAL：巨人东利 布洛基） 70:太古之岛!潜藏在小花园的黑影71:巨人的决斗!巨人东利与布洛基72:路飞生气了!神圣决斗中的卑鄙陷阱73:布洛基胜利狂哭!艾尔帕布决战74:魔鬼蜡烛!不甘心的眼泪与愤怒的泪水75:袭击路飞的魔法!颜色调配的陷阱76:毅然反击!乌索普的机智与火炎星77:再见了,巨人岛!朝阿拉巴斯坦出发78:娜美生病了!朝海上之雪前进 八 没有名字的国家（BOSS：瓦尔波。SPECIAL：多尔顿）新船员：驯鹿乔巴 79:奇袭!布里基克号与布里基的瓦尔波80:没有医生的岛!在没有名字的国家冒险81:开心吗?人称魔女的医生82:多尔顿的觉悟!瓦尔波军团登陆83:雪之岛!登上磁鼓山顶84:蓝鼻子的驯鹿!乔巴的秘密85:痴人说梦话!庸医西尔尔克86:西尔尔克的樱花与继承的遗志87:VS瓦尔波军团!吞吞果实的实力88:动物系恶魔果实!乔巴的七段变形89:王国的支配终将结束!旗子的信念直到永远90:西尔尔克的樱花!磁鼓炮射的奇迹91:再见了磁鼓岛!我要向大海出发了 九 沙漠的鳄鱼（BOSS：七武海沙鳄鱼。SPECIAL：火拳艾斯 上校斯摩格）新船员：罗宾 92:阿拉巴斯坦的英雄和船上的芭蕾女伶93:朝着沙漠之国前进!呼唤雨之粉与叛乱军94:各路英雄的再次相遇!他的名字叫火拳艾斯95:艾斯和路飞!热情的理想与兄弟情谊96:绿之城!爱尔马尔与功夫海牛97:沙之国的冒险!住在炎热大地的怪物98:沙漠海贼团登场!为自由而生的男人们99:冒牌货的骨气!真心的叛乱军卡缪100:叛乱军战士窥沙!对薇薇发誓的梦101:艳阳的决斗!艾斯VS蝎子男102:遗迹里迷路!薇薇,同伴和国家生存之道103:蜘蛛人咖啡店!8点敌方特务集合104:路飞VS薇薇!赌下同伴之泪的誓言105:阿拉巴斯坦战线!梦之城雨地106:一筹莫展的陷阱!突人雨宴当中107:理想乡作战开始!开始活动的叛乱108:恐怖的香蕉鳄鱼与Mr.王子109:通过逆转大逃亡的关键!蜡烛球110:无情的死斗!路飞VS克洛克达尔111:向着奇迹奔跑!阿拉巴斯坦动物岛112:叛乱军VS国王军!决战在阿尔巴那113:叹息的阿尔巴那!激斗,跑得快队长114:为了同伴的梦想发誓!决斗鼹鼠土堆第四街115:本日大公开!模仿模仿合成脸116:变身为娜美!冯.克雷连打芭蕾拳法117:娜美的旋风注意报告!天候棒炸裂118:皇族的秘宝!古代兵器冥王119:豪剑的精髓!斩钢铁之力与万物的呼吸120:战争结束了!窥沙举起了白旗121:薇薇声音的归宿!英雄从天而降122:沙鳄鱼VS水路飞!决斗第二回合123:鳄鱼!向着王家之墓飞奔吧,路飞124:恶梦之时逼近!这里是沙沙团秘密基地125:伟大之翼!我的名字是国家守护神贝尔126:超越!雨水降落在阿拉巴斯坦127:放下武器吧!海贼和坚守的正义128:海贼的宴会!阿拉巴斯坦逃出计划129:离别的日子!薇薇的冒险结束了130:危险的香气!第七位伙伴-妮可.罗宾 TV原创 彩虹色的雾 131:第一个患者!蓝波球的秘密132:航海士的反乱!为了不曾割舍的梦想133:被继承的梦想!咖哩的铁人香吉士134:让花朵绽放!男子汉乌索普的八尺烟花135:传说中的海贼猎人!流浪的剑士索隆136:羊之岛的赛尼和山中的海贼船137:赚了一笔啊!高利货赛尼的野心138:岛上宝物的线索!赛尼海贼团出击139:彩虹颜色雾的传说!露露嘉岛的老人半藏140:永远之国的居民!盘普今海贼团141:回想故乡!逃离不出的海贼墓场142:乱战必死!贝特的野心与彩虹之塔143:就这样传说开始了!去彩虹的那面 十 空海漫游（BOSS：神艾尼路。SPECIAL：库力克 战鬼瓦夷帕 原神科尔） 144:被夺走的记录!打捞之王人猿145:怪物登场!别对白胡子出手146:别小看梦想!嘲笑之镇”魔谷镇”147:海贼的最高峰!谈梦想的男人和海底探索王148:传说的一族!大话王诺兰德149:向云大满驼!追击南南见鸟150:梦想已完结了吗?贝拉密VS猿山联合军151:一亿的男人!世界最高权力和黑胡子海贼152:让船航向天空!搭上突激的海流153:这里是空之海!空之骑士和天国之门154:神之国!住在云上的天使们155:禁断的大地!神所居住的岛屿和天的制裁156:这么快就成罪犯了!SKYPIEA的执法者157:要逃跑吗!已经开始进行的神的试练158:可爱大道的陷阱!万能的神.艾涅尔159:向前,乌鸦丸号!目标活祭坛160:生存率10%!心网使者的神官大悟161:球的试练的威协!迷失森林的死斗162:乔巴危险!原来的神VS神官修罗163:越来越不可思议!绳的试练和爱的试练164:点燃香朵拉的灯吧!战士瓦夷帕165:天空的黄金乡加雅!目标神之社166:寻找黄金前夜的祭尊!对”大地”的想法167:神.艾涅尔登场!生存战斗的夜鸣曲168:长牙蟒蛇!终于到了生存者游戏的时间169:舍命的排击!(战鬼)瓦夷帕的觉悟170:空中的激战!海贼索隆VS战士布拉哈姆171:呼叫的燃烧炮!路飞VS战鬼瓦夷帕172:沼的试练!乔巴VS神官涅磐173:无敌的能力!艾涅尔的真面目174:幻之都市!雄伟的香多拉遗迹175:生存率0%!乔巴VS神官欧姆176:登上”巨大豆蔓”!上层遗迹的死斗177:铁的试练的重头戏!白荆死亡决斗178:迸出火花的斩击!索隆VS神官欧姆179:崩溃的上层遗迹!走向曲终的五重奏180:古代遗迹的对决!神.艾涅尔的目的181:前往无边无际大地的野心!方舟箴言 182 最后的激战!海贼路飞对神艾尼路!!183 MAXIM浮出水面!起动Despair184 路飞落下!神之载决和娜美的愿望!!185 苏醒的二人！燃烧吧爱情的救援前线！！186 走向绝望的狂想曲，空岛灭亡迫在眉睫！！187 钟声的引导！大战士与探险家的故事 188 从诅咒的束缚中解放！大战士流下热泪！！189 你是我永远的挚友！响彻广阔无边大海的誓约之钟190 天使岛毁灭！雷迎降临的恐怖！！191 放倒巨大豆蔓！逃出空岛的最后希望！192 神之国的奇迹！响彻天堂的岛之歌193 战争结束！响彻远方 充满自豪地幻想曲194 我来到了这里！历史正文的编织者195 走吧，回青海去！！编织出幻想的最终乐章 TV原创 G8要塞 196:发布非常事态命令!恶名昭著海贼船潜人197:料理人香吉士!在海军食堂发挥厨师的真正价值198:被囚的索隆与乔巴的紧急手术199:逼近的海军搜查网!第二名被囚者200:拼命的路飞和香吉士!救出大作战201:热血特种部队参战!桥上的攻防战202:突破包围网!夺回黄金梅利号203:消失的海贼船!要塞攻防第二回合204:黄金夺回作战与威霸回收作战205:一网打尽计划!强纳森自信的秘策206:别了海军要塞!逃出的最后攻防战 十一 长链岛冒险（BOSS：银狐福克西。） 207:长链岛的大冒险208:福克西海贼团与DAVY BACK FIGHT争霸战209:第一回战!环岛皮划艇赛210:银狐福克西!猛烈的干扰攻势211:第二回合!GROGGY RING赛212:连续的红牌!GROGGY RING213:第三回战!滚轴溜冰追逐战214:白热化爆走比赛!突人最终轮215:轰鸣的热球刚球!海贼躲避球赛216:悬崖的决战!不倒翁摔倒了217:船长对决!最终战单挑格斗218:迟缓攻击全开VS不死身的路飞219:壮绝激烈的单挑对决!命运何去何从 TV原创 失忆岛 220:失去了,被夺走了!你是谁?221:抱着笛子的谜之少年和罗宾的推理222:出击,夺回记忆!海贼团上陆223:露出獠牙的索隆!堵在面前的野兽224:原形毕露!记忆小偷最后的攻击225:自尊心强大的男人!银狐福克西226:最接近无敌的男人!最危险的男人 十二 水之都（BOSS：CP9路奇。SPECIAL：冰山 帕裏 青雉）新船员：罗宾 弗兰奇 阳光万里号 227:海军总部大将青雉!最强战斗力的威胁228:橡胶与冰的决斗!路飞VS青雉229:飞驰的海列车与水之都WATER SEWEW230:水上都市的冒险!目标巨大的造船厂231:福兰克一家与冰山先生232:格雷勒公司!壮观的一号船坞233:海贼诱拐事件与等待死亡的海贼船234:救出伙伴!猛攻福兰克屋235:月下的大干戈!悲伤下飘动的海贼旗236:路飞VS乌索普!男儿气魄的大碰撞237 激震水之都!被袭击的冰山!238 橡皮人对喷火的改造人239 犯人是草帽海贼团?水之都的护卫240 永远的离别?招来黑暗的女子尼可.罗宾241 抓住罗宾!草帽海贼团的决议242 信号伴随着炮击！开始行动的CP9243 取下面具的CP9！惊人的真面目244:隐藏的羁绊！冰山与福兰奇245:回来吧罗宾！与CP9的对决246:草帽海贼团全灭？豹型的威胁！247:被船所爱的男人！乌索普的眼泪！248:福兰奇的过去！海列车起航之日249:斯潘达姆的阴谋！海列车颠簸之日250:传说男人的末日！海列车哭泣之日251:背叛后面的真相！罗宾悲伤的决意！252:分离同伴的汽笛！飞驰而去的海列车253:香吉士突入！暴风雨中的海列车大战！254:娜美的全力呼唤！草帽小子路飞复活！255:另一辆海列车？火箭人出击！256.拯救同伴！向拳头发誓的敌我之羁绊！257.击碎大浪！路飞和索隆的最强合体技258.谜之男登场！？他的名为狙击王！259.厨师间的对决！香吉士对拉面拳法！260.车顶上的决斗！福兰奇对内罗261.鬼斩索隆对斩船人T骨262.罗宾争夺战！狙击王的奇策！！263.司法之岛！Eneas Lobby的全貌！264.登陆作战开始！突击！草帽小子海贼团！265.路飞猛冲！司法之岛的大决战！266.与巨人族的攻防！打开第二道门！267.杀出活路！腾空而起的火箭人！268.跟上路飞的步伐！草帽小子一伙全力作战269.路飞海贼团奔向新的战场！270.还我罗宾！路飞对布鲁诺！271.不要停止脚步！点起反击的狼烟！272.路飞就在眼前！前往法院前广场集结273.为了捍卫同伴!二档发动274.回答我罗宾!草帽小子海贼团的呼唤!275.罗宾的过去！被称为恶魔的少女！276.宿命的母女！母亲之名奥尔维亚！277.奥哈拉的悲剧278.说你想活下去!279,跳下瀑布吧！路飞的信念!280.男人的生存之道！索隆的野心和乌索普的梦想！281.泪水编织而成的同伴的羁绊！娜美的世界地图！282.离别造就了男子汉！香吉与乔巴.283.一切都为了伙伴！黑暗中的女人罗宾！284.绝不交出设计图！福兰奇的决断！285.夺取五把钥匙！草帽海贼团 VS CP9！286.恶魔果实的能力！卡库加布拉大变身287.死也不踢女人！男子汉香吉的骑士道！288.猫头鹰的失算！我的可乐是生命之水！289.索隆的新招炸裂登场！剑名：狙击王！290.无法控制！乔巴的蓝波球大变身!291.捕头路飞再登场！是梦境还是现实彩票大骚动！292.城内的散年糕大竞赛！大红鼻子的阴谋！293.泡沫使用者卡里法！逼近娜美的肥皂危机！294.凶报传来,屠魔令发动295.五个娜美？伴随幻象的反击！296.娜美的决断,攻击暴走的乔巴297.猎人香吉登场？赠送给谎言狼的挽歌298.灼热的足技,SANJI的反击299.白刃之间的猛袭!ZORO和KAKU强力斩击对决300.鬼神索隆,气势逼人的阿修罗化身301.斯潘达姆惊愕！屹立于司法塔上的英雄302.罗宾解放！路飞与路奇的激战303.犯人是捕头路飞？追寻消失的大樱花304.不战胜对手就保护不了任何人!3档发动305.战栗的过去！黑暗的正义与罗布·路奇306.梦幻的人鱼出现？在渐渐失去意识之时307.炮火中沉没的岛屿！福兰奇绝望的呼喊！308.等待路飞！踌躇之桥上的死斗！309.充满愿望之拳！路飞拼尽全力的[机关枪]！310.来自大海的朋友！草帽小子一伙最深的友情311.全员大逃亡!海贼的胜利之道312.感谢你,梅利!朦胧之雪中的离别之海313.打破宁静！持有爱之拳的海军中将314.最强的家族!路飞父亲的惊人身份315.新世界!伟大航路的去向316.香克斯的行动!连接暴走时代的纽带317.寻找箭鱼的少女！水之都大搜查318.坚强的妈妈！索隆家务活闹剧！ 319.山治惊愕！谜之老头与超美味料理320.终于全体悬赏！超过6亿的一伙人！321.君临大海的百兽之王！梦想之船终于完成！322.再见了亲爱的小弟们！弗兰奇起航323.走出水之都！男子汉乌索普决斗的了断 324.巡回的悬赏令！欢声雀跃的故乡 向前迈进的船！ 番外篇 艾斯被秒 325.最凶险的能力！袭击艾斯的黑胡子的黑暗 TV原创 海贼旗猎人（BOSS：爸爸？） 326.谜一般的海贼一行！阳光号和危险的陷井327.SUNNY号大难当前！咆哮的超速秘密机器328.沉没于新世界中的梦想！失意的海贼帕泽鲁329.袭击而来的刺客们！冰上的大决斗330 草帽一伙陷入苦战！嵌入旗帜的海贼魂331 酷热全开!迫近的双子磁力量332.混乱不堪的公馆！发怒的首领与被囚的一伙人333.重生的不死鸟！向同伴许下的誓言海贼旗之梦334.炽热的决战！路飞VS灼热的首领335.相会新世界！与勇猛的海贼的告别 TV 原创 336.乔巴人出动！保卫海滨的电视台 十三僵尸岛（BOSS：奥兹 月光莫利亚。 SPECIAL：罗拉）新船员：音乐家布鲁克 337 闯进魔之海！ 浮现于浓雾中的迷之骷髅338 遇见人的喜悦！骷髅绅士的真面目339 怪现象频发！登录[Thriller Bark]340 被称作天才的男人！霍古巴克现身341 娜美千钧一发！僵尸宅院和透明人342 僵尸之迷!恶梦般的霍古巴克研究所343 他的名字是莫里亚！操纵影子的大海贼设下的陷阱344 僵尸歌的飨宴！夜袭钟的黑暗声音345 全是动物！贝罗娜的不可思议的花园346 消失的草帽一伙！出现了神秘的剑客347 残余的骑士道348 从天而降的男人!剑侠鼻歌349 路飞紧急事态!最强影子的去向350 被称为魔人的战士奥兹复活351 500年后的苏醒!!奥兹开眼352 信念的祈求!! 死守爆炸头的布鲁克353 男子汉不灭的誓言！！在远方的天空下等待的朋友354 定将再会!!布鲁克许下誓言的海岬355 食物 娜美和影子！！路飞愤怒的大反击356 乌索普最强?消极之灵就交给我了357 将军僵尸被秒杀!奥兹的冒险心情358 炎之骑士山治！！踢毁虚假的婚礼359 透明的恩怨?山治被夺走的梦360 救命啊英雄 不死之身的敌人幽灵公主361 吓破胆的佩罗纳！！名副其实的牛皮大王乌索普362 屋顶上飞舞的斩击 索隆与龙马的决斗363 激怒的乔巴！霍古巴克魔鬼般的医术364 奥滋的巨吼！死出来草帽小子一伙365 敌人是路飞？最强僵尸对草帽小子一伙366 受死吧阿布萨罗姆！娜美的友情雷击367 扳回一城！必杀草帽合体技368 无声无息的袭击！迷之访问者暴君熊！369 奥滋加莫里亚！力量与智慧的最凶合体370 逆转战局的秘策！梦魇 路飞登场371 草帽小子一伙全军覆没！影影能力全开372 超绝战斗开始！路飞VS路飞373 决战迫近 重撞 最后的一击374 身体消失 照射在恶魔之岛上的朝阳375 永不完结的危机 草帽小子以获得抹杀命令376 全部弹开 熊的肉垫果实能力377 伙伴的痛苦就是我的痛苦 佐隆奋不顾身的战斗378 遥远的誓言 海贼之歌与小鲸鱼379 布鲁克的过去 欢乐的伙伴悲伤的离别380 宾克斯的美酒 连接过去和现在的歌381 新的伙伴音乐家鼻歌布鲁克 TV原创 382 迟缓果实的威胁 银狐福克西再现383 宝藏争夺战 崩溃的SPA ISLAND号384 布鲁克大奋斗 成为真正伙伴的艰辛道路？ 十四（香波地群岛篇） 385 环绕伟大航路半圈！到达！红土大陆386 憎恨草帽小子一伙的男人！铁面男迪巴鲁登场！387 再次相会！救出被囚的鱼人388 悲剧！隐藏在面具下的迪巴鲁的真面目389 爆炸！桑尼号超级秘密武器狮吼炮390 目标直指鱼人岛！肥皂泡群岛登陆391 暴虐！香波迪群岛的支配者天龙人392 全新的对手集结！超新星11人393 目标是凯米！！人贩子的魔手迫近394 救出凯米 群岛上残留着黑暗的历史395 UTIME LIMIT 人类拍卖会开幕396 铁拳炸裂！勇闯竞拍场397 特大恐慌！拍卖会场的死斗！398 大将黄猿出动！ 香波迪群岛的骚乱！399 突破包围网！ 海军VS三名船长！400 罗杰和雷利 海贼王和他的右手腕401 无法回避？大将黄猿的光速踢！402 压倒性优势！海军战斗兵器和平主义者403 新的强敌出现！挑着斧头的战桃丸404 大将黄猿的猛攻 草帽一伙一筹莫展！405 消失的伙伴们 草帽小子一伙的末日406 时代剧特别篇 捕头路飞再次登场407 时代剧特别篇 打破！斯里拉商会的圈套408 登陆！男子禁忌之岛 亚马逊·百合409 急迫！伙伴们的去向 女人岛的冒险410 全体一塌糊涂！海贼女帝汉库克411 后背隐藏的秘密 路飞遭遇蛇姬412 无情的判决！被石化的玛格雷特413 路飞大苦战！蟒蛇姐妹霸气的力量！！414 全力以赴的战斗！橡胶VS蛇蛇415 汉库克的告白 姐妹们难言的过去416 拯救艾斯！新的目的地是大监狱417 恋爱就象暴风雨！婀娜的汉库克418 伙伴们的行踪 气象科学与机关岛419 伙伴们的行踪 巨鸟之岛与桃色乐园！420 伙伴们的行踪 连接岛屿的桥与食人植物421 伙伴们的行踪 消极公主与恶魔王 推进城 Impel Down 422 决死的潜入！海底监狱 Impel Down423 地狱里重逢！？四分五裂果实的能力者！424 粉碎！红莲地狱 巴基的华丽大作战425 监狱最强的男人！毒人·麦哲伦登场426 剧场版联动特别篇 蠢蠢欲动 金狮子的野心427 剧场版联动特别篇 被盯上的小东海428 剧场版联动特别篇 阿密格海贼团的猛攻429 剧场版联动特别篇 激战！路飞VS拉鲁格430 被囚禁的王下七武海！海侠甚平431 牢头萨鲁德得斯的陷阱 LV3·饥饿地狱432 解放的白鸟！再会！冯·克雷433 署长麦哲伦出动 完成！草帽小子包围网434 全部战力集合！LV4·灼热地狱的决战435 麦哲伦够强！冯·克雷临阵逃亡436 一决雌雄！路飞孤注一掷的最后一击437因为是朋友！冯?克雷拼死的营救行动！438 地狱中的乐园！因佩尔LV5.5（2010年2月14日放送）439「路飞治疗开始 伊万小姐奇迹的力量!!」440 相信奇迹！冯·克雷魂的声援441「路飞复活伊娃的越狱计划启动」442 艾斯压送开始 最下层的LV6攻防443 最强小队结成 震憾！推进城444 更加混乱 黑胡子蒂奇袭来445 危险的相遇 黑胡子和雨之希留446 凭意志也不能倒下 认真起来的汉尼拔447 愤怒的JET手枪 路飞VS黑胡子448 阻止麦哲伦！伊万小姐绽放奥义449 麦哲伦的奇策 受阻的越狱计划450 越狱小队 危在旦夕 禁断招术 毒之巨兵451 发生吧 最后的奇迹 突破正义之门452 目标海军本部 营救艾斯之旅453 同伴的下落 空岛报告和改造动物454 伙伴们的下落!巨岛的比奈与桃色的对决455 伙伴们的行踪 革命军和暴食森林的陷阱456 伙伴们的行踪 巨大的墓碑与内裤的恩情 海军本部篇（顶上战争） 457 到达海军总部之前的回想特别篇 兄弟的誓言（动画原创）458 到达海军总部之前的回想特别篇 集合！三大将（动画原创）459 决战临近 海军最强布阵完成460 巨大舰队出现 袭来！白胡子海贼团461 决战拉开帷幕 艾斯和白胡子的过去462 毁灭世界的力量！地震果实的能力463 燃尽一切！大将赤犬的能力464 恶魔的后代！小奥兹 Jr. 勇往直前！465 只有胜者才是正义 发动！战国的作战466 草帽小队登场!风云突变的战场467 就算死也要救你！路飞VS海军 战斗开始468 激战的连续！能力者军团VS能力者军团469 熊发生的异变 伊万愤怒的一击470 剑豪米霍克 逼近路飞的黑刀的斩击471 歼灭作战启动 和平主义者军团的威力472 赤犬的谋略！被陷害的白胡子473 包围作战运作！白胡子海贼团陷入危机！474 处刑执行命令下达 突破包围壁！475 突入最终局面 白胡子起死回生的一招476 路飞拼尽全力 奥里斯广场的全力一战477 消减生命的力量 兴奋·荷尔蒙再次使用478 为了约定！！激斗！路飞与可比479 处刑台就在眼前！开启通往艾斯的道路480 各自选择的道路 路飞VS卡普481 艾斯救出!四皇白胡子最后的船长命令！482 烧尽火焰的能力!赤犬无情的追击!483 寻找答案 火拳艾斯死于战场484 海军本部崩溃 白胡子无言的愤怒！485 一决胜负 白胡子VS黑胡子海贼团486 演出开幕 黑胡子显示出的真正目的487 大将赤犬的执着 袭向路飞的岩浆铁拳488 拼命的呐喊 改变命运的充满勇气的数秒489 香克斯出现！巅峰对决终于结束 大事件后篇 490 群雄割据 新时代开始！491 登陆女儿岛 逼近路飞的残酷现实 海贼王×美食猎人 特别联合篇 492 最强组合！奋斗 路飞和阿虏（1小时特别篇） 兄弟相遇的回忆篇 493 路飞和艾斯 兄弟相遇的故事！494 萨博登场 不确定之物终点站的少年495 我不会逃！艾斯拼死的营救作战496 有朝一日要出海！三顽童推杯换盏结兄弟！497 告别达旦一家？建成！秘密基地（动画原创）498 路飞拜师？和海贼王交锋过的男人（动画原创）499 和巨虎的决战 成为船长的人是谁？（动画原创）500 被夺去的自由！逼近三兄弟的贵族的陷阱！501 被释放的火炎 Gray terminal的危机502 自由在哪里? 少年悲剧的出航!503 拜托你了！兄弟寄来的信504 为了兑现约定 各自开始旅程！505 好想见他们！路飞泪的呼喊！506 草帽一伙儿 震惊！传来的噩耗 修行与两年后 第507话 和冥王雷利重逢 路飞决断之时第508话 回到船长身边！空岛逃离与浮游岛的案件第509话 接触！大剑豪米霍克 索隆 意气用事的决斗！第510话 山治受难，返回王国的女王！第511话 竟然再次登陆！路飞来到海军本部！第512话 传达给伙伴们 四处传播的大新闻！第513话 海贼们开始行动！惊天动地的新世界！第514话 地狱中求生还 山治，赌上男人尊严的一战！第515话 还要变得更强 索隆向船长的发誓！第516话 路飞开始修行 2年后前往约定之地第517话 新章开幕 草帽一伙再集结！第518话 一触即发！路飞VS伪路飞第519话 被阻击的草帽一伙第520话 假草帽一伙的威胁第521话 见识修行的成果 鱼人岛篇 第522话 路飞踏上前往新世界的航程第523话 守卫桑尼号的男人！第524话 大海原的恶魔现身第525话 失散的草帽一伙第526话 海底火山喷发第527话 登陆鱼人岛！美丽的人鱼们第528话 香吉士生命垂危第529话 鱼人岛灭亡？夏利的预言第530话 鱼人岛之王 海神尼普顿第531话 龙宫城 被所救的鲨鱼带过来第532话 爱哭的胆小鬼！硬塔壳的人鱼公主第533话 发生紧急事态 被占领的龙宫城第534话 龙宫城震动 白星诱拐事件第535话 霍迪袭来 复仇计划开始第536话 龙宫城的决战 卓洛VS霍迪第537话 守护白星！邓肯的追击第538话 草帽一伙战败？霍迪掌控龙宫城第539话 复苏的因缘 娜美和鱼人海贼团第540话 解放奴隶的英雄 冒险家泰格第541话 黄猿登场！瞄准泰格的陷阱 美食的俘虏特别篇第542话 再会 阿虏和路飞 寻找海鲜果实（46分钟特别篇） 继续============================================ 第543话 英雄的末路 泰格令人震惊的真相第544话 海贼团分裂 甚平VS阿龙第545话 鱼人岛震动！漂流而来的天龙人第546话 突然的悲剧！封闭未来的凶杀第547话 再回到现在 霍迪开始行动第548话 王国震惊 尼普顿处刑命令第549话 产生的裂痕！路飞VS甚平第550话 霍迪的异变 凶药真正的力量第551话 决战开始 乔克尔特广场第552话 震惊的告白 乙姬暗杀的真相第553话 白星的眼泪！路飞终于登场第554话 大激战！草帽小子一伙VS10万敌人第555话 绝招炸裂！索隆、香吉出击！第556话 初次亮相！桑尼号的秘密武器！第557话 钢铁海贼！弗兰奇将军登场第558话 诺亚接近！鱼人岛毁灭的危机第559话 快点！路飞！白星危在旦夕！第560话 激斗开始！路飞VS霍迪！第561话 大乱站！草帽小子一伙VS新鱼人海贼团！第562话 路飞败北！？霍迪复仇的时刻第563话 令人震惊的真相！霍迪的真实身份！第564话 一切归零！对路飞强烈的愿望！第565话 路飞全力的一击！火拳枪炸裂第566话 终于了结！与霍迪的最终决战第567话 停下诺亚！拼命的橡皮机关枪！第568话 迈向未来！通向太阳的道路！第569话 被揭开的秘密 古代兵器的真相第570话 草帽小子一伙惊愕！新的海军元帅！第571话 最爱糖果！四皇毕古麻姆第572话 前途多艰 新世界的陷阱第573话 终于出航！再见鱼人岛第574话 迈向新世界！目标最强海域 Z的野心篇第575话 Z的野心篇 小小巨人莉莉！第576话 Z的野心篇 谜之最强军团登场！第577话 Z的野心篇 决死的大脱逃作战！第578话 Z的野心篇 路飞VS修佐！ 燃烧岛篇（庞克哈扎德） 第579话 登陆！燃烧岛庞克哈萨德第580话 灼热的战斗！路飞VS巨大龙！第581话 一伙人骚然！令人震惊的独头武士登场！第582话 惊愕！终于显露出的岛上的秘密第583话 救出孩子们！全员战斗开始第584话 剑术对决 布鲁克VS神秘的躯体武士第585话 七武海！托拉法尔加·劳第586话 大危机 路飞沉入极寒之湖第587话 激斗！劳VS斯摩格中将第588话 2年后的重逢！路飞与劳第589话 世界最邪恶 恐怖科学家凯撒 TV原创（联合篇）第590话 奔跑吧最强军团！阿虏和路飞和悟空！ 继续================================ 第591话 乔巴震怒 主人惨无人道的实验第592话 全部抹杀！传说中的杀手袭来！第593话 拯救娜美！路飞的雪山之战第594话 结成！路飞·劳的海贼同盟！第595话 抓住MASTER 海贼同盟开始作战！第596话 全灭危机 死亡怪物飞来第597话 大激战 凯撒发动真正的能力！第598话 劈开火海的武士！狐火锦卫门第599话 冲击！神秘男人 维尔戈真正的身份第600话 守护孩子们！袭来的Master的魔爪第601话 震惊新世界 凯撒恶梦的实验第602话 史上最邪恶的杀戮武器！死亡国度第603话 反击开始！路飞?劳全部逃出第604话 目标R栋！海贼同盟急行军！第605话 达斯琪的泪 G-5的决死作战第606话 背叛的中将！鬼竹之维尔戈第607话 白热化激战！路飞对凯撒第608话 幕后黑手 多福朗明哥出手第609话 路飞冻死？恐怖的雪女 第610话 碰撞的双拳！两中将之战 第611话 小龙！桃之助现身 第612话 暴风雨中的死斗！草帽一伙儿VS雪女 第613话 奥义爆发！索隆最强的一刀流 第614话 保护朋友！莫查拼死奔逃 第615话 茶胡子的悲痛！路飞愤怒的一击 第616话 令人震惊的决斗！白猎VS维尔戈 第617话 击败凯撒！最强的灰熊铳 第618话 袭来！来自德雷斯罗萨的刺客 第619话 大爆发！无敌的弗兰奇将军第620话 穷途末路！PUNK HAZARD大爆炸 第621话 捕获凯撒！将军炮炸裂 第622话 感动再会！桃之助与锦卫门 第623话 离别之时 庞克哈萨德出航 第624话 G5全灭！多佛朗明哥急袭第625话 紧迫！青雉VS多弗朗明哥第626话 消失的凯撒！海贼同盟出击第627话 路飞命丧大海？海贼同盟瓦解第628话 炸裂！路飞愤怒的铁拳 德雷斯罗萨篇 第629话 激震！撼动新世界的超级新闻第630话 冒险！爱与热情的国度 德雷斯罗萨第631话 狂热的漩涡 斗牛竞技场第632话 危险的恋情 舞女维奥莱特第633话 最强的无名战士！路西登场第634话 海贼贵公子 卡文迪许第635话 命运的再会 鬣狗贝拉米第636话 超级新星！吃人的巴托洛米奥第637话 群雄割据！B组白热化！第638话 一击必杀！惊愕的国王之拳第639话 斗鱼袭来！突破死亡铁桥第640话 冒险！妖精之岛Green Bit第641话 不为人知的世界 冬塔塔王国第642话 世纪的谋略 多弗朗明哥行动！第643话 惊天动地！大将滕虎的实力第644话 愤怒的一击！巨人VS路西第645话 破坏炮炸裂！路西命悬一线第646话 传说中的海贼 首领青椒！第647话 光与影 潜藏于德雷斯罗萨的阴影！第648话 出击！传说中的英雄乌索兰德第649话 激战之胜负 路西对青椒第650话 路飞与 宿命的剑斗士蕾贝卡第651话 守护到底！蕾贝卡和玩具军人第652话 最后的激战区 D组开战第653话 决战！乔拉对草帽一伙第654话 美剑！白马的卡文迪许！第655话 激烈冲突！香吉士VS多福朗明哥第656话 蕾贝卡必杀剑！背水的剑舞第657话 最强的战士 罗根VS蕾贝卡第658话 震惊！玩具士兵的真正身份第659话 战栗的过去！德雷斯罗萨的秘密第660话 噩梦！德雷斯罗萨悲剧的一夜第661话 七武海对决 罗VS多弗朗明哥 2014-09-14第662话 两雄对峙！草帽VS天夜叉 2014-09-21第663话 路飞惊愕 继承艾斯意志之人 2014-09-28第664话 SOP作战开始 乌索兰度突击 2014-10-05第665话 心潮澎湃 蕾贝卡VS斯雷曼 2014-10-12第666话 决出胜者！？D区令人震惊的结果 2014-10-19第667话 大将的决断 藤虎VS多弗朗明哥 2014-10-26第668话 决赛开始 英雄迪亚曼蒂登场 2014-11-02第669话 移动的城堡！最高干部琵卡出现！ 2014-11-09第670话 龙之爪炸裂！路西使出惊人一击！ 2014-11-16第671话 打倒砂糖 小人军突击！ 2014-11-23第672话 最后的光明 我们队长的秘密！ 2014-11-30第673话 破裂人 古拉迪乌斯大爆炸！ 2014-12-07第674话 骗子乌索兰度正在逃亡！ 2014-12-14第675话 命运中的邂逅 居鲁士和力库王 2014-12-21第676话 作战失败！英雄乌索兰度逝世！？ 2014-12-28第677话 传说复活！居鲁士的全力一击 2015-01-11第678话 火拳炸裂！烧烧果实力量复活 2015-01-18第679话 飒爽登场 革命军参谋总长萨博！ 2015-01-25第680话 恶魔的陷阱 德雷斯罗萨歼灭作战 2015-02-01第681话 悬赏5亿的男人 被盯上的乌索兰度！ 2015-02-08第682话 突破敌阵 路飞索隆开始反击 2015-02-15第683话 大地轰鸣 破坏神巨大琵卡降临 2015-03-01第684话 大集结！路飞和凶恶战士军团 2015-03-15第685话 突飞猛进！路飞军团VS琵卡！ 2015-03-22第686话 冲击告白！罗对灵魂的热血誓言！ 2015-03-29第687话 大冲突！参谋总长萨博VS大将藤虎 2015-04-05第688话 命悬一线 中了圈套的路飞！ 2015-04-12第689话 奋力逃脱！路飞起死回生的象枪 2015-04-19第690话 共同战线 路飞通往胜利的突破口 2015-04-26第691话 第二位武士 阵雨勘十郎登场 2015-05-03第692话 激战琵卡战 索隆必杀一击！ 2015-05-10第693话 小人族的公主 被抓的曼雪莉 2015-05-17第694话 不死之身！恐怖的人头玩具军团 2015-05-24第695话 拼上性命！路飞是获胜的王牌 2015-05-31第696话 泪眼相逢 蕾贝卡和居鲁士！ 2015-06-07第697话 一击必杀 拯救德雷斯罗萨的男人 2015-06-14第698话 愤怒爆发 路飞和罗最强的秘计 2015-06-21第699话 高贵一族 多弗朗明哥的真正身份！ 2015-06-28第700话 究极的力量 手术果实的秘密！ 2015-07-05第701话 悲伤的记忆 白色城镇的少年罗！ 2015-07-12第702话 天龙人！多弗壮绝的过去 2015-07-19第703话 苦难之路 罗和柯拉松的命之旅程 2015-08-02第704话 时限迫近！夺取手术果实！ 2015-08-09第705话 觉悟之时 柯拉松告别的笑容！ 2015-08-16第706话 冲吧 罗 温柔男人最后的战斗！ 2015-08-23第707话 冲向自由！罗 注射射击爆发 2015-08-30第708话 狂热之战 罗VS多弗朗明哥 2015-09-06第709话 干部决斗 崇高的海尔丁 2015-09-13第710话 爱之决战 新栋梁老蔡 VS BABY5 2015-09-20第711话 男子汉的坚持 贝拉米最后的突击！ 2015-09-27第712话 疾风怒涛 哈库巴VS德林杰 2015-10-04第713话 致敬神拳 屏障屏障手枪发动！ 2015-10-11第714话 拯救治愈公主 曼雪莉！ 2015-10-18第715话 男子汉的决斗 赛尼奥尔爱的挽歌 2015-10-25第716话 死亡星屑 迪亚曼蒂疾风骤雨般的猛攻 2015-11-01第717话 雷之破坏剑！居鲁士愤怒的一击！ 2015-11-08第718话 大地横断 巨像琵卡的奇袭战！ 2015-11-15第719话 空中决战 索隆新必杀奥义爆发！ 2015-11-22第720话 永别了！贝拉米 告别的一击！ 2015-11-29第721话 罗战死 路飞愤怒的猛攻！ 2015-12-06第722话 执念之刃 逆袭的伽马刀！ 2015-12-13第723话 霸气冲突 路飞VS多弗朗明哥 2015-12-20第724话 无法攻击 托雷波尔冲击的秘密 2015-12-27第725话 愤怒爆发 全部由我来承担 2016-01-10第726话 四档！惊异的弹力人！ 2016-01-17第727话 大逆袭！多弗朗明哥的觉醒！ 2016-01-24第728话 路飞！使尽全力的狮子火箭炮 2016-01-31第729话 火焰龙王 将路飞的性命守护到底 2016-02-14第730话 奇迹之泪 曼雪莉的战斗！ 2016-02-21第731话 生命的极限 阻止死之鸟笼！ 2016-02-28第732话 或生或死 命运的倒计时 2016-03-06第733话 讨伐天 路飞愤怒的大猿王枪 2016-03-20第734话 朝着自由！喜悦的德雷斯罗萨！ 2016-03-27第735话 前所未闻 大将藤虎冲击的决断！ 2016-04-03第736话 激烈暴走 极恶的世代出动！ 2016-04-10第737话 传说诞生 革命战士萨博的冒险！ 2016-04-17第738话 兄弟的羁绊 路飞?萨博重逢密谈 2016-04-24第739话 最强的生物 四皇?百兽凯多 2016-05-01第740话 藤虎出动 草帽一伙完全包围网 2016-05-08第741话 非常事态 被拐走的蕾贝卡！ 2016-05-15第742话 父女的羁绊 居鲁士和蕾贝卡！ 2016-05-22第743话 男子汉的坚持 路飞VS藤虎 决一雌雄 2016-05-29第744话 无处可逃 大将藤虎无情的追击！ 2016-06-05第745话 接纳酒 草帽大船团成立！ 2016-06-12第746话 群雄割据 狂暴的新世界怪物们 2016-06-19第747话 动画原创 银之要塞 路飞和巴托的大冒险 2016-06-26第748话 动画原创 地下迷宫 路飞VS推车人 2016-07-03第749话 动画原创 剑技白热 罗?索隆终于登场！ 2016-07-10第750话 动画原创 绝体绝命 路飞极限的灼热决战 2016-07-17 18th 佐乌篇第751话 冒险开幕 到达梦幻之岛佐乌岛！ 2016-07-31第752话 新七武海 传说?白胡子的儿子登场 2016-08-07第753话 拼死登象 巨象背上的大冒险！ 2016-08-21第754话 战斗开始 路飞VS毛皮族！ 2016-08-21第755话 卡鲁秋！草帽一伙重新团聚 2016-09-04第756话 反击开始 卷眉毛一伙大活跃！ 2016-09-11第757话 威胁来袭 百兽海贼团杰克！ 2016-09-25第758话 日间之王 犬岚公爵登场！ 2016-10-02第759话 夜间之王 猫蝮蛇老大登场 2016-10-09第760话 首都毁灭 卷眉毛一伙登陆！ 2016-10-16第761话 极限逼近 毛皮族和一伙的羁绊！ 2016-10-23第762话 恶童返乡 四皇BIG MOM的刺客 2016-10-30第763话 失踪的真相 山治惊愕的请贴 2016-11-06第764话 给伙计们 山治离别的纸条 2016-11-13第765话 去见猫蝮蛇老大 2016-11-20第766话 路飞决断 山治退出的危机！ 2016-11-27第767话 一触即发 犬和猫和武士！ 2016-12-04第768话 第三个人！忍者?雾之雷藏登场 2016-12-11第769话 赤之石！通往大秘宝的路标 2016-12-18第770话 和之国的秘密 光月家和历史正文 2016-12-25第771话 男人的誓言 路飞和光月桃之助 2017-01-08第772话 传说中的航海 犬和猫和海贼王！ 2017-01-15第773话 恶梦重现 不死之身杰克强袭 2017-01-22第774话 佐乌防卫战 路飞和象主！ 2017-01-29第775话 拯救巨象 草帽急救大作战！ 2017-02-05第776话 离别的下象 夺回山治的出海！ 2017-02-12第777话 参加世界会议 薇薇公主和白星公主 2017-02-19第778话 参加世界会议 蕾贝卡和樱花王国 2017-02-26第779话 凯多再次来袭 威胁重重极恶的世代！ 2017-03-05第780话 动画原创 空腹战线 路飞和海军超新星！ 2017-03-19第781话 动画原创 执着的3人 草帽一伙大追击战！ 2017-03-26第782话 动画原创 恶魔之拳 决战！路飞VS古兰特 2017-04-02 19th 蛋糕岛篇第783话 山治还乡 去BIG?MOM海域！ 2017-04-09第784话 0和4 遭遇！杰尔玛66 2017-04-16第785话 剧毒的危机 路飞和蕾玖！ 2017-04-23第786话 万国！四皇BIG?MOM登场 2017-04-30第787话 四皇之女 山治的未婚妻布琳 2017-05-07第788话 大进击！思食病的MOM 2017-05-14第789话 首都崩溃 BIG MOM和甚平 2017-05-21第790话 四皇之城 到达蛋糕岛 2017-05-28第791话 点心森林 路飞VS路飞！？ 2017-06-04第792话 妈妈的刺客 路飞和诱惑森林！ 2017-06-11第793话 海游国家 杰尔玛之王伽治 2017-06-18第794话 父子对决 伽治VS山治！ 2017-06-25第795话 巨大的野心 BIG MOM与凯撒 2017-07-02第796话 万国的真相 妈妈的恐怖能力！ 2017-07-09第797话 大干部！三将星克力架登场 2017-07-16第798话 8亿之敌 路飞VS千手克力架 2017-07-23第799话 全力对决 四档VS饼干果实能力 2017-07-30第800话 1和2集合 文斯莫克家 2017-08-06第801话 恩人之命 山治与主厨哲普 2017-08-13第802话 恩人之命 山治与主厨哲普 2017-08-20第803话 丢弃的过去 文斯莫克?山治 2017-08-27第804话 向着东海出发 山治下定决心出海 2017-09-03第805话 极限对决 路飞和无限饼干 2017-09-17第806话 饱食之力 新4档坦克人！ 2017-09-24第807话 悲哀的决斗 路飞VS山治（前篇） 2017-10-01第808话 悲哀的决斗 路飞VS山治（后篇） 2017-10-01第809话 复仇的暴风雨 愤怒军团袭来！ 2017-10-15第810话 冒险结束 山治下定决心的求婚 2017-10-22第811话 在此等待 路飞VS愤怒军团 2017-10-29第812话 潜入城堡内 抢夺！路标历史正文 2017-11-05第813话 因缘的对决 路飞与BIG MOM 2017-11-12第814话 灵魂的呐喊 布鲁克 佩德洛 闪电作战 2017-11-19第815话 再见了 布琳泪的决心 2017-11-26第816话 左眼的渊源 佩德洛VS蛋蛋男爵 2017-12-03第817话 烟蒂 山治的结婚前夜 2017-12-10第818话 不屈的灵魂 布鲁克 VS BIG MOM 2017-12-17第819话 母亲的愿望 杰尔玛的失败作品山治第820话 狂奔向山治身边 路飞开始逆袭!第821话 城内动乱 路飞前往约定之地第822话 离别的决心 山治和草帽便当第823话 四皇翻身 拯救布鲁克大作战第824话 约定之地 路飞极限的单枪匹马厮杀第825话 骗子 路飞和山治第826话 山治复活 破坏吧 地狱的茶会第827话 密会 路飞VS火焰坦克海贼团第828话 死之协定 路飞 贝基联合军第829话 路飞暗中行动 茶会即将开始 阴谋的结婚仪式第830话 家人集结 宴会开始 地狱的茶会第831话 假面夫妻 山治 布琳 登场第832话 死亡之吻 四皇暗杀作战开始第833话 归还酒杯 侠客甚平的了断第834话 作战失败 发起反击的BIG MOM海贼团第835话 奔跑吧山治 SOS 杰尔马66第845话：布琳的决心 大起火!诱惑的森林第846话：反击之雷，娜美和雷云宙斯第847话：偶然的再会，山治和陷入恋爱的坏布琳第848话：守护桑尼号 奋战！乔巴&amp;布鲁克]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>One Piece</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[loadrunner判断接口返回]]></title>
    <url>%2F2018%2F07%2F11%2Floadrunner%E5%88%A4%E6%96%AD%E6%8E%A5%E5%8F%A3%E8%BF%94%E5%9B%9E%2F</url>
    <content type="text"><![CDATA[loadrunner判断前一个接口返回，执行第二个接口 Action(){ /*关联获取接口返回结果，true或者false*/ web_reg_save_param(&quot;Text&quot;,&quot;LB=\&quot;result\&quot;:&quot;,&quot;RB=,&quot;,LAST); /*开始事务*/ lr_start_transaction(&quot;01_api_1&quot;); web_custom_request(&quot;api_1&quot;, &quot;URL=https://webapp-n2.test.com/api/test&quot;, &quot;Method=GET&quot;, &quot;TargetFrame=&quot;, &quot;Resource=0&quot;, &quot;Snapshot=t2.inf&quot;, &quot;RecContentType=text/html&quot;, LAST); lr_end_transaction(&quot;01_api_1&quot;,LR_AUTO); /*测试一下输出，用error只是因为会标红。。*/ lr_error_message(lr_eval_string(&quot;{Text}&quot;)); /*判断第一个接口返回是否为true*/ if (strcmp(lr_eval_string(&quot;{Text}&quot;),&quot;true&quot;) == 0){ lr_start_transaction(&quot;01_api_2&quot;); web_reg_find(&quot;Text=false&quot;, LAST); web_custom_request(&quot;api_2&quot;, &quot;URL=https://webapp-n2.test.com/api/test&quot;, &quot;Method=GET&quot;, &quot;TargetFrame=&quot;, &quot;Resource=0&quot;, &quot;Snapshot=t2.inf&quot;, &quot;RecContentType=text/html&quot;, LAST); lr_end_transaction(&quot;01_api_2&quot;,LR_AUTO); lr_output_message(&quot;第二接口完&quot;); }else{ lr_error_message(&quot;请求失败&quot;); return 0; }; return 0; }]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>loadrunner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter压测socket close异常]]></title>
    <url>%2F2018%2F07%2F06%2FJmeter%E5%8E%8B%E6%B5%8Bsocket-close%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[jmeter压测执行过程中报错：java.net.SocketException: Socket operation on nonsocket: connect 原因使用jmeter进行接口压测，http请求，默认是勾选了use keepAlive，但是在Jmeter.properties配置文件中的时间设置默认是注释的状态，也就是说，一旦发生连接空闲，则立刻断开，导致压测过程中出现事务失败。 解决办法在网上直接搜这个报错，有几个解决办法，说实话，有点懒，没看原理，就都照样该了下，重启jmeter之后就报错了。 Jmeter.properties取消注释：1hc.parameters.file=hc.parameters 取消注释并修改：1httpclient4.retrycount=1 取消注释并修改：1httpclient4.idletimeout=300 单位毫秒 hc.parameters取消注释并修改：1http.connection.stalecheck$Boolean=true 网上普遍的说法是httpclient4.idletimeout=300，其他几个是科学上网，在外网找到的。 参考资料 Jmeter WikiJmeter-Socket closed]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vultr安装锐速]]></title>
    <url>%2F2018%2F07%2F05%2FVultr%E5%AE%89%E8%A3%85%E9%94%90%E9%80%9F%2F</url>
    <content type="text"><![CDATA[Vultr专用破解版锐速安装 因为Vultr机房都位于国外，当上网高峰期来临时，连接速度会比较慢，所以就需要安装锐速来加速连接。 安装shadowsocks因为SSR搭建完成之后，在手机和mac上都找不到对应的客户端用，没办法，降级到比较老的shadowsocks安装方式类似：123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 这次只要配置个密码和端口，再选个加密方式即可~ 配置TCP Fast Open搭建完成shadowsocks之后，为了优化连接，可以增加一点配置：1vim /etc/rc.local 最后一行增加1echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen 1vim /etc/sysctl.conf 最后一行增加1net.ipv4.tcp_fastopen = 3 1vim /etc/shadowsocks.json 修改&quot;fast_open&quot;:true 多端口配置修改/etc/shadowsocks.json文件：12345678910111213&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:&#123; &quot;8088&quot;:&quot;xxx&quot;, &quot;8089&quot;:&quot;xxx&quot;, &quot;32123&quot;:&quot;xxx&quot; &#125;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;:true&#125; 重启：/etc/init.d/shadowsocks restart 注意事项1、安装锐速需降级系统内核，而安装 Google BBR 则需升级系统内核，故两者不能同时安装。 2、安装锐速需降级系统内核，有可能造成系统不稳定，故不建议将其应用在重要的生产环境中。 3、本教程只支持 CentOS6 x64 及 CentOS7 x64 系统，不支持任何 Debian &amp; Ubuntu 系统！ 系统判断1uname -r 1、结果以 2 开头，例如 2.6.32-696.18.7.el6.x86_64。 这种输出结果说明我们的服务器为 CentOS6 x64 系统，大家直接查看第三步进行锐速安装即可。 2、结果以 3 开头，例如 3.10.0-693.11.6.el7.x86_64。 这种输出结果说明我们的服务器为 CentOS7 x64 系统，大家直接查看第四步进行锐速安装即可。 3、结果以 4 开头，例如 4.12.10-1.el7.elrepo.x86_64。 这种输出结果说明我们的服务器已经安装 Google BBR 拥塞控制算法，此时已经无法继续安装锐速。 Centos X64安装锐速执行：1wget --no-check-certificate -O rskernel.sh https://raw.githubusercontent.com/uxh/shadowsocks_bash/master/rskernel.sh &amp;&amp; bash rskernel.sh 直接回车，安装完成系统会自动重启系统重启之后，重新连接服务器，执行：1yum install net-tools -y &amp;&amp; wget --no-check-certificate -O appex.sh https://raw.githubusercontent.com/0oVicero0/serverSpeeder_Install/master/appex.sh &amp;&amp; bash appex.sh install 遇到选择直接回车，完成安装，并且开机启动 参考连接]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>Vultr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix3.4配置邮件告警]]></title>
    <url>%2F2018%2F06%2F28%2Fzabbix3-4%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[zabbix3.4配置邮件告警使用zabbix配置邮件告警，当系统资源到达触发器设定阈值，邮件报警 触发器添加监控项测试用模板是zabbix自带的Template OS Linux模板，模板中原先就有监控CPU的监控项，这边测试就用CPU idle time（获取服务器空闲CPU百分比），如果当前安装的zabbix没有该监控项，就新建一个：1234567名称： CPU $2 time类型：Zabbix 客户端键值：system.cpu.util[,idle]信息类型：浮点数单位：%更新间隔：1m自定义时间间隔：灵活 保存即可 添加触发器添加完监控项之后，就要为该监控项添加触发器，当达到设定的阈值时，报警。配置-模板-找到Template OS Linux，点击触发器，创建新触发器。测试想要监控服务器的空闲CPU，当空闲CPU小于50%，时就会告警（为了效果明显，设大点。。）触发器信息如下：123名称：CPU usr% gt 50%严重性：严重表达式：&#123;Template OS Linux:system.cpu.util[,idle].avg(1m)&#125;&lt;50（表达式可以自己写，也可以用构造器，格式挺简单） 其他默认即可 添加图形为了方便观察，添加一个cpu空闲率的图形：配置-模板-选择Template OS Linux-图形，创建图形；1234名称：CPU空闲百分比纵轴Y最小值MIN：可计算的纵轴最大值：可计算的监控项：Template OS Linux：CPU idle time 保存，完成。可以试验下：1echo &quot;scale=5000; 4*a(1)&quot; | bc -l -q 计算圆周率后5000位，手工在服务器top可以看到cpu使用率到80%以上（小破虚拟机，纯试验用，1C），在监测中-仪表板-问题可以看见该问题告警。 邮件配置sendmail邮件发送需要安装几个小工具（可能本地装系统就已经装完了）12yum -y install sendmailsystemctl start sendmail.service mailx安装邮件发送工具1yum -y install mailx 配置zabbix服务外部邮箱编辑文件/etc/mail.rc（没有就新建），添加以下内容(以163邮箱为例)：12345set from=xxx@163.com #邮箱账号set smtp=smtp.163.com #smtp服务器set smtp-auth-user=xxx@163.com #邮箱帐号set smtp-auth-password=xxx #邮箱密码(163邮箱密码是你客户端登录的密码，不是mail.163.com登录的密码)set smtp-auth=login 配置完成，测试一下：1echo &quot;zabbix test...&quot; |mail -s &quot;zabbixssss&quot; xxx@163.com 进入邮箱，可以看见收到一封测试邮件~ 文件发送脚本zabbix提供了几种方式来发送告警信息，这边选择用脚本，在zabbix_server.conf文件中有定义脚本保存路径，例如我的测试服务器上的/etc/zabbix_server.conf中大约在第490行有定义（你也可以注释掉，自己加）:AlertScriptsPath=/usr/lib/zabbix/alertscripts 进入/usr/lib/zabbix/alertscripts文件夹，创建邮件发送脚本sendmail.sh，内容如下：1234#!/bin/bashmessages=`echo $3 | tr &apos;\r\n&apos; &apos;\n&apos;`subject=`echo $2 | tr &apos;\r\n&apos; &apos;\n&apos;`echo &quot;$&#123;messages&#125;&quot; | mail -s &quot;$&#123;subject&#125;&quot; $1 &gt;&gt;/tmp/sendmail.log 2&gt;&amp;1 需要注意的是/tmp/sendmail.log这个日志文件，需要有写和执行的权限，如果不放心，直接chmod 777 /tmp/sendmail.log即可。 可以用脚本测试一下邮件发送：sh sendmail.sh xxxx@163.com &quot;zabbix cesscdssss&quot; &quot;这是内容。。。&quot; 告警设置报警媒介类型进入zabbix web，管理-报警媒介类型，点击创建媒体类型，内容如下：12345678名称： sendmail类型：脚本脚本名称：sendmail.sh脚本参数： &#123;ALERT.SENDTO&#125;&#123;ALERT.SUBJECT&#125;&#123;ALERT.MESSAGE&#125;勾选已启用 点击新增。 用户添加媒介管理-用户，可以使用原来的管理员账号，也可以创建一个用户：12别名：user群组：zabbix administrators 报警媒介，点击添加：1234类型：sendmail收件人：xxxx@163.com当启用时：1-7,00:00-24:00（24小时全年无休~）剩下全勾上结束 点击添加，保存用户。 创建动作配置-动作，创建动作：动作：1名称：自己起，monitor cpu 操作：123456789101112默认操作步骤持续时间：1h默认标题：故障&#123;TRIGGER.STATUS&#125;,服务器:&#123;HOSTNAME1&#125;发生: &#123;TRIGGER.NAME&#125;故障!消息内容：告警主机:&#123;HOSTNAME1&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY1&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;当前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE1&#125;事件ID:&#123;EVENT.ID&#125;操作，新增发送消息给用户，选择之前创建的user，点击新增 恢复操作（系统恢复之后的邮件提示）：1234567891011默认标题：恢复&#123;TRIGGER.STATUS&#125;, 服务器:&#123;HOSTNAME1&#125;: &#123;TRIGGER.NAME&#125;已恢复!消息内容：告警主机:&#123;HOSTNAME1&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY1&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;当前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE1&#125;事件ID:&#123;EVENT.ID&#125;操作，添加发送消息给用户，选择创建的user，点击新增 这样就完工了！！！ 测试在服务器，执行：1echo &quot;scale=10000; 4*a(1)&quot; | bc -l -q 配置的邮箱就会收到邮件告警：12345678910故障PROBLEM,服务器:Zabbix server发生: CPU user% gt 50故障!告警主机:Zabbix server 告警时间:2018.06.28 10:23:19告警等级:High告警信息: CPU user% gt 50告警项目:system.cpu.util[,idle]问题详情:CPU idle time:3.64 %当前状态:PROBLEM:3.64 %事件ID:110 在报表-动作日志，可以看见报警日志；服务器恢复之后，会收到恢复的邮件：12345678910恢复OK, 服务器:Zabbix server: CPU user% gt 50已恢复!告警主机:Zabbix server告警时间:2018.06.28 10:23:19告警等级:High告警信息: CPU user% gt 50告警项目:system.cpu.util[,idle]问题详情:CPU idle time:90.08 %当前状态:OK:90.08 %事件ID:110 参考链接 zabbix配置监控项，触发器zabbix3.2.6部署邮件报警]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>zabbix3.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix3.4监控linux内存]]></title>
    <url>%2F2018%2F06%2F27%2Fzabbix3-4%E7%9B%91%E6%8E%A7linux%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[zabbix3.4监控linux内存情况 linux内存在linux下命令行可以直接获取当前系统的内存信息：1cat /proc/meminfo 展示如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445MemTotal: 997948 kBMemFree: 82436 kBMemAvailable: 122756 kBBuffers: 0 kBCached: 155512 kBSwapCached: 62072 kBActive: 352832 kBInactive: 354784 kBActive(anon): 271604 kBInactive(anon): 284732 kBActive(file): 81228 kBInactive(file): 70052 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 2097148 kBSwapFree: 1329916 kBDirty: 12 kBWriteback: 0 kBAnonPages: 503976 kBMapped: 34672 kBShmem: 4232 kBSlab: 81628 kBSReclaimable: 33496 kBSUnreclaim: 48132 kBKernelStack: 8432 kBPageTables: 43468 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 2596120 kBCommitted_AS: 10619316 kBVmallocTotal: 34359738367 kBVmallocUsed: 190780 kBVmallocChunk: 34359310332 kBHardwareCorrupted: 0 kBAnonHugePages: 38912 kBCmaTotal: 0 kBCmaFree: 0 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 89984 kBDirectMap2M: 958464 kB zabbix自定义监控项zabbix在/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf中增加监控内存的item：12# 获取内存UserParameter=memory.usage[*],/bin/cat /proc/meminfo | awk &apos;/^$1:/&#123;print $$2&#125;&apos; 重启zabbix-agent：systemctl restart zabbix-agent使用zabbix_get查看数据：1zabbix_get -s 192.168.85.132 -k memory.usage[Active] 可以获取到当前active内存：12[root@localhost zabbix_agentd.d]# zabbix_get -s 192.168.85.132 -k memory.usage[Active]337468 zabbix web配置进入zabbix web页面，配置-模板，创建模板，创建一个linux meninfo的模板，群组选择Linux servers;点击监控项，创建该模板下面的监控项，示例：12345名称：Meminfo Active memory类型：Zabbix 客户端键值：memory.usage[Active]信息类型：数值（无正负）更新间隔：1m 类似的创建几个你需要关注的监控项；点击图形，创建图形，输入图形名称，添加监控项，完成。 添加模板配置-主机，选择主机，点击模板，在链接指示器中搜索上步创建的模板，点击添加，点击更新。监测中-最新数据，可以查看到前面创建的监控项的最新数据；检测中-图形，图形选择创建的图形，可以看见实时的内存信息。]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>zabbix3.4</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix3.4监控mysql5.7]]></title>
    <url>%2F2018%2F06%2F27%2Fzabbix3-4%E7%9B%91%E6%8E%A7mysql5-7%2F</url>
    <content type="text"><![CDATA[zabbix3.4监控mysql5.7 zabbix_agent尝试使用zabbix3.4监控mysql5.7，首先需要在mysql所在服务器，安装agent，安装方法很简单：1yum -y install zabbix-agent 安装完成之后在本地服务器下会有zabbix-agent的配置相关生成（本地测试用的centos7，生成目录在/etc/zabbix下） 配置MySQL首先，为了避免接下来可能出现的把数据库账号密码写死在命令行中的情况，可以先在MySQL配置文件中配置一下，/etc/my.cnf文件中新增配置：123[mysqladmin] user=zabbixpassword=11111 这样在执行/usr/bin/mysqladmin -uuser -ppwd -Pport -hhost ping时候就不用加上用户名密码了，由于zabbix-agent也是安装在本机，所以该命令在配置完mysql账密之后可以简化为mysqladmin ping 配置zabbix-agentzabbix_agentd.conf配置zabbix-agent的文件是/etc/zabbix/zabbix_agentd.conf，所有需要的修改都在这里面执行，列一下可能用到的修改项：12345Server=192.168.85.132(大约97行)ServerActive=192.168.85.132（大约138行）Hostname=Zabbix server（大约149行）Include=/etc/zabbix/zabbix_agentd.d/*.conf（大约269行（如果是注释状态，释放即可））UnsafeUserParameters=1（大约288行，默认是0，修改为1） userparameter_mysql.conf在上步Include=/etc/zabbix/zabbix_agentd.d/*.conf释放之后，zabbix-agent可以从指定的文件夹（zabbix_agentd.d）中读取配置，该文件夹中默认就有userparameter_mysql.conf文件，里面就是zabbix用到的监控的item（监控项），每个监控项写一行，创建监控项格式：123UserParameter=&lt;key&gt;,&lt;shell command&gt;或者 UserParameter=&lt;key&gt;,&lt;script dir&gt; 示例：12UserParameter=mysql.version,mysql -VUserParameter=mysql.status[*],/etc/zabbix/script/mysql/chk_mysql.sh $1 第一条item，key是mysql.version，意思就是这是监控MySQL版本的一个item，后面的mysql -V是具体执行的shell命令，通过执行该命令获取MySQL的版本；第二个item，key是mysql.status[*]，意思是该监控项监控的是，mysql的状态，通过执行/etc/zabbix/script/mysql/chk_mysql.shshell 脚本来获取MySQL的各状态。 附上我的userparameter_mysql.conf配置（网上一堆这样的配置，我也是参考的）123UserParameter=mysql.version,mysql -VUserParameter=mysql.status[*],/etc/zabbix/script/mysql/chk_mysql.sh $1UserParameter=mysql.ping,mysqladmin ping | grep -c alive chk_mysql.sh上步，配置项中配置的是脚本文件的，就是将获取监控项的各个脚本写在一个文件中，避免userparameter_mysql.conf文件太杂太乱，如上步配置的，获取MySQL状态的脚本是/etc/zabbix/script/mysql/chk_mysql.sh默认安装的zabbix是没有该文件的，需要手动创建mkdir -p /etc/zabbix/script/mysql,cd /etc/zabbix/script/mysql,vim chk_mysql.sh完成创建脚本，编辑，附上我的脚本（来自互联网）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#!/bin/bash# -------------------------------------------------------------------------------# FileName: check_mysql.sh# Revision: 1.0# Date: 2018/06/20# Author: kyle# Email: # Website: # Description: # Notes: ~# -------------------------------------------------------------------------------# Copyright: # License: GPL# 主机地址/IPMYSQL_HOST=&apos;192.168.85.132&apos;# 端口MYSQL_PORT=&apos;3306&apos;# 数据连接MYSQL_CONN=&quot;/usr/bin/mysqladmin&quot;# 参数是否正确if [ $# -ne &quot;1&quot; ];then echo &quot;arg error!&quot; fi# 获取数据case $1 in Uptime) result=`$&#123;MYSQL_CONN&#125; status|cut -f2 -d&quot;:&quot;|cut -f1 -d&quot;T&quot;` echo $result ;; Com_update) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_update&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Slow_queries) result=`$&#123;MYSQL_CONN&#125; status |cut -f5 -d&quot;:&quot;|cut -f1 -d&quot;O&quot;` echo $result ;; Com_select) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_select&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Com_rollback) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_rollback&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Questions) result=`$&#123;MYSQL_CONN&#125; status|cut -f4 -d&quot;:&quot;|cut -f1 -d&quot;S&quot;` echo $result ;; Com_insert) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_insert&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Com_delete) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_delete&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Com_commit) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_commit&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Bytes_sent) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Bytes_sent&quot; |cut -d&quot;|&quot; -f3` echo $result ;; Bytes_received) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Bytes_received&quot; |cut -d&quot;|&quot; -f3` echo $result ;; Com_begin) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_begin&quot;|cut -d&quot;|&quot; -f3` echo $result ;; *) echo &quot;Usage:$0(Uptime|Com_update|Slow_queries|Com_select|Com_rollback|Questions|Com_insert|Com_delete|Com_commit|Bytes_sent|Bytes_received|Com_begin)&quot; ;;esac 脚本其实很简单，通过mysqladmin获取MySQL自带的计数器数值即可~ zabbix-server进入zabbix web页面，Configuration-Hosts，选择主机，打开主机的配置页面，选择Templates（模板），在Link new templates栏输入MySQL，在跳转出的模板中选择Template DB MySQL，点击add，完成模板配置，然后回到服务器，重启agent端：1systemctl restart zabbix-agent 测试数据获取：1zabbix_get -s yourHostIp -k mysql.status[Com_insert] 可以成功获取到数据。 图形查看返回zabbix web端，在Monitoring-Graphs下可以看见配置完成的监控项的实时图形。 可能遇到的问题以下是可能会遇见的问题： Using a password on the command line interface can be insecure.首先是这个[warning]，这是因为在命令行中写死了数据库的用户名和密码，所以有这个不安全的提示；解决办法，只需要将数据库的账密添加到/etc/my.cnf中，并且在命令行中去掉账密即可。 2539” of type “string”: cannot convert value to numeric type这个问题，很明显，是字符格式的问题，shell脚本获取的监控项数据，设置的为string类型，但是选择的zabbix绘图要求的item的数据类型是numeric类型，只要转换下格式即可；解决办法，Configuration-Templtes，点击items，跳转到item页面，选择item，点击开，编辑类型Type of information；具体的类型可以先通过Configuration-Templtes-Graphs查看。]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>zabbix3.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix配置]]></title>
    <url>%2F2018%2F06%2F26%2Fzabbix%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[zabbix的一些常用配置 zabbix-agent首先，安装完zabbix-web之后，想要监控系统，还需要在系统安装一个agent端：1yum -y install zabbix-agent 命令行安装即可，安装完成之后，可以在本地服务器下找到配置文件，我的是在:/etx/zabbix在：12zabbix_agentd.confzabbix_agentd.d 其中zabbix_agentd.d是文件夹，里面是具体的监控配置文件userparameter_mysql.conf，这个文件里面就是一系列zabbix可用的监控指标的配置，这个后面再专门写写zabbix的配置。 zabbix_getzabbix有个工具：zabbix_get，可以用来获取监控指标，用法示例：1zabbix_get -s IP -k mysql.status[Com_insert] 上面这条命令在配置文件配置完成的情况下，可以用来获取服务器上MySQL执行的insert数量。 图像乱码问题在第一次使用zabbix，图形显示，中文是一个个的方框，也就是乱码，这是因为zabbix的汉化不是很完全，可以手工替换字体来解决乱码问题。首先在本地windows机器下拿到中文字体，例如楷体:simkai.ttf(文件路径：C:\Windows\Fonts)然后把windows上下载完成的字体上传到zabbix服务器中，路径：/usr/share/zabbix/fonts该目录下本来有一个系统字体，并且软链接到zabbix-web，也就是页面显示的字体，现在要做的就是用自己上传的楷体替换到系统原来的字体123[root@localhost fonts]# lltotal 11512lrwxrwxrwx. 1 root root 33 Jun 26 15:46 graphfont.ttf -&gt; /etc/alternatives/zabbix-web-font 首先是将系统原字体备份mv graphfont.ttf graphfont.ttf.back然后修改配置文件/usr/share/zabbix/include/defines.inc.php将文件中的FONT_NAME从原来的graphfont修改为simkai，一共有两处，修改完成之后页面上就可以看见乱码解决了~ （关于zabbix的东西，后面肯定是要写一个监控配置的，待续~~~）]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>zabbix3.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机基础知识系列（一）]]></title>
    <url>%2F2018%2F06%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[程序员基础，性能测试需要知道的一些底层概念（一） 进程、线程、程序对操作系统来说，线程是最小的执行单元，进程是最小的资源管理单元，线程和进程都是由系统内核管理。 进程定义程序被加载到内存中并准备执行，就是一个进程，它是操作系统动态执行的基本单元，在传统的操作系统中，进程既是基本的分配单元，也是基本的执行单元。关于进程有两点需要注意：一、进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量；二、进程是一个“执行中的程序”。程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。 进程状态进程有三个状态，就绪-运行-阻塞。就绪状态其实就是获取除CPU之外的所有资源，只要处理器分配资源就可以马上执行；运行状态就是获取了处理器分配的资源，开始运行程序；阻塞状态，当程序条件不够时，需要等待条件满足才能继续执行，例如I/O。 程序程序其实本身没有任何运行的含义，程序是指令和数据的有序集合。 线程定义单个进程中执行中的每个任务就是一个线程，线程是进程中执行运算的最小单位。一个线程只能属于一个进程，但是一个进程可以拥有多个线程。多线程处理就是允许一个进程中在同一时刻执行多个任务。 进程与线程的区别1，线程没有地址空间，线程包含在进程的地址空间中。线程上下文只包含一个堆栈、一个寄存器、一个优先权，线程文本包含在他的进程的文本片段中。同一进程中的多个线程共享代码段(代码和常量)，数据段(全局变量和静态变量)，扩展段(堆存储)。但是每个线程拥有自己的栈段，寄存器的内容（栈段又叫运行时段，用来存放所有局部变量和临时变量）。2，线程在执行过程中与进程还是有区别的。每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。3，从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。4，线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。（进程就像火车，线程就是火车的车厢） 多进程与多线程多线程多线程，顾名思义，同时运行多个线程；多任务可以由多进程完成，也可以由一个进程内的多线程完成。 线程状态首先，线程大致有五种状态:初始化，就绪，运行，阻塞，死亡； 线程锁在多线程中，每个线程都有自己的资源，但是代码区是共享的，即每个线程都可以执行相同的函数。这可能带来的问题就是几个线程同时执行一个函数，导致数据的混乱，产生不可预料的结果，因此我们必须避免这种情况的发生。例如：有两个线程，同时操作一个列表， 列表中数值都是0，一个线程是更新（update），操作为从前往后顺序更新值为1；线程二为打印（print），操作为从后往前倒序打印列表，当两个线程同时操作列表时就会出现打印时一半0，一半1，出现了数据不同步，为了避免这样的情况，就引进了线程锁的概念。 锁有两种状态——锁定和未锁定。每当一个线程比如”update”要访问共享数据时，必须先获得锁定；如果已经有别的线程比如”print”获得锁定了，那么就让线程”update”暂停，也就是同步阻塞；等到线程”print”访问完毕，释放锁以后，再让线程”update”继续。经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的混乱数据。 线程通信（条件变量）列表并不是一开始就有的；而是通过线程”create”创建的。如果”update”或者”print” 在”create”还没有运行的时候就访问列表，将会出现一个异常。使用锁可以解决这个问题，但是”update”和”print”将需要一个无限循环——他们不知道”create”什么时候会运行，让”create”在运行后通知”update”和”print”显然是一个更好的解决方案。于是，引入了条件变量。 条件变量允许线程比如”update”和”print”在条件不满足的时候（列表为None时）等待，等到条件满足的时候（列表已经创建）发出一个通知，告诉”update” 和”print”条件已经有了，你们该起床干活了；然后”update”和”print”才继续运行。 线程运行和阻塞状态转换阻塞有三种状态：同步阻塞（锁定池）是指处于竞争锁定的状态，线程请求锁定时将进入这个状态，一旦成功获得锁定又恢复到运行状态；等待阻塞（等待池）是指等待其他线程通知的状态，线程获得条件锁定后，调用“等待”将进入这个状态，一旦其他线程发出通知，线程将进入同步阻塞状态，再次竞争条件锁定；而其他阻塞是指调用time.sleep()、anotherthread.join()或等待IO时的阻塞，这个状态下线程不会释放已获得的锁定。 多进程为啥会想看多进程这么个东西，那是因为，python说实话，有点坑的地方是，实质上python没有多线程。python虽然可以通过threading模块来实现多线程编程，但是Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。而通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。所以使用python实现并发多线程，不太现实。。 不过即使如此，我们也可以使用多进程来实现多核任务，毕竟当前多核处理器满大街都是。 实现多进程首先，unix中有个fork()函数，这玩意就可以实现多进程，这函数产生的效果就是把当前进程复制一份，普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。 python的os模块封装了fork()，可以很简单就实现创建子进程；但是由于windows系统没有fork()，在windows上就不能执行包含fork()调用的脚本，在windows上就用multiprocessing替代。 multiprocessing 示例使用multiprocessing模块进行多进程编程，可以支持跨平台。123456789101112131415161718192021222324252627#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@Auther Kyle@Time 2018/6/19 13:10&quot;&quot;&quot;from multiprocessing import Poolimport os, time, randomdef LongTimeTask(name): print(&quot;Run task&#123;0&#125; &#123;1&#125;&quot;.format(name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print(&quot;Task &#123;0&#125; runs &#123;1&#125; seconds.&quot;.format(name, (end - start)))if __name__ == &apos;__main__&apos;: print(&quot;Parent process &#123;0&#125;&quot;.format(os.getpid())) p = Pool(4) for i in range(5): p.apply_async(LongTimeTask, args=(i, )) print(&quot;Waiting for all subprocesses done...&quot;) p.close() p.join() print(&quot;All subprocess done&quot;) 执行结果：12345678910111213Parent process 1692Waiting for all subprocesses done...Run task0 4464Run task1 5516Run task2 2388Run task3 8540Task 3 runs 0.22301292419433594 seconds.Run task4 8540Task 1 runs 0.463026762008667 seconds.Task 2 runs 1.3660781383514404 seconds.Task 4 runs 1.2180695533752441 seconds.Task 0 runs 1.7631008625030518 seconds.All subprocess done 进程间通信multiprocessing提供多种方法来交换数据：Queue，Pipes等。代码示例:12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@Auther Kyle@Time 2018/6/19 14:56&quot;&quot;&quot;from multiprocessing import Process, Queueimport os, time, randomdef write(q): &quot;&quot;&quot;写数据进程执行&quot;&quot;&quot; print(&quot;Process to write: &#123;0&#125;&quot;.format(os.getpid())) for value in [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;]: print(&quot;Put &#123;0&#125; to queue.&quot;.format(value)) q.put(value) time.sleep(random.random())def read(q): &quot;&quot;&quot;读数据进程执行&quot;&quot;&quot; print(&quot;Process to read: &#123;0&#125;&quot;.format(os.getpid())) while True: value = q.get(True) print(&quot;Get &#123;0&#125; from queue.&quot;.format(value))if __name__ == &apos;__main__&apos;: # 父进程创建Queue，传给各个子进程 q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入 pw.start() # 启动子进程pr，读取 pr.start() # 等待写进程执行结束 pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止 pr.terminate() 运行结果：12345678Process to read: 7616Process to write: 4948Put A to queue.Get A from queue.Put B to queue.Get B from queue.Put C to queue.Get C from queue. 以上代码均来自于网络~ 协程协程，又称微线程，英文Coroutines，是一种比线程更加轻量级的存在。正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。（关于协程，真的不太懂，之后有空再研究，看到一句话:子程序就是协程的一种特例）多线程编程中，为了防止数据不同步，需要添加锁机制，但是协程应为就用了一个线程，在协程之间共享资源是不用加锁机制的，只需要判断状态。 参考链接 廖雪峰关于多进程教程Python线程指南廖雪峰-协程教程]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>进程</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下切换MySQL数据到数据盘]]></title>
    <url>%2F2018%2F06%2F12%2FCentos%E4%B8%8B%E5%88%87%E6%8D%A2MySQL%E6%95%B0%E6%8D%AE%E5%88%B0%E6%95%B0%E6%8D%AE%E7%9B%98%2F</url>
    <content type="text"><![CDATA[centos 7对ECS进行挂载数据盘，并切换MySQL数据保存目录到数据盘 测试需要，申请了阿里云的ECS服务器，用来搭建MySQL，搭建时候没有注意，没想到运维大哥那么体贴的申请了数据盘，还是SSD的，这样也就需要把原来MySQL数据存储路径换到数据盘。 操作数据盘首先查看当前服务器是否有数据盘：fdisk -l1234567891011121314Disk /dev/vda: 53.7 GB, 53687091200 bytes, 104857600 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x0008d73a Device Boot Start End Blocks Id System/dev/vda1 * 2048 104855551 52426752 83 LinuxDisk /dev/vdb: 107.4 GB, 107374182400 bytes, 209715200 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes 可以看到当前服务上面有两个盘/dev/vda和/dev/vdb，其中/dev/vda是系统盘，并且已经有分区/dev/vda1，经常使用的查看磁盘的命令是df -h，但是有个问题，如果你的数据盘没有分区、挂载，使用df -h是不会显示的，只会展示这样：1234567Filesystem Size Used Avail Use% Mounted on/dev/vda1 50G 3.1G 44G 7% /devtmpfs 16G 0 16G 0% /devtmpfs 16G 0 16G 0% /dev/shmtmpfs 16G 520K 16G 1% /runtmpfs 16G 0 16G 0% /sys/fs/cgrouptmpfs 3.2G 0 3.2G 0% /run/user/0 数据盘分区查找到数据盘/dev/vdb之后，对它进行分区：fdisk /dev/vdb，1234567Welcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition tableBuilding a new DOS disklabel with disk identifier 0x39e32289. 接下来是有几个选项，选择适合的选项即可：12345Command (m for help): 输入&apos;n&apos;，创建一个新分区Partition type: 输入&apos;p&apos;，选择主分区Partition number (1-4, default 1): 输入&apos;1&apos;，仅创建一个分区First sector (2048-209715199, default 2048): 我用的默认Last sector, +sectors or +size&#123;K,M,G&#125; (2048-209715199, default 209715199): 同样默认 接下来wq保存退出即可。然后这个时候fdisk -l，就能看见新的分区：12345678910111213141516171819Disk /dev/vda: 53.7 GB, 53687091200 bytes, 104857600 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x0008d73a Device Boot Start End Blocks Id System/dev/vda1 * 2048 104855551 52426752 83 LinuxDisk /dev/vdb: 107.4 GB, 107374182400 bytes, 209715200 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x39e32289 Device Boot Start End Blocks Id System/dev/vdb1 2048 209715199 104856576 83 Linux 格式化分区首先新建文件夹：cd /home、mkdir mysql挂载：mount /dev/vdb1 /home/mysql在新分区上创建文件系统：mkfs.ext4 /dev/vdb1备份/etc/fstab：cp /etc/fstab /etc/fstab.bak查找当前磁盘分区的UUID：blkid向 /etc/fstab 写入新分区信息:vim /etc/fstab，写入UUID=ec7443b1-14e4-4174-ae8a-2194484a754b /home/mysql ext4 defaults 0 0(UUID是之前获得的) 复制MySQL数据复制数据：mv /var/lib/mysql/* /home/mysql修改配置：vim /etc/my.cnf，修改数据文件到/home/mysql重启MySQLOVER~]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用fiddler抓iphone包]]></title>
    <url>%2F2018%2F06%2F07%2F%E4%BD%BF%E7%94%A8fiddler%E6%8A%93iphone%E5%8C%85%2F</url>
    <content type="text"><![CDATA[使用fiddler抓包iphone 亲测可用，系统及版本：12Fiddler: Telerik Fiddler Web Debugger (v2.6.3.48898)iphone 6s(ios 11.3.1) Fiddler设置首先，需要设置下fiddler，至于fiddler的下载安装就不说了。 配置监听https需要配置fiddler，使得允许监听https，因为fiddler默认是抓http格式的。(再次声明，受不了七牛云之类的手持身份证实名认证的措施，由于之前工作做过征信相关，对这方面有点在乎，能少泄露一点就少一点。。。所以，基本blog中一直是无图片~)1Tools ——&gt; （Telerik）Fiddler Options ——&gt; https 勾选Decrypt Https traffic，此时系统会提示你是否要安装fiddler的证书之类的，安装一下即可~ 远程连接配置配置完https之后，需要设置允许远程连接，还是在Tools ——&gt; （Telerik）Fiddler Options选择Connections，监听端口使用默认的8888即可，勾选Allow remote computers to connect，此时会弹出一个warning，提示你会开启远程连接，并且需要重启fiddler才会生效，点击确定即可； 重启fiddler iphone设置获取PC端ip这个就比较简单了，cmd ——&gt; ipconfig拿到ip即可，例如192.168.100.10 iphone安装证书首先确保手机和PC处于同一网络（直接连接同一wifi最简单），然后在手机浏览器中输入上述步骤获取的ip和端口1http://192.168.100.10:8888 页面会出现Fiddler Echo Service该页面，看到一条You can download the FiddlerRoot certificate，点击下载证书，然后信任安装证书即可（安装完的证书可以在iphone-设置-通用-描述文件中看到）（证书名字，我当时装的时候叫DO_NOT_TRUST_FiddlerRoot） 设置代理安装完成证书，进入手机设置-无限局域网，选择连接的wifi，配置代理选择手动，输入服务器，端口，点击存储。完成~ 抓包手机浏览器访问页面，可以使用fiddler抓到包，看到请求和返回~以下抓到的示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697HTTP/1.1 200 OKServer: nginxDate: Thu, 07 Jun 2018 03:07:22 GMTContent-Type: text/html; charset=UTF-8Connection: keep-aliveVary: Accept-EncodingX-Powered-By: PHP/7.1.5Set-Cookie: upv2=20180607%2C4; expires=Sat, 09-Jun-2018 03:07:22 GMT; Max-Age=172800; path=/Content-Length: 7346&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh-CN&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;古墓丽影：源起之战迅雷下载,百度网盘,高清迅雷下载 - 97电影网&lt;/title&gt;&lt;meta name=&quot;keywords&quot; content=&quot;古墓丽影：源起之战迅雷下载,古墓丽影：源起之战百度网盘资源,古墓丽影：源起之战高清迅雷下载 - 97电影网&quot; /&gt;&lt;meta name=&quot;description&quot; content=&quot;这里有电影《古墓丽影：源起之战》的百度网盘资源，还有《古墓丽影：源起之战》的迅雷下载链接,演员：艾丽西亚·维坎德,多米尼克·威斯特,沃尔顿·戈金斯,吴彦祖,克里斯汀·斯科特·托马斯,汉娜·乔恩-卡门,尼克·弗罗斯特,德里克·雅各比,安东尼奥·阿克儿,亚历山大·维尧姆,杰美·温斯顿,迈克尔·奥拜奥拉,艾米丽·凯里,肯尼思·霍&quot; /&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no&quot;&gt; &lt;link rel=&quot;icon&quot; href=&quot;http://www.id97.com/favicon.ico&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/amazeui.min.css&quot;&gt; &lt;script src=&quot;http://libs.baidu.com/jquery/1.7.2/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/static/js/amazeui.min.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; rev=&quot;stylesheet&quot; type=&quot;text/css&quot; media=&quot;all&quot; href=&quot;http://www.id97.com/static/mobile/mobile.css&quot;&gt; &lt;!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn&apos;t work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src=&quot;http://cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;http://cdn.bootcss.com/respond.js/1.4.2/respond.min.js&quot;&gt;&lt;/script&gt; &lt;![endif]--&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;am-topbar-inverse&quot;&gt; &lt;header class=&quot;am-container&quot;&gt; &lt;h1 class=&quot;am-topbar-brand&quot;&gt; &lt;a href=&quot;http://www.id97.com/&quot;&gt;97电影网&lt;/a&gt; &lt;/h1&gt; &lt;button class=&quot;am-topbar-btn am-topbar-toggle am-btn am-btn-sm am-btn-success am-show-sm-only&quot; data-am-collapse=&quot;&#123;target: &apos;#doc-topbar-collapse&apos;&#125;&quot;&gt;&lt;span class=&quot;am-sr-only&quot;&gt;97电影网&lt;/span&gt; &lt;span class=&quot;am-icon-bars&quot;&gt;&lt;/span&gt;&lt;/button&gt; &lt;div class=&quot;am-collapse am-topbar-collapse&quot; id=&quot;doc-topbar-collapse&quot;&gt; &lt;ul class=&quot;am-nav am-nav-pills am-topbar-nav&quot;&gt; &lt;li&gt;&lt;a href=&quot;http://www.id97.com/&quot;&gt;首页&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.id97.com/movie&quot;&gt;电影&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&quot;am-topbar-right&quot;&gt; &lt;form action=&quot;/search&quot; method=&quot;GET&quot; class=&quot;am-topbar-form am-topbar-left am-form-inline&quot; role=&quot;search&quot;&gt; &lt;div class=&quot;am-form-group&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;am-form-field am-input-sm&quot; name=&quot;q&quot; placeholder=&quot;搜索&quot;&gt; &lt;/div&gt; &lt;/form&gt; &lt;div class=&quot;am-dropdown&quot; data-am-dropdown=&quot;&#123;boundary: &apos;.am-topbar&apos;&#125;&quot;&gt; &lt;button class=&quot;am-btn am-btn-secondary am-topbar-btn am-btn-sm am-dropdown-toggle&quot; data-am-dropdown-toggle&gt;登入/注册 &lt;span class=&quot;am-icon-caret-down&quot;&gt;&lt;/span&gt;&lt;/button&gt; &lt;ul class=&quot;am-dropdown-content&quot;&gt; &lt;li&gt;&lt;a href=&quot;/signup&quot;&gt;注册&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/signin&quot;&gt;登入&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/header&gt;&lt;/div&gt;&lt;div class=&quot;am-container&quot;&gt; &lt;h3 class=&quot;am-article-title&quot;&gt; 古墓丽影：源起之战 &lt;/h3&gt; &lt;div class=&quot;am-g&quot;&gt; &lt;div class=&quot;am-u-sm-5&quot;&gt;&lt;img class=&quot;img-responsive&quot; width=&quot;100%&quot; src=&quot;http://img1.xmspc.com/uploads/movie-poster/8ltxwirll3g7.jpg&quot;&gt;&lt;/div&gt; &lt;div class=&quot;am-u-sm-7&quot; style=&quot;padding-left:0;font-size:14px;color:#666;&quot;&gt;&lt;strong&gt;主演：&lt;/strong&gt;艾丽西亚·维坎德 / 多米尼克·威斯特 / 沃尔顿·戈金斯 ...&lt;br/&gt;&lt;strong&gt;类型：&lt;/strong&gt;动作 / 冒险&lt;br/&gt;&lt;strong&gt;上映：&lt;/strong&gt;2018-03-16(美国/中国大陆)&lt;br/&gt;&lt;strong&gt;豆瓣：&lt;/strong&gt;6.3分&lt;br/&gt; &lt;/div&gt; &lt;div class=&quot;am-u-sm-12&quot; style=&quot;padding-top:15px;font-size:14px;color:#666;&quot;&gt;&lt;strong&gt;简介：&lt;/strong&gt;劳拉（艾丽西亚·维坎德 Alicia Vikander 饰）的父亲一生都致力于研究古墓，在劳拉尚且年幼的时候，父亲在一场冒险之中失踪了。一晃眼多年过去，劳拉一直拒绝承认父亲已死的消息，也拒绝接手父亲手下的商业帝国。&lt;br /&gt;一次偶然中，劳拉发现了父亲遗留下的冒险笔记，父亲希望劳拉能把这些资料付之一炬，但为了寻找父亲的下落，劳拉决定寻找笔记中记载的岛屿。劳拉找到了名为陆仁（吴彦祖 饰）的男子，两人结伴踏上了旅途。刚一上岛，劳拉和陆仁就遇见了一直和父亲作对的马赛亚斯（沃特·戈金斯 Walton Goggins 饰）以及他的雇佣兵团队。马赛亚斯一心想要找到古墓的踪迹，不惜杀死了不肯透露半点消息的劳拉的父亲，如今，劳拉亦落入了他的魔爪之中，会遭遇怎样的命运呢？&lt;/div&gt; &lt;/div&gt; &lt;h3 class=&quot;res-h3&quot;&gt;资源列表：&lt;/h3&gt; &lt;ul class=&quot;am-list res-list&quot;&gt;&lt;li class=&quot;list-group-item&quot;&gt;&lt;/li&gt;&lt;li&gt;&lt;p class=&quot;text-break&quot; style=&quot;margin:0;&quot;&gt;&lt;a href=&quot;https://pan.baidu.com/s/14V_KvaJcMIzwY3Octe4WDQ&quot;&gt;古墓丽影：源起之战 - 百度云，网盘资源，密码：3xvh&lt;/a&gt;&lt;/p&gt;&lt;textarea style=&quot;width:100%;&quot;&gt;https://pan.baidu.com/s/14V_KvaJcMIzwY3Octe4WDQ&lt;/textarea&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;p class=&quot;text-break&quot; style=&quot;margin:0;&quot;&gt;&lt;a href=&quot;ed2k://|file|%E5%8F%A4%E5%A2%93%E4%B8%BD%E5%BD%B1.%E6%BA%90%E8%B5%B7%E4%B9%8B%E6%88%98.Tomb.Raider.2018.HD1080P.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97.mp4|2207922795|225513B29378FAEC5871822A46DE2F8D|h=NEFWJ3E5TL6ALZV2O63HVU5GALU6IGBI|/&quot;&gt;古墓丽影.源起之战.Tomb.Raider.2018.HD1080P.中英双字.mp4&lt;/a&gt;&lt;/p&gt;&lt;textarea style=&quot;width:100%;&quot;&gt;ed2k://|file|%E5%8F%A4%E5%A2%93%E4%B8%BD%E5%BD%B1.%E6%BA%90%E8%B5%B7%E4%B9%8B%E6%88%98.Tomb.Raider.2018.HD1080P.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97.mp4|2207922795|225513B29378FAEC5871822A46DE2F8D|h=NEFWJ3E5TL6ALZV2O63HVU5GALU6IGBI|/&lt;/textarea&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;p class=&quot;text-break&quot; style=&quot;margin:0;&quot;&gt;&lt;a href=&quot;ed2k://|file|%E5%8F%A4%E5%A2%93%E4%B8%BD%E5%BD%B1.%E6%BA%90%E8%B5%B7%E4%B9%8B%E6%88%98.Tomb.Raider.2018.HD720P.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97.mkv|1574630029|9D61330E39013720310FD4FBE83807FB|h=35M7EUX7TERZMN4QCYGSWIGC7F5JS4ZV|/&quot;&gt;古墓丽影.源起之战.Tomb.Raider.2018.HD720P.中英双字.mkv&lt;/a&gt;&lt;/p&gt;&lt;textarea style=&quot;width:100%;&quot;&gt;ed2k://|file|%E5%8F%A4%E5%A2%93%E4%B8%BD%E5%BD%B1.%E6%BA%90%E8%B5%B7%E4%B9%8B%E6%88%98.Tomb.Raider.2018.HD720P.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97.mkv|1574630029|9D61330E39013720310FD4FBE83807FB|h=35M7EUX7TERZMN4QCYGSWIGC7F5JS4ZV|/&lt;/textarea&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;footer class=&quot;footer&quot;&gt; &lt;p&gt;免责声明：本网站将逐步删除和规避程序自动搜索采集到的不提供分享的版权影视。本站仅供测试和学习交流。请大家支持正版。&lt;/p&gt; &lt;p&gt;唯一网址：&lt;a href=&quot;http://www.id97.com/&quot;&gt;97电影网&lt;/a&gt;&lt;/p&gt;&lt;/footer&gt;&lt;script src=&quot;https://www.szshouzhai.com/kdksd/c-5270-22.js&quot;&gt;&lt;/script&gt;&lt;script&gt;var _hmt = _hmt || [];(function() &#123; var hm = document.createElement(&quot;script&quot;); hm.src = &quot;https://hm.baidu.com/hm.js?a6cc69b245346a568ba6088ab53ff7ac&quot;; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s);&#125;)();&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; OVER!]]></content>
      <categories>
        <category>just for fun</category>
      </categories>
      <tags>
        <tag>fiddler</tag>
        <tag>iphone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3.6安装basemap]]></title>
    <url>%2F2018%2F06%2F01%2Fpython3-6%E5%AE%89%E8%A3%85basemap%2F</url>
    <content type="text"><![CDATA[python3.6安装basemap 很久没碰matplotlib了，想看看有没有中国地图加人口，这样绘制一张图，找白天，貌似basemap里面有，basemap需要：from mpl_toolkits.basemap import Basemap，然后就尝试安装mpl_toolkits，不出所料，失败了。。。 折腾半天，附上windows下python3.6安装basemap步骤： 下载首先，一个神奇的网站，经常逛： python包下载 下载对应python版本的文件，cp36表示3.6版本： 12basemap‑1.1.0‑cp36‑cp36m‑win_amd64.whl pyproj‑1.9.5.1‑cp36‑cp36m‑win_amd64.whl 安装windows进入cmd模式，进入保存上述俩文件的路径，使用pip安装：12pip install pyproj‑1.9.5.1‑cp36‑cp36m‑win_amd64.whlpip install basemap‑1.1.0‑cp36‑cp36m‑win_amd64.whl 验证打开简单的世界地图：12345678import matplotlib.pyplot as pltfrom mpl_toolkits.basemap import Basemapplt.figure(figsize=(16, 8))m = Basemap()m.drawcoastlines()plt.show()]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】loadrunner请求三种格式API]]></title>
    <url>%2F2018%2F05%2F22%2F%E3%80%90%E8%BD%AC%E3%80%91loadrunner%E8%AF%B7%E6%B1%82%E4%B8%89%E7%A7%8D%E6%A0%BC%E5%BC%8FAPI%2F</url>
    <content type="text"><![CDATA[loadrunner请求API，http POST三种请求格式的脚本 本篇文章主要针对POST请求的三种数据请求格式，组织不同的脚本: （1）、application/x-www-form-urlencoded 键值对 （2）、multipart/form-data 表单 （3）、application/json Json串 PS：loadrunner body参数中的引号，需要自己加\转义。 application/x-www-form-urlencoded 键值对12345678910111213141516171819202122232425262728293031323334353637383940414243444546Action() &#123; lr_start_transaction(&quot;checkPerson&quot;); /* 注册获取返回参数，该方法可以配合打印返回数据，检测数据内容 */ web_reg_save_param(&quot;Para&quot;, &quot;LB=&quot;, &quot;RB=&quot;, LAST); /* 注册断言： Text=断言内容 */ /* 该方法会判断后面的web请求方法的返回值 */ web_reg_find(&quot;Text=成功&quot;, LAST); /* 汉字进行UTF-8编码 */ lr_convert_string_encoding(&quot;需要进行UTF-8加密的中文字符串&quot;,LR_ENC_SYSTEM_LOCALE,LR_ENC_UTF8,&quot;result&quot;); /* 向后面的web请求函数增加请求头 */ /* 如果web请求方法中已经设置了相同的头，则优先使用web请求方法中的头，例如web请求方法中的EncType参数，对应请求投中的Content-Type。由于下面的方法已经设置了EncType参数，所以这里的设置并没有什么X用 */ /* 表单直接使用方法自带参数，键值对和json建议使用该方法 */ web_add_header(&quot;Content-Type&quot;, &quot;application/x-www-form-urlencoded; charset=utf-8&quot;); /* 主要针对form表单和键值对两种格式的web请求 */ web_submit_data(&quot;checkPerson&quot;, &quot;Action=http://130.1.11.105:9080/ibis/faceService/checkPerson&quot;, &quot;Method=POST&quot;, /* 该方法支持常见的两种请求数据格式 */ /* （1）&quot;EncType=multipart/form-data&quot;。form表单提交数据 */ /* （1）&quot;EncType=application/x-www-form-urlencoded&quot;。默认使用键值对提交数据 */ //&quot;EncType=&quot;, &quot;TargetFrame=&quot;, &quot;Referer=&quot;, ITEMDATA, &quot;Name=Name1&quot;, &quot;Value=Value1&quot;, ENDITEM, &quot;Name=Name2&quot;, &quot;Value=Value2&quot;, ENDITEM, LAST); /* 打印相应结果 */ /* lr_eval_string(&quot;&#123;result&#125;&quot;) 使用loadrunner引用外部函数，只有这样才能取出上面web_reg_save_param方法的返回值 */ lr_log_message(lr_eval_string(&quot;&#123;result&#125;&quot;)); lr_end_transaction(&quot;checkPerson&quot;, LR_AUTO); return 0; &#125; multipart/form-data 表单12345678910111213141516171819202122232425262728293031323334353637383940414243444546Action() &#123; lr_start_transaction(&quot;checkPerson&quot;); /* 注册获取返回参数，该方法可以配合打印返回数据，检测数据内容 */ web_reg_save_param(&quot;Para&quot;, &quot;LB=&quot;, &quot;RB=&quot;, LAST); /* 注册断言： Text=断言内容 */ /* 该方法会判断后面的web请求方法的返回值 */ web_reg_find(&quot;Text=成功&quot;, LAST); /* 汉字进行UTF-8编码 */ lr_convert_string_encoding(&quot;需要进行UTF-8加密的中文字符串&quot;,LR_ENC_SYSTEM_LOCALE,LR_ENC_UTF8,&quot;result&quot;); /* 向后面的web请求函数增加请求头 */ /* 如果web请求方法中已经设置了相同的头，则优先使用web请求方法中的头，例如web请求方法中的EncType参数，对应请求投中的Content-Type。由于下面的方法已经设置了EncType参数，所以这里的设置并没有什么X用 */ /* 表单直接使用方法自带参数，键值对和json建议使用该方法 */ //web_add_header(&quot;Content-Type&quot;, // &quot;multipart/form-data; boundary = --------BORN3QKNRTS4; charset=UTF-8&quot;); /* 主要针对form表单和键值对两种格式的web请求 */ web_submit_data(&quot;checkPerson&quot;, &quot;Action=http://130.1.11.105:9080/ibis/faceService/checkPerson&quot;, &quot;Method=POST&quot;, /* 该方法支持常见的两种请求数据格式 */ /* （1）&quot;EncType=multipart/form-data&quot;。form表单提交数据 */ /* （1）&quot;EncType=&quot;。默认使用键值对提交数据 */ &quot;EncType=multipart/form-data&quot;, &quot;TargetFrame=&quot;, &quot;Referer=&quot;, ITEMDATA, &quot;Name=Name1&quot;, &quot;Value=Value1&quot;, ENDITEM, &quot;Name=Name2&quot;, &quot;Value=Value2&quot;, ENDITEM, LAST); /* 打印相应结果 */ /* lr_eval_string(&quot;&#123;result&#125;&quot;) 使用loadrunner引用外部函数，只有这样才能取出上面web_reg_save_param方法的返回值 */ lr_log_message(lr_eval_string(&quot;&#123;result&#125;&quot;)); lr_end_transaction(&quot;checkPerson&quot;, LR_AUTO); return 0; &#125; application/json Json串12345678910111213141516171819202122232425262728293031323334353637383940414243444546Action() &#123; lr_start_transaction(&quot;checkPerson&quot;); /* 注册获取返回参数，该方法可以配合打印返回数据，检测数据内容 */ web_reg_save_param(&quot;Para&quot;, &quot;LB=&quot;, &quot;RB=&quot;, LAST); /* 注册断言： Text=断言内容 */ /* 该方法会判断后面的web请求方法的返回值 */ // web_reg_find(&quot;Text=成功&quot;, // LAST); /* 汉字进行UTF-8编码 */ lr_convert_string_encoding(&quot;需要进行UTF-8加密的中文字符串&quot;,LR_ENC_SYSTEM_LOCALE,LR_ENC_UTF8,&quot;result&quot;); /* 向后面的web请求函数增加请求头 */ /* 如果web请求方法中已经设置了相同的头，则优先使用web请求方法中的头，例如web请求方法中的EncType参数，对应请求投中的Content-Type。由于下面的方法已经设置了EncType参数，所以这里的设置并没有什么X用 */ /* 表单直接使用方法自带参数，键值对和json建议使用该方法 */ web_add_header(&quot;Content-Type&quot;, &quot;application/json; charset=UTF-8&quot;); /* 主要针对form表单和键值对两种格式的web请求 */ web_custom_request(&quot;web_custom_request&quot;, &quot;URL=http://www.baidu.com&quot;, &quot;Method=POST&quot;, &quot;TargetFrame=&quot;, &quot;Resource=0&quot;, &quot;Referer=&quot;, &quot;Mode=HTTP&quot;, /* json和键值对数据格式，建议使用web_add_header方法添加Content-Type头 */ //&quot;EncType=application/json&quot;, &quot;Body=&#123;\&quot;Name1\&quot;:\&quot;Value1\&quot;,\&quot;Name2\&quot;:\&quot;Value2\&quot;&#125;&quot;, LAST); /* 打印相应结果 */ /* lr_eval_string(&quot;&#123;result&#125;&quot;) 使用loadrunner引用外部函数，只有这样才能取出上面web_reg_save_param方法的返回值 */ lr_log_message(lr_eval_string(&quot;&#123;result&#125;&quot;)); lr_end_transaction(&quot;checkPerson&quot;, LR_AUTO); return 0; &#125;]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>loadrunner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】windows性能监控指标]]></title>
    <url>%2F2018%2F05%2F16%2F%E3%80%90%E8%BD%AC%E3%80%91windows%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87%2F</url>
    <content type="text"><![CDATA[使用loadrunner进行性能测试，需要监控服务器，当IIS和sqlserver位于windows服务器时，就需要使用windows自带的性能监控工具进行性能数据收集，之后进行分析，以下为各指标详解： 内存分析内存分析需要使用的计数器：Memory性能对象和Physical Disk性能对象的计数器。内存分析的主要方法和步骤： 查看Memory-&gt;Available Mbytes指标Available Mbytes：描述：Available MBytes 指能立刻分配给一个进程或系统使用的物理内存数量，以 MB 为单位表示。它等于分配给待机(缓存的)、空闲和零分页列表内存的总和。建议指标：该值不宜低于400。一般要保留10%的可用内存，假设系统有8G内存，则该值最好不要低于800M说明：过高说明内存资源即将耗尽，应考虑增加内存如果该指标的数据比较小，系统可能出现了内存方面的问题，需要继续下面步骤进一步分析 注意Memory-&gt;Pages/sec、Memory-&gt;Page Reads/sec和Memory-&gt;Page Fault/sec的值操作系统会利用磁盘较好的方式提高系统可用内存量或者提高内存的使用效率。这三个指标直接反应了操作系统进行磁盘交换的频度 Pages/sec：描述：Pages/sec 是指为解决硬页错误从磁盘读取或写入磁盘的速度。这个计数器是可以显示导致系统范围延缓类型错误的主要指示器。它是 Memory\Pages Input/sec 和 Memory\Pages Output/sec 的总和。是用页数计算的，以便在不用做转换的情况下就可以同其他页计数如: Memory\Page Faults/sec 做比较，这个值包括为满足错误而在文件系统缓存(通常由应用程序请求)的非缓存映射内存文件中检索的页建议指标：该值不宜超过20 说明：此值持续高于几百，说明内存中有很多东西需要与硬盘交换，可能有内存问题，应考虑增加内存或更换内存 Page Fault/sec：说明：每秒发生页面失效次数，页面失效次数越多，说明操作系统向内存读取的次数越多。此时需要查看Page Reads/sec的计数值，该计数器的阀值为5，如果计数值超过5，则可以判断存在内存方面的问题。 根据Physical Disk性能对象的计数器值分析性能瓶颈对Physical Disk计数器对象的分析包括对Page Reads/sec和%Disk Time及Average Disk Queue Length的分析。如果Page Reads/sec很低，同时%Disk Time和Average Disk Queue Length的值很高，则可能有磁盘瓶颈。但是队列长度增加的同时Page Reads/sec并未降低，则是内存不足 内存计数器阀值Memory-&gt;Available Bytes建议的阀值：对于具有较大内存的计算机&gt;=10%可用空间对于较小内存也需要大于4MB空间可用说明：Available Bytes剩余的可用物理内存，单位是兆字节，表明进程当前可使用的内存字节数 Memory-&gt;Pages/sec建议的阀值：Pages/sec&lt;=20说明：操作系统经常会利用磁盘交换的方式提高系统的可用的内存量或是提高内存的使用效率。Pages/sec是指为解决硬页错误从磁盘读取或写入磁盘的速度。这个计数器是可以显示导致系统范围延缓类型错误的主要计数器。它是Memory-&gt;Pages Input/sec和Pages Output/sec的总和。是用页数计算的，以便在不同做转换的情况下就可以同其他页计数，如：Memory-&gt;Pages Fault/sec做比较，这个值包括为错误而在文件系统缓存（通常由应用程序请求）的非缓存映射内存文件中检索的页。如果Pages/sec的值为20或更大，应进一步研究页交换活动。Pages/sec的值很大不一定表明内存有问题，而可能是运行使用内存映射文件的程序所致 Memory-&gt;Page Faults/sec建议的阀值：5说明： Page Fault/secPage Fault/sec值在这个进程中执行线程造成的页面错误出现的速度。当线程引用了不在主内存工作集中的虚拟内存页即会出现Page Fault。如果它在备用表中（即已经在主内存中）或另一个共享页的处理正在使用它，就会无法从磁盘中获取页 Paging File-&gt;%Usage建议的阀值：70%以上说明：与Available Bytes和Pages/sec一起复查该值，了解计算机的页交换活动 CPU监控首先看System-&gt;%Total Processor Time性能计数器的计数值该计数器的值体现服务器整体处理器利用率，对多处理器的系统而言，该计数器提醒所有CPU的平均利用率。如果该值持续超过90%，则说明整个系统面临着处理器方面的瓶颈，需要通过增加处理器来提高性能 %Total Processor Time：描述：% Processor Time 指处理器用来执行非闲置线程时间的百分比。计算方法是，度量处理器用来执行空闲线程的时间，然后用 100% 减去该值。(每个处理器有一个空闲线程，该线程在没有其他线程可以运行时消耗周期)。此计数器是处理器活动的主要指示器，显示在采样间隔期间所观察的繁忙时间平均百分比。应注意，对处理器是否空闲的计算是在系统时钟的内部采样间隔期间(10ms)执行的。考虑到现在的处理器速度非常快，因此，在处理器可能会用大量时间为系统时钟采样间隔之间的线程提供服务时，% Processor Time 会低估处理器利用率。当恰好进行采样后即向计时器发出信号时，更可能对应用程序做出不准确地度量，基于工作负荷的计时器应用程序是一个这样的示例。建议指标：该监控内容不宜超过80%说明：过高说明CPU资源即将耗尽，应增加CPU资源或实施分布式策略 查看每个CPU的Processor-&gt;%Processor Time和Processor-&gt;%UserTime和Processor-&gt;%Privileged TimeProcessor-&gt;%User Time是系统非核心操作消耗的CPU时间，如果该值较大，可以考虑是否能够通过友好算法等方法降低这个值。如果该服务器时数据库服务器，Processor-&gt;%User Time值较大的原因很可能是数据库的排序或是函数操作消耗了过多的CPU时间，此时可以考虑对数据库系统进行优化 研究系统处理器瓶颈查看System-&gt;Processor Queue Length计数器的值，当该计数器的值大于CPU数量的总数+1时，说明产生了处理器阻塞。在处理器的%Process Time很高时，一般都是处理器阻塞，但产生处理器阻塞时，Processor-&gt;%Process Time计数器的值不一定很大，此时就必须查找阻塞的原因 CPU计数器阀值Processor-&gt;%Processor Time建议的阀值：85%说明：查找占用处理器时间高百分比的进程。升级到更快的处理器或安装其他处理器 Processor-&gt;Interrupts/sec建议的阀值：取决于处理器，每秒1000次中断是好的起点说明：此计数器的值是明显增加，而系统活动没有相应的增加则表明存在硬件问题。确定引起中断的网络适配器、磁盘或者其他硬件 Server-&gt;Bytes Total/sec建议的阀值：/说明：如果所有的服务器Bytes Total/sec和与网络的最大传送速度几乎相等，则可能需要将网络分段 Server-&gt;Work Item Shortages建议的阀值：3说明：如果值达到该阀值，请考虑将DWORD项InitWorkItems（在启动期间分配给处理器的工作项数）或者MaxWorkItems（服务器可以分配的接收缓冲区的最大数）添加到注册表（在HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\LanmanServer\Parameters 下面）。项InitWorkItems的范围可以是从1到512，同时MaxWorkItems的范围可以是从1到65535。以InitWorkItems的任何值以及MaxWorkItems的值4096开始，并一直加倍这些值，直到Server-&gt;Work Item Shortages阀值低于3 Server-&gt;Pool Paged Peak建议的阀值：物理RAM的数量说明：此值是最大页面文件大小和物理内存数量的指示器 Server Work Queue-&gt;Queue Length建议的阀值：4说明：如果值达到此阀值，则可能存在处理器瓶颈。这是即时计数器；观察在多个间隔上的值 磁盘监控与Processor-&gt;Privieged Time合并进行分析如果在Physical Disk计数器中，只有%Disk Time比较大，其他值都比较适中，硬盘可能会是瓶颈。若几个值都比较大，且数值持续超过80%，则可能是内存泄露 \PhysicalDisk(_Total)\% Disk Time：描述：Disk Time 指所选磁盘驱动器忙于为读或写入请求提供服务所用的时间的百分比。建议指标：此值不宜超过10说明：此值过高，说明硬盘响应效率较低，应换用更高性能的硬盘 根据Disk Transfers/sec进行分析一般来说，定义该数值小于15ms为优秀，介于15~30ms之间为良好，30~60之间为可接受，超过60ms则需要考虑更换或是硬盘的RAID方式 磁盘计数器阀值 Physical Disk-&gt;%Free Space和Logical Disk-&gt;%Free Space建议的阀值：15% Physical Disk-&gt;%Disk Time和Logical Disk-&gt;%Disk Time建议的阀值：90% Physical Disk-&gt;Disk Reads/sec和Physical Disk-&gt;Disk Writes/sec建议的阀值：取决于制造商的规格说明：检查磁盘的指定传送速度，以验证此速度没有超过规格。通常，Ultra WideSCSI磁盘每秒可以处理50到70次I/O操作。注意，无论I/O是顺序的还是随机的，都会对磁盘的每秒读写速率产生很大的影响 Physical Disk-&gt;Current Disk Queue Length建议的阀值：主轴数+2说明：这是即时计数器，观察在多个间隔上的值。对于随时间变化的平均值，可试用Physicial Disk-&gt;Avg.Disk Queue Length 进程分析方法查看进程的Process-&gt;%Processor Time值每个进程的%Processor Time反映进程所消耗的处理器时间。用不同进程所消耗的处理器时间进行对比，可以看出具体哪个进程在性能测试过程中消耗了最多的处理器时间，从而可以据此对应用进行优化 查看每个进程产生的页面失效、可以用每个进程产生的页面失效（通过Process-&gt;Page Faults/sec计数器获得）和系统页面失效（通过Memory-&gt;Page Faults/sec计数器获得）的比值，来判断哪个进程产生了最多的页面失效，这个进程要么是需要大量内存的进程，要么是非常活跃的进程，可以对其进行重点分析 了解进程的Process-&gt;Private BytesProcess-&gt;Private Bytes是指进程所分配的无法与其进程共享的当前字节数量。该计数器主要用来判断在性能测试过程中有无内存泄露。例如：对于一个IIS之上的Web应用，可以重点监控inetinfo进程的Private Bytes。如果在性能测试过程中，该进程的Private Bytes计数器值不断增加，或是性能测试停止一段时间，该进程的Private Bytes仍持续在高水平，则说明应用存在内存泄露 网络分析方法Network Interface-&gt;Bytes Total/sec发送和接收字节的速率，可以通过该计数器值来判断网络链接速度是否是瓶颈，具体操作方法是用该计数器的值和当前网络的带宽进行比较 与Processor-&gt;Privileged Time合并进行分析如果在Physical Disk计数器中，只有%Disk Time比较大，其他值都比较适中，硬盘可能会是瓶颈。若几个值都比较大，且数值持续超过80%，则可能是内存泄露。 ASP.NET监控Request Wait Time地址：\ASP.NET\Request Wait Time描述：最近的请求在队列中等待的毫秒数。建议指标：此值不宜超过10000说明：此值过高说明IIS已经无法承受更多的请求，应考虑实施分布式策略 原文地址]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7搭建zabbix]]></title>
    <url>%2F2018%2F05%2F11%2Fcentos7%E6%90%AD%E5%BB%BAzabbix%2F</url>
    <content type="text"><![CDATA[centos7搭建zabbix3.4 zabbix安装环境要求： zabbix安装要求 安装前置操作关闭selinux1sudo sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config 升级yum1sudo yum -y update 切换iptables防火墙查看防火墙状态1firewall-cmd --state 关闭防火墙1systemctl stop firewalld.service 禁止开机启动启动防火墙1systemctl disable firewalld.service iptables设置安装iptables服务1yum install iptables-services 开启iptables防火墙1systemctl start iptables.service 开启特定端口：编辑文件：/etc/sysconfig/iptables，加入想要开放的端口即可，例如开放10051端口：1-A INPUT -p tcp -m tcp --dport 8090 -j ACCEPT 保存退出，重启防火墙：1systemctl restart iptables.service 安装MySQL下载源包：1wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 安装mysql源:1yum localinstall mysql57-community-release-el7-8.noarch.rpm 检查是否安装成功：1yum repolist enabled | grep &quot;mysql.*-community.*&quot; 123mysql-connectors-community/x86_64 MySQL Connectors Community 51mysql-tools-community/x86_64 MySQL Tools Community 63mysql57-community/x86_64 MySQL 5.7 Community Server 267 可以修改源配置，安装你喜欢的版本：1vim /etc/yum.repos.d/mysql-community.repo 只需要把对应的enable改成1即可。安装1yum install mysql-community-server 启动服务12systemctl start mysqldsystemctl status mysqld #查看状态 配置开机启动12systemctl enable mysqldsystemctl daemon-reload 修改root密码查看默认密码：1grep &apos;temporary password&apos; /var/log/mysqld.log 修改密码很简单，mysql -uroot -p进入控制台，修改：1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;yourpwd&apos;; 修改权限：1GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;pwd&apos; WITH GRANT OPTION; 配置防火墙，开放3306端口，即可在windows使用工具连接数据库。 安装Apache123sudo yum -y install httpdsystemctl start httpd.service #启动systemctl enable httpd.service #开机启动 安装php1sudo yum install php 安装php扩展1sudo yum install php-mysqlnd php-gd libjpeg* php-snmp php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-bcmath php-mhash php-common php-ctype php-xml php-xmlreader php-xmlwriter php-session php-mbstring php-gettext php-ldap php-mysqli --skip-broken 1sudo yum install wget telnet net-tools python-paramiko gcc gcc-c++ dejavu-sans-fonts python-setuptools python-devel sendmail mailx net-snmp net-snmp-devel net-snmp-utils freetype-devel libpng-devel perl unbound libtasn1-devel p11-kit-devel OpenIPMI unixODBC 修改一些配置设置MySQL参数1vim /etc/my.cnf 在文件最后添加以下内容（8G内存为例，根据自己配置适当修改）123456789101112131415161718192021222324innodb_file_per_table = 1innodb_status_file = 1innodb_buffer_pool_size = 6Ginnodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 16Minnodb_log_file_size = 64Minnodb_support_xa = 0default-storage-engine = innodbbulk_insert_buffer_size = 8Mjoin_buffer_size = 16Mmax_heap_table_size = 32Mtmp_table_size = 32Mmax_tmp_tables = 48read_buffer_size = 32Mread_rnd_buffer_size = 16Mkey_buffer_size = 32Mthread_cache_size = 32innodb_thread_concurrency = 8innodb_flush_method = O_DIRECTinnodb_rollback_on_timeout = 1query_cache_size = 16Mquery_cache_limit = 16Mcollation_server = utf8_bincharacter_set_server = utf8 注：原则上 innodb_buffer_pool_size 需要设置为主机内存的 80%，如果主机内存不是 8GB，以上参数可依据相应比例进行调整，例如主机内存为 16GB，则 innodb_buffer_pool_size 建议设置为 12GB，innodb_log_buffer_size 建议设置为 32M，innodb_log_file_size 建议设置为 128M，以此类推。请注意innodb_buffer_pool_size的值必须是整数，例如主机内存是4G，那么innodb_buffer_pool_size可以设置为3G，而不能设置为3.2G 重启MySQL1systemctl restart mysqld 创建zabbix数据库用户进入mysql控制台1mysql -uroot -p 12345create database zabbix character set utf8;create user zabbix@&apos;%&apos; identified by &apos;yourpwd&apos;;GRANT ALL PRIVILEGES ON *.* TO &apos;zabbix&apos;@&apos;%&apos; IDENTIFIED BY &apos;yourpwd&apos; WITH GRANT OPTION;flush privileges;exit; 安装zabbix源1sudo rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm 安装zabbix1sudo yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-java-gateway zabbix-web 配置zabbix导入zabbix所需信息12cd /usr/share/doc/zabbix-server-mysql-3.4.3zcat create.sql.gz | mysql -uroot zabbix -p 配置zabbix参数1sudo vim /etc/zabbix/zabbix_server.conf 1234567891011121314151617181920DBPassword=yourpwd(125行左右)CacheSize=512M（在385行左右）HistoryCacheSize=128M（在410行左右）HistoryIndexCacheSize=128M（在419行左右）TrendCacheSize=128M（在428行左右）ValueCacheSize=256M（在438行左右）Timeout=30（在448行左右） 配置Apache中的php参数123456789sudo vim /etc/httpd/conf.d/zabbix.confphp_value max_execution_time 600php_value memory_limit 256Mphp_value post_max_size 32Mphp_value upload_max_filesize 32Mphp_value max_input_time 600php_value always_populate_raw_post_data -1date.timezone 去掉注释符号#，并将值修改为 Asia/Shanghai 重启系统1reboot 启动zabbix1sudo systemctl start httpd &amp;&amp; systemctl start zabbix-server 在浏览器中输入http://your_IP/zabbix，进入zabbix页面进行初始化配置，单击两次next step，填写正确数据库信息，继续next step，填写zabbix detail（相当于起名字），端口不变！！！然后finish，完成安装。 设置中文第一次登录zabbix监控系统，默认用户为admin，默认密码zabbix，正确登录系统。选择Administrator –&gt; Users –&gt; Admin，在Language栏选择Chinese(zh_CN)完成汉化。 OVER! 参考链接 centos7安装zabbix3.4]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>Zabbiz3.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos部署.net core]]></title>
    <url>%2F2018%2F05%2F10%2Fcentos%E9%83%A8%E7%BD%B2-net-core%2F</url>
    <content type="text"><![CDATA[Centos7部署.net core应用 安装dotnet产品提要首先需要注册Microsoft签名密钥并添加Microsoft产品提要，才能安装.net12rpm --import https://packages.microsoft.com/keys/microsoft.ascsh -c &apos;echo -e &quot;[packages-microsoft-com-prod]\nname=packages-microsoft-com-prod \nbaseurl= https://packages.microsoft.com/yumrepos/microsoft-rhel7.3-prod\nenabled=1\ngpgcheck=1\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc&quot; &gt; /etc/yum.repos.d/dotnetdev.repo&apos; 默认使用root用户操作 安装.NET SDK首先更新yum1yum update 安装所需组件1yum install libunwind libicu 安装.NET SDK1yum install dotnet-sdk-2.1.200 完成安装，dotnet --version验证安装 部署应用将你的.net core应用随意放置在某个目录，进入目录，执行1dotnet YourApp.WebApi.dll 即可启动服务，默认启动端口为5000. nginx代理安装nginx安装nginx需要添加EPEL仓库，然后再安装：12yum install epel-releaseyum install nginx 启动nginx启动：1systemctl start nginx 设置nginx开机启动1systemctl enable nginx 修改配置将nginx的默认配置文件中的80端口内容注释掉，文件路径：/etc/nginx/nginx.conf,然后在nginx的配置加载目录下创建你需要代理的端口配置文件yourapp.conf，路径：/etc/nginx/conf.d，文件内容：1234567891011server &#123; listen 80; location / &#123; proxy_pass http://localhost:5000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection keep-alive; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 重启nginx即可通过80端口访问部署的.net core服务。 配置守护进程由于.net core程序在linux上运行，一般都是需要在shell里运行，执行命令：dotnet app.dll，一旦窗口关闭了，程序就被杀了，所以需要配置个守护进程，微软推荐：Supervisor 安装安装很简单，一条命令：1yum install supervisor 配置修改默认配置文件：supervisord.conf，找到最后：12[include]files = supervisord.d/*.ini 修改为：12[include]files = supervisord.d/*.conf 进入supervisord.d文件夹，创建APP的配置文件YourAPP.conf12cd supervisord.dvim YourAPP.conf 内容为：1234567891011[program:HelloWebApp]command=dotnet YourAPP.dll #要执行的命令directory=/usr/local/YourAPP #命令执行的目录environment=ASPNETCORE__ENVIRONMENT=Production #环境变量user=root #进程执行的用户身份stopsignal=INTautostart=true #是否自动启动autorestart=true #是否自动重启startsecs=1 #自动重启间隔stderr_logfile=/var/log/HelloWebApp.err.log #标准错误日志stdout_logfile=/var/log/HelloWebApp.out.log #标准输出日志 保存退出 运行supervisord12supervisord -c /etc/supervisord.confps -ef | grep APPName 常用命令：12345supervisorctl shutdown #关闭所有任务supervisorctl stop|start program_namesupervisorctl status #查看所有任务状态 加自启动文件路径：/usr/lib/systemd/system/supervisord.service，安装时候已经存在，如果没有，就自己创建一个：1234567891011121314[Unit]Description=Supervisor daemon[Service]Type=forkingExecStart=/usr/bin/supervisord -c /etc/supervisord.confExecStop=/usr/bin/supervisorctl shutdownExecReload=/usr/bin/supervisorctl reloadKillMode=processRestart=on-failureRestartSec=42s[Install]WantedBy=multi-user.target 加载启动项：123systemctl enable supervisord验证systemctl is-enabled supervisord 问题记录由于安装在linux上，不同于windows，出现了一个现象，页面进行请求之后，消息队列中的消息一直无法被消费，查看日志，显示：123The handler does not support custom handling of certificates with this combination of libcurl (7.29.0) and its SSL backend (&quot;NSS/3.28.4&quot;).) ---&gt; System.PlatformNotSupportedException: The handler does not support custom handling of certificates with this combination of libcurl (7.29.0) and its SSL backend (&quot;NSS/3.28.4&quot;).at System.Net.Http.CurlHandler.SslProvider.SetSslOptionsForUnsupportedBackend(EasyRequest easy, ClientCertificateProvider certProvider)at System.Net.Http.CurlHandler.SslProvider.SetSslOptions(EasyRequest easy, ClientCertificateOption clientCertOption 原因就是linux不支持ssl（貌似是这样），搜了一堆答案，大部分是建议升级curl 解决linux netcore https请求使用自签名证书忽略安全检查方法开始：首先安装openssl和gcc1yum install openssl-devel gcc 然后是最新版本的curl：123456wget https://curl.haxx.se/download/curl-7.59.0.tar.gztar -zxf curl-7.59.0.tar.gzcd curl-7.59.0./configure --prefix=/usr/local/curl/ --without-nss --with-ssl=/usr/local/ssl/makemake install 备份原来的curl：1mv /usr/bin/curl /usr/bin/curl.bak 新安装的curl创建软链接1ln -s /usr/local/curl/bin/curl /usr/bin/curl 查看此时curl版本1curl --version 编辑搜索目录：1vim /etc/ld.so.conf 增加一行：/usr/local/curl/lib 重启服务，完成！ Supervisor详细配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128; Sample supervisor config file.;; For more information on the config file, please see:; http://supervisord.org/configuration.html;; Notes:; - Shell expansion (&quot;~&quot; or &quot;$HOME&quot;) is not supported. Environment; variables can be expanded using this syntax: &quot;%(ENV_HOME)s&quot;.; - Quotes around values are not supported, except in the case of; the environment= options as shown below.; - Comments must have a leading space: &quot;a=b ;comment&quot; not &quot;a=b;comment&quot;.; - Command will be truncated if it looks like a config file comment, e.g.; &quot;command=bash -c &apos;foo ; bar&apos;&quot; will truncate to &quot;command=bash -c &apos;foo &quot;.[unix_http_server]file=/tmp/supervisor.sock ; socket 文件路径;chmod=0700 ; socket 文件 模式 (默认 0700);chown=nobody:nogroup ; socket file uid:gid owner;username=user ; 使用supervisorctl连接的用户;password=123 ; 上条用户的密码;[inet_http_server] ; Web Server和远程的supervisorctl 配置块(默认关闭);port=127.0.0.1:9001 ; 监听的地址和端口;username=user ; 登录时用的用户;password=123 ; 上条用户的密码[supervisord]logfile=/tmp/supervisord.log ; supervisord进程日志路径logfile_maxbytes=50MB ; supervisord进程日志的大小 当超过50M时，会生成一个新的日志( 0 表示不限制)logfile_backups=10 ; 日志文件保持的数量，启动supervisor时 会自动创建10个buckup文件，用于log rotate ( 0 表示不限制)loglevel=info ; 日志级别pidfile=/tmp/supervisord.pid ; supervisord的pid文件路径。nodaemon=false ; 如果是true，supervisord进程将在前台运行 默认为false(后台运行)minfds=1024 ; 这个是最少系统空闲的文件描述符，低于这个值supervisor将不会启动minprocs=200 ; 最小可用的进程描述符，低于这个值supervisor也将不会正常启动;umask=022 ; 进程创建文件的掩码 (默认 022);user=chrism ; 该参数指定的用户也可以对supervisord进行管理;identifier=supervisor ; supervisord的标识符;directory=/tmp ; 当supervisord以守护进程运行的时候，启动supervisord进程之前，会先切换到这个目录;nocleanup=true ; false的时候 supervisord进程启动的时候 会在把以前子进程产生的日志文件(路径为AUTO的情况下)清除掉(true不清除);childlogdir=/tmp ; 当子进程日志路径为AUTO的时候，子进程日志文件的存放路径 (默认 $TMP);environment=KEY=&quot;value&quot; ; 这个是用来设置环境变量的，supervisord在linux中启动默认继承了linux的 环境变量，在这里可以设置supervisord进程特有的其他环境变量supervisord启动子进程时，子进程会拷贝父进程的内存空间内容。 所以设置的这些环境变量也会被子进程继承 (默认不设置);strip_ansi=false ; 这个选项如果设置为true，会清除子进程日志中的所有ANSI(\n,\t) 序列[rpcinterface:supervisor] ; 这个选项是给XML_RPC用的，果想使用supervisord或者web server 必须要开启supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; supervisorctl本地连接supervisord，本地UNIX socket;serverurl=http://127.0.0.1:9001 ; supervisorctl远程连接supervisord的时候，用到的地址和端口;username=chris ; 连接登录的用户名;password=123 ; 密码;prompt=mysupervisor ; 输入用户名密码时候的提示符 默认:mysupervisor ;history_file=~/.sc_history ; 指定历史命令的文件;[program:theprogramname] ; 案例 [program:给要管理进程起的一个名字];command=/bin/cat ; 要执行的进程 可带参数 $1 $2 $3 注意!! 执行的进程不能是守护进程 ! !;process_name=%(program_name)s ; 进程名 下条numprocs参数为1，就不用管这个参数 默认值%(program_name)s也就是上面的那个program冒号后面的名字;numprocs=1 ; 启动进程的数目。当不为1时，就是进程池的概念，默认为1;directory=/tmp ; 进程运行前，会前切换到这个目录;umask=022 ; 进程掩码 (default None);priority=999 ; 子进程启动关闭优先级，优先级低的，最先启动，关闭的时候最后关闭 (default 999);autostart=true ; 设置为true 子进程将在supervisord启动后被自动启动;startsecs=1 ; 设置子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了;startretries=3 ; 进程启动失败后，最大尝试启动的次数 当超过3次后，supervisor将把此进程的状态置为FAIL;autorestart=unexpected ; 设置子进程挂掉后自动重启的情况，有三个选项，false,unexpected和true。如果为false的时候，无论什么情况下，都不会被重新启动，如果为unexpected，只有当进程的退出码不在上面的exitcodes里面定义的退出码的时候，&gt;才会被自动重启。当为true的时候，只要子进程挂掉，将会被无条件的重启;exitcodes=0,2 ; 注意和上面的的autorestart=unexpected对应 exitcodes里面的定义的退出码是expected的。;stopsignal=QUIT ; 进程停止信号，可以为TERM, HUP, INT, QUIT, KILL, USR1, or USR2等信号 默认为TERM 当用设定的信号去杀掉进程，退出码会被认为是expected;stopwaitsecs=10 ; 这个是当我们向子进程发送stopsignal信号后，到系统返回信息给supervisord，所等待的最大时间。 超过这个时间，supervisord会向该子进程发送一个强制kill的信号(默认10秒);stopasgroup=false ; 这个东西主要用于，supervisord管理的子进程，这个子进程本身还有子进程 那么我们如果仅仅干掉supervisord的子进程的话，子进程的子进程有可能会变成孤儿进程 所以咱们可以设置可个选项，把整个该子进程的整个进程组都干掉 设置为true的话，一般killasgroup也会被设置为true 该选项发送的是stop信号(def false);killasgroup=false ; 这个和上面的stopasgroup类似，不过发送的是kill信号(def false);user=chrism ; 如果supervisord是root启动，我们在这里设置这个非root用户，可以用来管理该program 默认不设置;redirect_stderr=true ; 为true，则stderr的日志会被写入stdout日志文件中 (default false);stdout_logfile=/a/path ; 子进程的stdout的日志路径，可以指定路径，AUTO，none等三个选项 设置为none的话，将没有日志产生。设置为AUTO的话，将随机找一个地方成日志文件，而且当supervisord重新启动的时候，以前的日志文件会被清空。当 redirect_stderr=true的时候，sterr也会写进这个日志文件;stdout_logfile_maxbytes=1MB ; 日志文件最大大小，和[supervisord]中定义的一样 (default 50MB);stdout_logfile_backups=10 ; 和[supervisord]定义的一样 (0 means none, default 10);stdout_capture_maxbytes=1MB ; 这个东西是设定capture管道的大小，当值不为0的时候，子进程可以从stdout发送信息，而supervisor可以根据信息，发送相应的event (default 0);stdout_events_enabled=false ; 为ture的时候，当子进程由stdout向文件描述符中写日志的时候，将触发supervisord发送PROCESS_LOG_STDOUT类型的event(default false);stderr_logfile=/a/path ; 设置stderr写的日志路径，当redirect_stderr=true。这个就不用设置了，设置了也是白搭。因为它会被写入stdout_logfile的同一个文件中 default AUTO(随便找个地存，supervisord重启被清空);stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10);stderr_capture_maxbytes=1MB ; number of bytes in &apos;capturemode&apos; (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=&quot;1&quot;,B=&quot;2&quot; ; 这个是该子进程的环境变量，和别的子进程是不共享的;serverurl=AUTO ; override serverurl computation (childutils);[eventlistener:theeventlistenername] ;这个东西其实和program的地位是一样的，也是suopervisor启动的子进程，不过它干的活是订阅supervisord发送的event。他的名字就叫listener了。我们可以在listener里面做一系列处理，比如报警....;command=/bin/eventlistener ; 和上面的program一样，表示listener的可执行文件的路径;process_name=%(program_name)s ; 这个也一样，进程名，当下面的numprocs为多个的时候，才需要。否则默认就OK了;numprocs=1 ; 相同的listener启动的个数;events=EVENT ; event event事件的类型，也就是说，只有写在这个地方的事件类型。才会被发送;buffer_size=10 ; event队列缓存大小 (default 10);directory=/tmp ; 进程执行前，会切换到这个目录下执行 (def no cwd);umask=022 ; umask for process (default None);priority=-1 ; 启动优先级 (default -1);autostart=true ; true supervisord启动一起启动 (default: true);startsecs=1 ; 设置子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了 (def. 1);startretries=3 ; 失败最大尝试次数 (default 3);autorestart=unexpected ; 和program一样 (def: unexpected);exitcodes=0,2 ; &apos;expected&apos; exit codes used with autorestart (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=false ; redirect_stderr=true is not allowed for eventlisteners;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=&quot;1&quot;,B=&quot;2&quot; ; process environment additions;serverurl=AUTO ; override serverurl computation (childutils);[group:thegroupname] ; 这个东西就是给programs分组，划分到组里面的program。我们就不用一个一个去操作了 我们可以对组名进行统一的操作。 注意：program被划分到组里面之后，就相当于原来的配置从supervisor的配置文件里消失了supervisor只会对组进行管理，而不再会对组里面的单个program进行管理了;programs=progname1,progname2 ; 组成员，用逗号分开;priority=999 ; 优先级，相对于组和组之间 (default 999);[include] ; 跟Nginx虚拟主机一个样;files = relative/directory/*.ini 参考链接 centos部署.net core]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>.net core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用webpagetest测试不同国家登录响应]]></title>
    <url>%2F2018%2F05%2F08%2F%E4%BD%BF%E7%94%A8webpagetest%E6%B5%8B%E8%AF%95%E4%B8%8D%E5%90%8C%E5%9B%BD%E5%AE%B6%E7%99%BB%E5%BD%95%E5%93%8D%E5%BA%94%2F</url>
    <content type="text"><![CDATA[使用webpageTest模拟不同国家进行登录操作 产品boss提了个从不同国家测试系统访问响应时间的需求，目前完成的是不同国家登录操作。 先来个套话：网站的打开速度直接影响用户体验，据悉，网站若没有在4秒内读取出来，大多数的访客就会选择离开，而且网页的载入速度也会影响网站的排名，因此，网站的打开速度极其重要。根据不同的需求去分析网站的加载速度，有助于促进网站高效运行 工具拿到需求之后，上网搜过很多工具，接触了的有： Pingdomsucuri 以及正在使用的： webpagetest webpagetest其他的就不介绍了，只介绍怎么使用webpagetest进行不同国家的登录操作。说实话，刚开始接触时候有点懵，webpagetest自己有个Auth模块，原以为可以直接通过这个来进行登录鉴权，结果可以预料，压根没用，后来就开始琢磨Script模块。看了n久官方文档之后，实验出来了，鼓励大家看官方文档啊。。。上链接： script模块 webpagetest提供脚本的形式，帮助用户使用脚本来填充表单，达到登录的目的。这点看下来有点类似于自动化测试时候，先看页面源码，找到用户名/密码源码的唯一标识，在script代码框中使用该唯一标识来指代需要用到的元素，例如：登录页面源码展示的用户名：1&lt;input name=&quot;username&quot; class=&quot;ant-input ng-not-empty ng-dirty ng-valid-parse userInput ng-touched&quot; id=&quot;username&quot; type=&quot;text&quot; placeholder=&quot;用户名或邮箱&quot; ng-model=&quot;model.username&quot; ng-change=&quot;onChange()&quot;&gt; 从上面的源码可以看出，使用id可以唯一标志该字段，在自动化测试中使用find_element_by_id(&#39;username&#39;)即可获得该页面元素，类比到webpagetest的script，也是如此：1setValue id=username yourusername 即可完成定位到用户名并且完成用户名输入，同样的，密码：源码为：1&lt;input id=&quot;password&quot; name=&quot;password&quot; type=&quot;password&quot; class=&quot;ant-input ant-input-lg ng-not-empty ng-dirty ng-valid-parse userInput ng-touched&quot; placeholder=&quot;密码&quot; ng-model=&quot;model.password&quot; autocomplete=&quot;off&quot; focus-if=&quot;model.username&quot; ng-change=&quot;pwdOnChange()&quot;&gt; webpagetest定位：1setValue id=password yourpassword 当然，点击登录按钮也类似：1clickAndWait innerText=Login 以上演示的只是一种定位方式，更多的使用，还是去看官方文档吧，有各种情况可供选择~~ 登录直接上我的登录脚本：123456logData 0navigate https://test-login.comlogData 1setValue name=username yourusernamesetValue name=password yourpasswordclickAndWait type=submit 说明logData个人理解是是否开启数据记录的标志，类似开启缓存（可能理解不对），0为关闭，1为开启，对于登录之后的操作，可以在登录前设置logData为1，打开数据记录，这样在后续的操作中就可以使用登录之后的用户信息。 官方示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// load the account name and passwordloadVariables accounts.txt// bring up the login screensetEventName launchnavigate http://webmail.aol.com// ignore any errors from here on (in case the mailbox is empty or we get image challenged)ignoreErrors 1// log insetValue name=loginId %AOLSN%setValue name=password %AOLPW%setEventName loadsubmitForm name=AOLLoginForm// only read and send a mail once an hourminInterval AOLMail 60// close the today curtainclick className=backdropsleep 5// Open the first message with a subject of &quot;test&quot;setEventName readclickAndWait innerText=test// delete the messageclick title=Delete (del)sleep 5// open the compose mail formsetEventName composeclickAndWait title=Write mail (Alt + w)// send a test message to myselfsleep 1setValue tabindex=100 %AOLSN%setValue name=Subject testloadFile msg.txt %MSG%setInnerText contentEditable=true %MSG%sleep 1setDOMElement className=confirmMessagesetEventName sendclickAndWait innerText=SendendInterval// sign offsetEventName logoutclickAndWait className=signOutLink]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>webpagetest</tag>
        <tag>response time</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7搭建Nitrate]]></title>
    <url>%2F2018%2F04%2F22%2FCentos7%E6%90%AD%E5%BB%BANitrate%2F</url>
    <content type="text"><![CDATA[基于python+Django，测试用例管理平台Nitrate搭建 前言基于目前Jira+confluence已经成为日常流程管控，老大就琢磨着我们测试用例需要个专门的平台进行管控，所以也就产生了调研的需求，候选有俩：testlink和Nitrate，由于目前组内python氛围较活跃，自动化测试用例也是基于python，所以也就是希望能找到一个基于python写的系统，方便定制，二次开发嘛~ 开篇在有搭建Nitrate这个任务之后，本着偷懒的心态，首先搜了一圈搭建教程，然而，一篇都没找到！！！也就是说，我得自己折腾了！！！没办法，直接上github找项目地址，说不定在说明里面有介绍呢 Nitrate项目地址 里面的确是有介绍，搭建教程貌似也有，还是各种环境的搭建教程，好像看到些光辉啊.. Nitrate Doc 文档介绍了各种搭建教程，选你看着比较顺眼的，动手吧~ 坎坷的系统搭建平时Linux还算是比较顺手，直接选Installing nitrate on RHEL6 with Apache and MySQL，虽然介绍的Redhat的，不都涨一样嘛~开工：由于自己电脑还是Windows的（别提了，测试嘛，需要太多工具，唉），首先就是搭个Centos7的虚拟机，轻车熟路了，非常迅速的完工，Xshell远程连上，开始愉快的黑窗口作业。。 环境准备由于搭建的centos7是所谓的CentOS-7-x86_64-Everything-1611版本，网卡什么的驱动都是装好了，如果你装的是最间版，那么ifconfig命令都敲不了。。。自己百度怎么开网吧。。 Git由于是需要从github仓库直接拉项目，所以git就必须先搭个了:1yum install git 就完成了，如果遇到yum不让用，日志显示XX进程正在使用yum，那要么等，要么就是暴力点，直接杀：1rm -rf /var/run/yum.pid 然后就可以安心的yum install了。 Django由于Nitrate是基于Django的，所以，必不可少的需要装个Django；装Django，有三种方法： pip最简单就是一条命令带走：1pip install Django setuptools使用setuptools安装，首先需要先装它：1yum install python-setuptools 安装完成之后，再使用easy_install安装django：1easy_install django 源码安装首先是上官网下载个tar.gz格式的源码包： 官方源码下载地址 然后就可以开始正常的解压安装了：1234cd your_pathrz (windows拷包到linux)tar -zxvf Django-x.x.tar.gzpython setup.py install 即可完成安装，验证：1django-admin.py 正确安装会出现很多选项，类似这样：12345678910111213[root@localhost run]# django-admin.pyType &apos;django-admin.py help &lt;subcommand&gt;&apos; for help on a specific subcommand.Available subcommands:[django] check compilemessages createcachetable dbshell diffsettings dumpdata 好了，这这里来说说遇到的第一个坑，鬼知道是为了个什么，Nitrate限制Django版本，当你使用pip或者easy_install安装个2.0版本之后，后面编译安装Nitrate时候，就会开始报错给你了，到时候就知道是多么北京的事了,印象中Django版本要求是1.8&lt;=Django版本&lt;1.11 ，唉，所以，如果谁正准备装这个，或者偶尔看到我写的这玩意，真的，记住，还是源码安装Django吧。。。另外，强烈建议你就要你装完系统的python版本（多半是2.7.5），千万别升3.6，不然可能还要哭一会。 pip上面说的可以使用pip来装Django，但是，貌似2.7.5的python压根就没自带个pip，好吧，反正后面还需要pip，还是先装上吧：首先安装epel扩展1yum -y install epel-release 然后就可以装pip了：1yum -y install python-pip 完了清个cache:1yum clean all MySQL数据库选MySQL也没什么可纠结了，安装：下载源包：1wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 安装mysql源:1yum localinstall mysql57-community-release-el7-8.noarch.rpm 检查是否安装成功：1yum repolist enabled | grep &quot;mysql.*-community.*&quot; 123mysql-connectors-community/x86_64 MySQL Connectors Community 51mysql-tools-community/x86_64 MySQL Tools Community 63mysql57-community/x86_64 MySQL 5.7 Community Server 267 可以修改源配置，安装你喜欢的版本：1vim /etc/yum.repos.d/mysql-community.repo 只需要把对应的enable改成1即可。 安装1yum install mysql-community-server 这里再次吐槽下公司的网，烂的不是一点半点，这个包印象中有近200M，公司网以20k速度给我下。。。直接流量开热点才下好。 启动服务systemctl start mysqld 查看状态systemctl status mysqld 配置开机启动12systemctl enable mysqldsystemctl daemon-reload 修改root密码查看默认密码：1grep &apos;temporary password&apos; /var/log/mysqld.log 修改密码很简单，mysql -uroot -p进入控制台，改：1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;pwd&apos;; 顺便改个权限：1GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;pwd&apos; WITH GRANT OPTION; 再配个防火墙，3306端口打开，那么在Windows中就能使用工具连接数据库了。 修改字符编码编辑/etc/my.cnf，在[mysqld]下添加配置：123[mysqld]character_set_server=utf8init_connect=&apos;SET NAMES utf8&apos; 重启mysql服务即可。 开始搭建项目clone首先是clone到本地：12cd /usr/local/srcgit clone https://github.com/Nitrate/Nitrate.git 大概有这么些东西：123456789101112131415161718192021[root@localhost Nitrate]# lltotal 160-rw-r--r--. 1 root root 609 Apr 22 12:23 AUTHORSdrwxr-xr-x. 4 root root 43 Apr 22 12:41 build-rw-r--r--. 1 root root 66430 Apr 22 12:23 CHANGELOG.rstdrwxr-xr-x. 4 root root 60 Apr 22 12:23 contribdrwxr-xr-x. 2 root root 35 Apr 22 12:41 distdrwxr-xr-x. 3 root root 76 Apr 22 12:23 docs-rw-r--r--. 1 root root 18092 Apr 22 12:23 LICENSE-rw-r--r--. 1 root root 1690 Apr 22 12:23 Makefile-rwxr-xr-x. 1 root root 279 Apr 22 12:23 manage.py-rw-r--r--. 1 root root 256 Apr 22 12:23 MANIFEST.indrwxr-xr-x. 2 root root 110 Apr 22 12:41 Nitrate.egg-info-rw-r--r--. 1 root root 25090 Apr 22 12:23 nitrate.spec-rw-r--r--. 1 root root 1753 Apr 22 12:23 README.rst-rw-r--r--. 1 root root 1127 Apr 22 12:23 requirements.txt-rw-r--r--. 1 root root 657 Apr 22 12:23 setup.cfg-rw-r--r--. 1 root root 2234 Apr 22 12:23 setup.pydrwxr-xr-x. 19 root root 4096 Apr 22 12:23 tcms-rw-r--r--. 1 root root 827 Apr 22 12:23 tox.ini-rw-r--r--. 1 root root 4 Apr 22 12:23 VERSION.txt 安装开发包1yum install gcc python-devel mysql-devel krb5-devel libxml2-devel libxslt-devel 安装完成之后，还要项目依赖 安装依赖进入项目目录：1cd /usr/local/src/Nitrate 开始安装：1pip install . 这个过程会在你本地检查一个个的依赖，没有就装，其中就会检查Django，这破版本的问题，真的是害我又重装一遍。安装速度取决于你的网速和电脑硬件性能，安心等着successful。 源码安装Nitrate还是在这个目录，执行:1python setup.py install 使用源码安装Nitrate，等着就好，安装完成之后，可以到/usr/lib/python2.7/site-packages下找到你安装的Nitrate：123[root@localhost site-packages]# ls | grep NitrateNitrate-4.1-py2.7.eggNitrate-4.1-py2.7.egg-info 看看里面有啥：12345678910111213141516171819202122232425262728293031323334[root@localhost site-packages]# cd Nitrate-4.1-py2.7.egg[root@localhost Nitrate-4.1-py2.7.egg]# lsEGG-INFO tcms[root@localhost Nitrate-4.1-py2.7.egg]# lltotal 4drwxr-xr-x. 2 root root 130 Apr 22 14:52 EGG-INFOdrwxr-xr-x. 18 root root 4096 Apr 22 14:52 tcms[root@localhost Nitrate-4.1-py2.7.egg]# cd tcms/[root@localhost tcms]# lltotal 56-rw-r--r--. 1 root root 307 Apr 22 14:52 celery.py-rw-r--r--. 1 root root 586 Apr 22 14:52 celery.pycdrwxr-xr-x. 11 root root 4096 Apr 22 14:52 core-rw-r--r--. 1 root root 301 Apr 22 14:52 __init__.py-rw-r--r--. 1 root root 422 Apr 22 14:52 __init__.pycdrwxr-xr-x. 4 root root 75 Apr 22 14:52 integrationdrwxr-xr-x. 4 root root 32 Apr 22 14:52 localedrwxr-xr-x. 3 root root 261 Apr 22 14:52 managementdrwxr-xr-x. 3 root root 228 Apr 22 14:52 profilesdrwxr-xr-x. 2 root root 272 Apr 22 14:52 reportdrwxr-xr-x. 2 root root 241 Apr 22 14:52 searchdrwxr-xr-x. 2 root root 224 Apr 22 16:15 settingsdrwxr-xr-x. 8 root root 94 Apr 22 15:09 staticdrwxr-xr-x. 14 root root 4096 Apr 22 16:06 templatesdrwxr-xr-x. 6 root root 4096 Apr 22 14:52 testcasesdrwxr-xr-x. 6 root root 4096 Apr 22 14:52 testplansdrwxr-xr-x. 6 root root 4096 Apr 22 14:52 testrunsdrwxr-xr-x. 2 root root 86 Apr 22 14:52 tests-rw-r--r--. 1 root root 2334 Apr 22 14:52 urls.py-rw-r--r--. 1 root root 2299 Apr 22 14:52 urls.pycdrwxr-xr-x. 2 root root 123 Apr 22 14:52 utils-rw-r--r--. 1 root root 1896 Apr 22 14:52 wsgi.py-rw-r--r--. 1 root root 1605 Apr 22 14:52 wsgi.pycdrwxr-xr-x. 4 root root 4096 Apr 22 14:52 xmlrpc 记住tcms/这个文件夹，后面的配置，全都在这里面。 配置初始化数据首先是创建nitrate这数据库，然后创建用户，赋权限，初始化数据：12create database nitrate;GRANT ALL PRIVILEGES ON *.* TO &apos;nitrate&apos;@&apos;%&apos; IDENTIFIED BY &apos;pwd&apos; WITH GRANT OPTION; 修改配置之前接触过Django的，应该都知道有个文件setting.py这里面是你app的一些重要配置，我们要改的，也就是它。Nitrate把传统意义上的setting.py分成了两个文件（其实是一个文件）：12common.pyproject.py 文件路径：/usr/lib/python2.7/site-packages/Nitrate-4.1-py2.7.egg/tcms/settings几乎所有配置都可以在common.py中完成，但是project.py在文件开头就是一句话：1from common import * 所以，我们常用的配置，在project.py中完成即可。内容大概长这样，可以参考我的配：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# Django settings for product env.from common import *# Debug settingsDEBUG = TrueTEMPLATE_DEBUG = DEBUG# Database settingsDATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;nitrate&apos;, &apos;USER&apos;: &apos;nitrate&apos;, &apos;PASSWORD&apos;: &apos;pwd&apos;, &apos;HOST&apos;: &apos;192.168.98.133&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;, &apos;slave_1&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;nitrate&apos;, &apos;USER&apos;: &apos;nitrate&apos;, &apos;PASSWORD&apos;: &apos;pwd&apos;, &apos;HOST&apos;: &apos;192.168.98.133&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;,&#125;# add RemoteUserMiddleWare if kerberos authentication is enabledMIDDLEWARE_CLASSES += (# &apos;django.contrib.auth.middleware.RemoteUserMiddleware&apos;,)# Remote kerberos authentication backends#AUTHENTICATION_BACKENDS = (# &apos;tcms.core.contrib.auth.backends.ModAuthKerbBackend&apos;,#)DATABASE_ROUTERS = [&apos;tcms.core.utils.tcms_router.RWRouter&apos;]# Kerberos realm#KRB5_REALM = &apos;EXAMPLE.COM&apos;# Bugzilla integration setttings# Config following settings if your want to integrate with bugzillaBUGZILLA3_RPC_SERVER = &apos;&apos;BUGZILLA_URL = &apos;&apos;BUGZILLA_USER = &apos;&apos;BUGZILLA_PASSWORD = &apos;&apos;# JIRA integration setttings# Config following settings if your want to integrate with JIRAJIRA_URL = &apos;&apos;# Set the default send mail addressEMAIL_HOST = &apos;smtp.example.com&apos;EMAIL_FROM = &apos;noreply@example.com&apos;# Site-specific messages# First run - to detemine need port user or not.FIRST_RUN = False# You can add a help link on the footer of home page as following format:# (&apos;http://foo.com&apos;, &apos;foo&apos;)FOOTER_LINKS = ( (&apos;/xmlrpc/&apos;, &apos;XML-RPC service&apos;),)# added for nitrate3.4 compatibilityDEFAULT_GROUPS = [&apos;default&apos;]TESTOPIA_XML_VERSION = &apos;1.0&apos;# admin settingsADMINS = ( # (&apos;Your Name&apos;, &apos;your_email@domain.com&apos;),)# user guide URLUSER_GUIDE_URL = &quot;&quot;DEFAULT_PAGE_SIZE = 100 基本需要修改的，一是DEBUG开关，第二个是数据库配置，开启DEBUG开关是为了后面初始化数据时候获取staticfile，开始第二个坑：12AUTHENTICATION_BACKENDSMIDDLEWARE_CLASSES 注释别放开啊别放开，千万别手痒，惨痛的教训，就是手痒在不知道这俩什么含义就放开了，然后在搭建完成之后，登录都登录不了。。一直在报jquery.min.js 404，这个问题真的是折腾死，开始根本想不到是这边的问题，造成把common.py文件研究了个遍，环境重新又搭建两遍，一遍使用venv开启，一遍按原来的来，最终在万念俱灰，把注释又加上才解决，唉。。。 配置common.py首先，直接上我配完的，可参考:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509# -*- coding: utf-8 -*-import django.conf.global_settings as DEFAULT_SETTINGSimport os.pathNITRATE_VERSION = &apos;4.0.0&apos;DEBUG = False# Administrators error report email settingsADMINS = ( # (&apos;Your Name&apos;, &apos;your_email@example.com&apos;),)TCMS_ROOT_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), &apos;..&apos;).replace(&apos;\\&apos;, &apos;/&apos;))MANAGERS = ADMINSDATABASES = &#123; # Master DB for writing &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;nitrate&apos;, &apos;USER&apos;: &apos;nitrate&apos;, &apos;PASSWORD&apos;: &apos;pwd&apos;, &apos;HOST&apos;: &apos;192.168.98.133&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;, # First slave DB for reading &apos;slave_1&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;nitrate&apos;, &apos;USER&apos;: &apos;nitrate&apos;, &apos;PASSWORD&apos;: &apos;pwd&apos;, &apos;HOST&apos;: &apos;192.168.98.133&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;, # Second slave DB for reporting, optional &apos;slave_report&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.3306&apos;, &apos;NAME&apos;: &apos;nitrate&apos;, &apos;USER&apos;: &apos;nitrate&apos;, &apos;PASSWORD&apos;: &apos;pwd&apos;, &apos;HOST&apos;: &apos;192.168.98.133&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;&#125;# Hosts/domain names that are valid for this site; required if DEBUG is False# See https://docs.djangoproject.com/en/1.5/ref/settings/#allowed-hostsALLOWED_HOSTS = [&apos;*&apos;]# Local time zone for this installation. Choices can be found here:# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name# although not all choices may be available on all operating systems.# In a Windows environment this must be set to your system time zone.TIME_ZONE = &apos;UTC&apos;# Language code for this installation. All choices can be found here:# http://www.i18nguy.com/unicode/language-identifiers.htmlLANGUAGE_CODE = &apos;en-us&apos;SITE_ID = 1# If you set this to False, Django will make some optimizations so as not# to load the internationalization machinery.USE_I18N = True# If you set this to False, Django will not format dates, numbers and# calendars according to the current locale.USE_L10N = True# If you set this to False, Django will not use timezone-aware datetimes.USE_TZ = False# Absolute filesystem path to the directory that will hold user-uploaded files.# Example: &quot;/var/www/example.com/media/&quot;MEDIA_ROOT = &apos;&apos;# URL that handles the media served from MEDIA_ROOT. Make sure to use a# trailing slash.# Examples: &quot;http://example.com/media/&quot;, &quot;http://media.example.com/&quot;MEDIA_URL = &apos;&apos;# URL prefix for admin absolute URLADMIN_PREFIX = &apos;/admin&apos;LOGIN_URL = &apos;nitrate-login&apos;LOGIN_REDIRECT_URL = &apos;user-profile-redirect&apos;LOGOUT_REDIRECT_URL = &apos;nitrate-login&apos;# Absolute path to the directory static files should be collected to.# Don&apos;t put anything in this directory yourself; store your static files# in apps&apos; &quot;static/&quot; subdirectories and in STATICFILES_DIRS.# Example: &quot;/var/www/example.com/static/&quot;#BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), &apos;..&apos;).replace(&apos;\\&apos;, &apos;/&apos;))#STATIC_ROOT = &apos;/usr/lib/python2.7/site-packages/Nitrate-4.1-py2.7.egg/tcms/static/&apos;STATIC_ROOT = &apos;/home/nitrate/projects/site/assets&apos;#STATIC_ROOT = os.path.join(TCMS_ROOT_PATH, &apos;static&apos;)# URL prefix for static files.# Example: &quot;http://example.com/static/&quot;, &quot;http://static.example.com/&quot;STATIC_URL = &apos;/static/&apos;# Additional locations of static filesSTATICFILES_DIRS = ( # Put strings here, like &quot;/home/html/static&quot; or &quot;C:/www/django/static&quot;. # Always use forward slashes, even on Windows. # Don&apos;t forget to use absolute paths, not relative paths. os.path.join(TCMS_ROOT_PATH,&apos;static&apos;), #&apos;/usr/lib/python2.7/site-packages/Nitrate-4.1-py2.7.egg/tcms/static/&apos;,# &apos;/home/nitrate/projects/site/assets&apos;,)# List of finder classes that know how to find static files in# various locations.STATICFILES_FINDERS = ( &apos;django.contrib.staticfiles.finders.FileSystemFinder&apos;, &apos;django.contrib.staticfiles.finders.AppDirectoriesFinder&apos;,)# Make this unique, and don&apos;t share it with anybody.SECRET_KEY = &apos;^8y!)$0t7yq2+65%&amp;_#@i^_o)eb3^q--y_$e7a_=t$%$1i)zuv&apos;TEMPLATES = [ &#123; &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, &apos;DIRS&apos;: [ os.path.join(TCMS_ROOT_PATH, &apos;templates/&apos;).replace(&apos;\\&apos;, &apos;/&apos;), ], &apos;APP_DIRS&apos;: True, &apos;OPTIONS&apos;: &#123; &apos;debug&apos;: True, &apos;context_processors&apos;: [ &apos;django.contrib.auth.context_processors.auth&apos;, &apos;django.template.context_processors.debug&apos;, &apos;django.template.context_processors.i18n&apos;, &apos;django.template.context_processors.media&apos;, &apos;django.template.context_processors.static&apos;, &apos;django.template.context_processors.tz&apos;, &apos;django.contrib.messages.context_processors.messages&apos;, # Added for Nitrate &apos;django.template.context_processors.request&apos;, &apos;tcms.core.context_processors.admin_prefix_processor&apos;, &apos;tcms.core.context_processors.auth_backend_processor&apos;, &apos;tcms.core.context_processors.request_contents_processor&apos;, &apos;tcms.core.context_processors.settings_processor&apos;, ], &#125;, &#125;,]MIDDLEWARE_CLASSES = ( &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;, &apos;django.middleware.locale.LocaleMiddleware&apos;, &apos;django.middleware.common.CommonMiddleware&apos;, &apos;tcms.core.middleware.CsrfDisableMiddleware&apos;, &apos;django.middleware.csrf.CsrfViewMiddleware&apos;, &apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;, &apos;django.contrib.messages.middleware.MessageMiddleware&apos;,)ROOT_URLCONF = &apos;tcms.urls&apos;# Python dotted path to the WSGI application used by Django&apos;s runserver.WSGI_APPLICATION = &apos;tcms.wsgi.application&apos;INSTALLED_APPS = ( &apos;django.contrib.admin&apos;, &apos;django.contrib.admindocs&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.sites&apos;, &apos;django.contrib.staticfiles&apos;, &apos;django_comments&apos;, &apos;kobo.django.xmlrpc&apos;, &apos;tinymce&apos;, &apos;tcms.core.contrib.auth.apps.AppConfig&apos;, &apos;tcms.core.contrib.comments.apps.AppConfig&apos;, &apos;tcms.core.contrib.linkreference&apos;, &apos;tcms.core.logs&apos;, &apos;tcms.integration.bugzilla&apos;, &apos;tcms.integration.errata&apos;, &apos;tcms.management&apos;, &apos;tcms.profiles&apos;, &apos;tcms.testcases&apos;, &apos;tcms.testplans&apos;, &apos;tcms.testruns&apos;, &apos;tcms.xmlrpc.apps.AppConfig&apos;, # core app must be here in order to use permissions created during creating # modules for above apps. &apos;tcms.core.apps.AppConfig&apos;,)SESSION_SERIALIZER = &apos;django.contrib.sessions.serializers.JSONSerializer&apos;## Default apps settings## Define the custom comment app# http://docs.djangoproject.com/en/dev/ref/contrib/comments/custom/COMMENTS_APP = &apos;tcms.core.contrib.comments&apos; # &apos;nitrate_comments&apos;## XML-RPC interface settings## XML-RPC methodsXMLRPC_METHODS = &#123; &apos;TCMS_XML_RPC&apos;: ( (&apos;tcms.xmlrpc.api.auth&apos;, &apos;Auth&apos;), (&apos;tcms.xmlrpc.api.build&apos;, &apos;Build&apos;), (&apos;tcms.xmlrpc.api.env&apos;, &apos;Env&apos;), (&apos;tcms.xmlrpc.api.product&apos;, &apos;Product&apos;), (&apos;tcms.xmlrpc.api.testcase&apos;, &apos;TestCase&apos;), (&apos;tcms.xmlrpc.api.testcaserun&apos;, &apos;TestCaseRun&apos;), (&apos;tcms.xmlrpc.api.testcaseplan&apos;, &apos;TestCasePlan&apos;), (&apos;tcms.xmlrpc.api.testopia&apos;, &apos;Testopia&apos;), (&apos;tcms.xmlrpc.api.testplan&apos;, &apos;TestPlan&apos;), (&apos;tcms.xmlrpc.api.testrun&apos;, &apos;TestRun&apos;), (&apos;tcms.xmlrpc.api.user&apos;, &apos;User&apos;), (&apos;tcms.xmlrpc.api.version&apos;, &apos;Version&apos;), (&apos;tcms.xmlrpc.api.tag&apos;, &apos;Tag&apos;), ),&#125;XMLRPC_TEMPLATE = &apos;xmlrpc.html&apos;# Cache backendCACHES = &#123; &apos;default&apos;: &#123; &apos;BACKEND&apos;: &apos;django.core.cache.backends.locmem.LocMemCache&apos;, &#125;&#125;SESSION_ENGINE = &apos;django.contrib.sessions.backends.cached_db&apos;# Needed by django.core.context_processors.debug:# See http://docs.djangoproject.com/en/dev/ref/templates/api/#django-core-context-processors-debugINTERNAL_IPS = (&apos;127.0.0.1&apos;, )# Authentication backends# For the login/register/logout reaon, we only support the internal auth backends.AUTHENTICATION_BACKENDS = ( &apos;tcms.core.contrib.auth.backends.DBModelBackend&apos;,)## Mail settings## Set the default send mail address# See http://docs.djangoproject.com/en/dev/ref/settings/#email-backendEMAIL_HOST = &apos;&apos;EMAIL_PORT = 25EMAIL_FROM = &apos;noreply@foo.com&apos;EMAIL_SUBJECT_PREFIX = &apos;[TCMS] &apos;EMAILS_FOR_DEBUG = []ENABLE_ASYNC_EMAIL = TrueCELERY_BROKER_URL = &apos;redis://&apos;# Celery worker settingsCELERY_TASK_RESULT_EXPIRES = 60 * 2CELERY_RESULT_BACKEND = &apos;db+sqlite:///celery-results.db&apos;CELERYD_TIMER_PRECISION = 120CELERY_IGNORE_RESULT = TrueCELERY_MAX_CACHED_RESULTS = -1CELERY_DEFAULT_RATE_LIMIT = &apos;250/m&apos;# TCMS email behavior settingsPLAN_EMAIL_TEMPLATE = &apos;mail/change_plan.txt&apos;PLAN_DELELE_EMAIL_TEMPLATE = &apos;mail/delete_plan.txt&apos;CASE_EMAIL_TEMPLATE = &apos;mail/edit_case.txt&apos;CASE_DELETE_EMAIL_TEMPLATE = &apos;mail/delete_case.txt&apos;# TCMS Bug System settings# Set default bug system to bugzillaDEFAULT_BUG_SYSTEM_ID = 1# Maximum upload file size, default set to 5MB.# 2.5MB - 2621440# 5MB - 5242880# 10MB - 10485760# 20MB - 20971520# 50MB - 5242880# 100MB 104857600# 250MB - 214958080# 500MB - 429916160MAX_UPLOAD_SIZE = 5242880# PaginationPLAN_RUNS_PAGE_SIZE = 20# Site-specific messages# The site can supply optional &quot;message of the day&quot; style banners, similar to# /etc/motd. They are fragments of HTML.# This if set, is shown on the login/registration screens.# MOTD_LOGIN = &apos;&apos;# The URLS will be list in footer# Example:#FOOTER_LINKS = (# (&apos;mailto:nitrate-dev-list@example.com&apos;, &apos;Contact Us&apos;),# (&apos;mailto:nitrate-admin@example.com&apos;, &apos;Request Permission&apos;),# (&apos;http://foo.com&apos;, &apos;foo&apos;)#)FOOTER_LINKS = ()# Attachement file download path# it could be spcified to a different out of MEDIA_URL# FILE_UPLOAD_DIR = path.join(MEDIA_DIR, &apos;uploads&apos;).replace(&apos;\\&apos;,&apos;/&apos;),FILE_UPLOAD_DIR = &apos;/var/nitrate/uploads&apos;# Enable the administrator delete permission# In another word it&apos;s set the admin to super user or not.SET_ADMIN_AS_SUPERUSER = False## Authentication backend settings## Bugzilla author xmlrpc url# Required by bugzilla authentication backendBUGZILLA3_RPC_SERVER = &apos;&apos;BUGZILLA_URL = &apos;&apos;# JIRA URLJIRA_URL = &apos;&apos;# Turn on/off bugzilla external trackerBUGZILLA_EXTERNAL_TRACKER = False# Turn on/off listening signals sent by models.LISTENING_MODEL_SIGNAL = True# Kerberos settings# Required by kerberos authentication backendKRB5_REALM = &apos;&apos;# Integration with Errata system, used to linkify the Errata ID# A valid Errata URL:# https://errata.devel.example.com/errata/stateview/&#123;Errata ID&#125;ERRATA_URL_PREFIX = &apos;&apos;# user guide url:USER_GUIDE_URL = &apos;&apos;# Default page size for showing each possible query result. This provides a# consistent user experiece to users.DEFAULT_PAGE_SIZE = 20# Disable TCMS to produce test run progress info to consumers by qpid for# reducing unnecessary I/O access and errata does not subscribe tcms msg now.# If you want to continue sending msg to qpid, please overwrite it in product# .py and make sure qpid config is correct.ENABLE_QPID = False# TCMS use Piwik to track request.ENABLE_PIWIK_TRACKING = False# Piwik site id, generate by eng-opsPIWIK_SITE_ID = &apos;&apos;# Piwik api url without schema.PIWIK_SITE_API_URL = &apos;&apos;# Piwik js lib url without schemaPIWIK_SITE_JS_URL = &apos;&apos;# A sample logging configuration. The only tangible logging# performed by this configuration is to send an email to# the site admins on every HTTP 500 error when DEBUG=False.# See http://docs.djangoproject.com/en/dev/topics/logging for# more details on how to customize your logging configuration.LOGGING = &#123; &apos;version&apos;: 1, &apos;disable_existing_loggers&apos;: False, &apos;formatters&apos;: &#123; &apos;verbose&apos;: &#123; &apos;format&apos;: &apos;%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s&apos; &#125;, &apos;simple&apos;: &#123; &apos;format&apos;: &apos;[%(asctime)s] %(levelname)s %(message)s&apos; &#125;, &apos;xmlrpc_log&apos;: &#123; &apos;format&apos;: &apos;[%(asctime)s] %(levelname)s XMLRPC %(process)d &quot;%(message)s&quot;&apos; &#125;, &#125;, &apos;filters&apos;: &#123; &apos;require_debug_false&apos;: &#123; &apos;()&apos;: &apos;django.utils.log.RequireDebugFalse&apos; &#125; &#125;, &apos;handlers&apos;: &#123; &apos;console&apos;: &#123; &apos;level&apos;: &apos;DEBUG&apos;, &apos;class&apos;: &apos;logging.StreamHandler&apos;, &apos;formatter&apos;: &apos;simple&apos; &#125;, &apos;xmlrpc&apos;: &#123; &apos;level&apos;: &apos;DEBUG&apos;, &apos;class&apos;: &apos;logging.StreamHandler&apos;, &apos;formatter&apos;: &apos;xmlrpc_log&apos;, &#125;, &apos;mail_admins&apos;: &#123; &apos;level&apos;: &apos;ERROR&apos;, &apos;filters&apos;: [&apos;require_debug_false&apos;], &apos;class&apos;: &apos;django.utils.log.AdminEmailHandler&apos; &#125;, &#125;, &apos;loggers&apos;: &#123; &apos;django.request&apos;: &#123; &apos;handlers&apos;: [&apos;mail_admins&apos;], &apos;level&apos;: &apos;ERROR&apos;, &apos;propagate&apos;: True, &#125;, &apos;nitrate.xmlrpc&apos;: &#123; &apos;handlers&apos;: [&apos;xmlrpc&apos;], &apos;level&apos;: &apos;DEBUG&apos;, &apos;propagate&apos;: True, &#125;, &#125;&#125;TINYMCE_DEFAULT_CONFIG = &#123; &apos;mode&apos;: &quot;exact&quot;, &apos;theme&apos;: &quot;advanced&quot;, &apos;language&apos;: &quot;en&quot;, &apos;skin&apos;: &quot;o2k7&quot;, &apos;browsers&apos;: &quot;gecko&quot;, &apos;dialog_type&apos;: &quot;modal&quot;, &apos;object_resizing&apos;: &apos;true&apos;, &apos;cleanup_on_startup&apos;: &apos;true&apos;, &apos;forced_root_block&apos;: &quot;p&quot;, &apos;remove_trailing_nbsp&apos;: &apos;true&apos;, &apos;theme_advanced_toolbar_location&apos;: &quot;top&quot;, &apos;theme_advanced_toolbar_align&apos;: &quot;left&quot;, &apos;theme_advanced_statusbar_location&apos;: &quot;none&quot;, &apos;theme_advanced_buttons1&apos;: &quot;formatselect,&quot; &quot;bold,italic,&quot; &quot;underline,&quot; &quot;bullist,&quot; &quot;numlist,&quot; &quot;link,&quot; &quot;unlink,&quot; &quot;image,&quot; &quot;search,&quot; &quot;|,&quot; &quot;outdent,&quot; &quot;indent,&quot; &quot;hr,&quot; &quot;fullscreen,&quot; &quot;|,&quot; &quot;help&quot;, &apos;theme_advanced_buttons2&apos;: &quot;tablecontrols&quot;, &apos;theme_advanced_buttons3&apos;: &quot;&quot;, &apos;theme_advanced_path&apos;: &apos;false&apos;, &apos;theme_advanced_blockformats&apos;: &quot;p,h2,h3,h4,div,code,pre&quot;, &apos;theme_advanced_styles&apos;: &quot;[all] clearfix=clearfix;&quot; &quot;[p] summary=summary;&quot; &quot;[div] code=code;&quot; &quot;[img] img_left=img_left;&quot; &quot;[img] img_left_nospacetop=img_left_nospacetop;&quot; &quot;[img] img_right=img_right;&quot; &quot;[img] img_right_nospacetop=img_right_nospacetop;&quot; &quot;[img] img_block=img_block;&quot; &quot;[img] img_block_nospacetop=img_block_nospacetop;&quot; &quot;[div] column span-2=column span-2;&quot; &quot;[div] column span-4=column span-4;&quot; &quot;[div] column span-8=column span-8&quot;, &apos;height&apos;: &apos;300&apos;, &apos;width&apos;: &apos;100%&apos;, &apos;urlconverter_callback&apos;: &apos;myCustomURLConverter&apos;, &apos;plugins&apos;: &quot;table,safari,&quot; &quot;advimage,&quot; &quot;advlink,&quot; &quot;fullscreen,&quot; &quot;visualchars,&quot; &quot;paste,&quot; &quot;media,&quot; &quot;template,&quot; &quot;searchreplace,&quot; &quot;emotions,&quot;, &apos;table_styles&apos;: &quot;Header 1=header1;&quot; &quot;Header 2=header2;&quot; &quot;Header 3=header3&quot;, &apos;table_cell_styles&apos;: &quot;Header 1=header1;&quot; &quot;Header 2=header2;&quot; &quot;Header 3=header3;&quot; &quot;Table Cell=tableCel1&quot;, &apos;table_row_styles&apos;: &quot;Header 1=header1;&quot; &quot;Header 2=header2;&quot; &quot;Header 3=header3;&quot; &quot;Table Row=tableRow1&quot;,&#125;LOCALE_PATHS = ( os.path.join(TCMS_ROOT_PATH, &apos;locale&apos;),)TESTOPIA_XML_VERSION = &apos;1.1&apos; 需要注意的： 检查INSTALLED_APPS中，是否有django.contrib.staticfiles，很重要！ DEBUG开关 数据库配置 STATIC_ROOT,STATIC_URL,STATICFILES_DIRS，这三个，真的真的很重要！并且很容易就出问题，看我注释了那么多行就知道我是试了多少种组合了 前三条没什么可说的，关键就是第四条，先贴出个第三个坑:1django.core.exceptions.ImproperlyConfigured: The STATICFILES_DIRS setting should not contain the STATIC_ROOT setting 这个是在进行数据初始化时候报的错，问题很好看，字面意思就是，然后我就开始各种尝试配置STATIC_ROOT和STATICFILES_DIRS，首先先解释一下这个配置的作用，首先，配置的是路径，文件夹的路径，作用就是存放静态文件，各种js,css等，在你页面加载的静态文件，都在这个文件夹里。在Django项目进行部署时：1python manage.py collectstatic 命令就会把所有需要的静态文件都复制到你配置的STATIC_ROOT文件夹中。所以STATIC_ROOT配置的是你app级的静态文件保存地址。那么STATICFILES_DIRS呢，这个文件夹，可以看成是所有app公共的静态文件的保存地址，当需要加载静态文件时，django会首先在公共的文件中查找，然后去app级的文件夹查找。至于STATIC_URL这个配置其实就是为了映射STATIC_ROOT，值基本配STATIC_URL = &#39;/static/&#39;即可。 开启服务首先是初始化数据：1django-admin.py migrate --settings=tcms.settings.product 将Nitrate一些必须的数据，表初始化；然后是加载静态文件：1django-admin.py collectstatic --settings=tcms.settings.product 根据你指定的配置，将静态文件拷贝到指定文件夹；然后是创建超级管理员：1django-admin.py createsuperuser --settings=tcms.settings.product 最后，起服务：1django-admin.py runserver --settings=tcms.settings.product 到浏览器上http://127.0.0.1:8000开始折腾吧~~~ 几个问题debug-toolbar当打开DEBUG，在进行初始化时，可能会报错：1no module named debug-toolbar 很明显，缺包，装包，不过包名不叫debug-toolbar,1yum install django-debug-toolbar 即可。 django.core.exceptions.ImproperlyConfigured: The STATICFILES_DIRS setting should not contain the STATIC_ROOT setting也是字面意思，STATIC_ROOT配置不能包含在STATICFILES_DIRS中，为什么会遇到这个问题，这玩意是我在第一次起服务没报错，但是页面静态文件一个都获取不到，整个页面朴素的不像话时候，尝试解决引发的另一个问题。先说说页面元素不加载，当初我配置是看网上有介绍STATICFILES_DIRS可以注释，不需要配，然后我就把STATIC_ROOT配成公共文件地址，结果在页面打开Nitrate时候，所有静态文件都是类似于：1&quot;GET /static/media/css/bootstrap/bootstrap.css HTTP/1.1&quot; 404 5904 这样的问题，整个页面就朴素的不行。。。然后又尝试把STATIC_ROOT注释，这次报的是代码中指明了app配置，STATIC_ROOT该项不能少这样的报错；然后两个都保留，这次就出现了上面那个错；再一次，在没看setting.py文件前，把STATIC_ROOT设置成了公共的，STATICFILES_DIRS设置成了app的，一如既往，静态文件全部加载不出来。。最后才修改成上述配置文件样（试过的组合不止这些，反正是折腾死，还怀疑过是copy静态文件时，少拷了个文件，都想改源码了，唉。。。）所以这个问题解决很简单，把STATIC_ROOT设置成了app的，STATICFILES_DIRS设置成了公共的。 DATABASES is improperly configured. Please supply the ENGINE value这个报错遇到过好几个，基本是俩原因： 改配置文件，输错了 nitrate用户没有权限检查的改了即可。 后记周五下午在公司没有搭建成功，搭的都心累了，成果就是一及其朴素的页面；周天早上6点钟开始折腾，一直弄到下午，才完完整整的搭完，唉，真的是个充实的周末…目前环境是搭建在虚拟机中，访问也是只能虚拟机中的Firefox输入http://127.0.0.1:8000才能访问，后面需要结合appach和wsgi，至少是完成公司局域网内访问，这个应该挺简单，再弄。。。 参考文档 Collecting staticfiles throws ImproperlyConfigured Managing static filesDjango 使用 Bootstrap，在 DEBUG = True 模式下，部分 js、css 提示 404 错误settings.py中的静态文件管理设置django中的setting最佳配置小结 ============================================================================================================================================================================================来更新接下来的部署了！ 使用apache&amp;mod_wsgi部署django项目 使用apache和mod_wsgi来部署Nitrate，使得不需要一直在虚拟机里面的浏览器才能打开Nitrate。 安装httpd&amp;mod_wsgi1yum install httpd mod_wsgi 创建上传文件夹创建长传文件夹，并且修改用户及属组：12mkdir -p /var/nitrate/uploadschown apache:apache /var/nitrate/uploads 配置mod_wsgi在/etc/httpd/conf.d文件夹下，创建文件wsgi.conf，修改内容：1LoadModule wsgi_module modules/mod_wsgi.so 配置Apache&amp;mod_wsgi在/etc/httpd/conf.d文件夹下创建nitrate的配置文件nitrate-httpd.conf，具体内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# Deployment using mod_wsgi## Useful documentation:# https://docs.djangoproject.com/en/1.5/howto/deployment/wsgi/# Force the use of ssl:#&lt;IfModule mod_rewrite.c&gt;# RewriteEngine on# RewriteCond %&#123;HTTPS&#125; off# RewriteRule ^(.*)$ https://%&#123;HTTP_HOST&#125;%&#123;REQUEST_URI&#125;#&lt;/IfModule&gt;# Make sure static files collected to this dir# Ref https://docs.djangoproject.com/en/1.5/ref/contrib/staticfiles/#django-admin-collectstatic#Alias /static /usr/share/nitrate/staticiAlias /static /home/nitrate/projects/site/assets#Alias /usr/lib/python2.7/site-packages/Nitrate-4.1-py2.7.egg/tcms/static# Limit threads forked:# prefork MPM StartServers 5MinSpareServers 5MaxSpareServers 10MaxClients 256MaxRequestsPerChild 0# Configurations for mod_wsgiWSGIScriptAlias / /usr/lib/python2.7/site-packages/tcms/wsgi.pyWSGIPythonPath /usr/lib/python2.7/site-packagesWSGIPassAuthorization On&lt;Location &quot;/&quot;&gt; # ==================== # Handler for mod_wsgi # ==================== SetHandler wsgi-script Options All AllowOverride All Require all granted LimitRequestBody 10485760 AddOutputFilterByType DEFLATE text/html text/plain text/xml text/javascript application/x-javascript text/css ErrorDocument 401 &quot;Your request is unauthorization.&quot;&lt;/Location&gt;&lt;Location &quot;/static&quot;&gt; SetHandler None # Disable auth on the static content, so that we&apos;re aren&apos;t forced to # use Kerberos. Doing so would remove &quot;Expires&quot; headers from the static # content, which would lead to poor page-load times. AuthType none Satisfy Any Allow from All # Many file types are likely to benefit from compression # Enable gzip compression on them: AddOutputFilterByType DEFLATE text/html text/plain text/xml text/javascript application/x-javascript text/css # Set far-future Expires headers on static content # (trac 184): ExpiresActive On ExpiresDefault &quot;access plus 10 years&quot;&lt;/Location&gt; 需要注意的几个配置：123Alias /static /home/nitrate/projects/site/assetsWSGIScriptAlias / /usr/lib/python2.7/site-packages/tcms/wsgi.pyWSGIPythonPath /usr/lib/python2.7/site-packages 都修改成你自己的本地路径 httpd.conf说实话，我对这玩意是真的不熟悉，就基本没改，路径：/etc/httpd/conf/httpd.conf，只需要修改：12ServerName example.com:80Listen ip_address:80 我比较懒，直接一个改成localhost，另一个改为80，就完工了。然后就可以起服务了！！！1systemctl start httpd.service 在本地windows下的浏览器应该就可以直接访问虚拟机的ip来访问nitrate了 可能遇到的问题反正对我来说不是可能，全遇到了。。 httpd服务启动失败这个问题，原因很多，直接看日志比较正常，我是因为端口配错了才出现 页面报错，无法连接mysql，报权限问题首先，检查是否有权限，在确定有权限情况下，基本是系统的问题了。解释一下，虚拟机装的是centos，centos在默认情况下SELinux是打开的，这玩意，是不允许远程连接MySQL资源的。。。所以简单的解决：1setenforce 0 网上有个建议做法：1setsebool httpd_can_network_connect_db 1 允许Apache访问外部MySQL资源 浏览器访问虚拟机IP，静态文件不加载和之前碰到的配路径一样，所有静态文件加载都是403，加载不了，这次，确定不是路径配置的问题，那就是权限问题呗，给你/static目录下的文件赋权限，有可执行权限即可。1chmod -R 755 /static]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>Nitrate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下升级python2.7到3.6]]></title>
    <url>%2F2018%2F04%2F20%2FCentos%E4%B8%8B%E5%8D%87%E7%BA%A7python2-7%E5%88%B03-6%2F</url>
    <content type="text"><![CDATA[Centos下，修改python版本，保留原2.7.5版本同时，更改默认版本为3.6 保留原版本由于yum中会配置python版本，在进行python版本更新时，需要先将yum的配置文件都更改了。首先，切用户1su - root 1mv /usr/bin/python2.7 /usr/bin/python2.7.5 # 保留默认版本python为python2.7.5 1ln -s /usr/bin/python2.7.5 /usr/local/bin/python2.7.5 # 创建软连接 1ls -al /usr/bin/yum* # 查看/usr/bin/目录下所有yum文件，共7个 一个一个改：1#!/usr/bin/python —&gt; #!/usr/bin/python2.7.5 12vi /usr/libexec/urlgrabber-ext-down # 修改/usr/libexec/目录下 urlgrabber-ext-down#!/usr/bin/python —&gt; #!/usr/bin/python2.7.5 安装python3.6安装配置环境wget首先检查是否有安装wget，没有则需要安装：1yum install wget 准备编译环境12yum groupinstall &apos;Development Tools&apos;yum install zlib-devel bzip2-devel openssl-devel ncurses-devel 开始安装123456789101112131415161718192021222324wget https://www.python.org/ftp/python/3.6.2/Python-3.6.2.tgztar zxvf Python-3.6.2.tgzcd Python-3.6.2./configuremake allmake installmake cleanmake distcleanrm -rf /usr/bin/pythonrm -rf /usr/bin/python3rm -rf /usr/bin/python3.6ln -s /usr/local/bin/python3.6 /usr/bin/pythonln -s /usr/local/bin/python3.6 /usr/bin/python3ln -s /usr/local/bin/python3.6 /usr/bin/python3.6/usr/bin/python -V/usr/bin/python3 -V/usr/bin/python3.6 -Vrm -rf /usr/local/bin/pythonrm -rf /usr/local/bin/python3ln -s /usr/local/bin/python3.6 /usr/local/bin/pythonln -s /usr/local/bin/python3.6 /usr/local/bin/python3python -Vpython3 -Vpython3.6 -V 123456[root@localhost Python-3.6.2]# python -VPython 3.6.2[root@localhost Python-3.6.2]# python3 -VPython 3.6.2[root@localhost Python-3.6.2]# python3.6 -VPython 3.6.2 安装成功~ 参考链接]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[切换163yum源]]></title>
    <url>%2F2018%2F04%2F19%2F%E5%88%87%E6%8D%A2163yum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[来篇福利文 经常装环境的应该遇过下包基本没动静，基于这“伟大”的互联网环境，下包真的是很心累的一件事，好在国内有志之士还是弄了很多福利的，下面：Centos切换国内163yum源 前言前提条件，linux服务器支持wget，没有则装一个：1yum install -y wget 装好之后，开始切换yum源。 备份首先，搭环境的必要素质，修改配置文件之前，一定要先备份！（踩了n多坑的教训）1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载163源切换到/etc/yum.repos.d，wget下载163源配置文件1wget http://mirrors.163.com/.help/CentOS6-Base-163.repo 改名修改下载完成的文件的名称1mv /etc/yum.repos.d/CentOS6-Base-163.repo /etc/yum.repos.d/CentOS-Base.rep 生成缓存12yum clean allyum makecache 完工~~~]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之SQL优化系列（三）]]></title>
    <url>%2F2018%2F04%2F18%2FMySQL%E4%B9%8BSQL%E4%BC%98%E5%8C%96%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[MySQL精准分析执行时间 当进行sql性能瓶颈分析时，第一反应肯定是查看sql执行时间，那么当使用慢查询日志，以及explain都无法知晓具体信息时，怎么分析。 Query ProfilerQuery Profiler是MYSQL自带的一种query诊断分析工具，通过它可以分析出一条SQL语句的性能瓶颈在什么地方。通过show variables like &quot;%pro%&quot;;可以查看该工具是否开启：1234567891011121314151617mysql&gt; show variables like &quot;%pro%&quot;;+------------------------------------------+-------+| Variable_name | Value |+------------------------------------------+-------+| check_proxy_users | OFF || have_profiling | YES || mysql_native_password_proxy_users | OFF || performance_schema_max_program_instances | -1 || profiling | OFF || profiling_history_size | 15 || protocol_version | 10 || proxy_user | || sha256_password_proxy_users | OFF || slave_compressed_protocol | OFF || stored_program_cache | 256 |+------------------------------------------+-------+11 rows in set, 1 warning (0.00 sec) 发现当前为关闭状态，手动开启：12mysql&gt; set profiling = 1;Query OK, 0 rows affected, 1 warning (0.00 sec) 使用首先执行几条sql，作为分析样本：1234567mysql&gt; select sleep(3);+----------+| sleep(3) |+----------+| 0 |+----------+1 row in set (3.00 sec) 1234567mysql&gt; select 1;+---+| 1 |+---+| 1 |+---+1 row in set (0.00 sec) 查看执行情况：123456789mysql&gt; show profiles;+----------+------------+-----------------------------+| Query_ID | Duration | Query |+----------+------------+-----------------------------+| 1 | 0.00325925 | show variables like &quot;%pro%&quot; || 2 | 2.99971075 | select sleep(3) || 3 | 0.00051050 | select 1 |+----------+------------+-----------------------------+3 rows in set, 1 warning (0.00 sec) 可以看出具体执行时间，若想查看具体那一条SQL的具体信息：123456789101112131415161718mysql&gt; show profile for query 2; +----------------------+----------+ | Status | Duration | +----------------------+----------+ | starting | 0.000103 | | checking permissions | 0.000008 | | Opening tables | 0.000006 | | init | 0.000016 | | optimizing | 0.000008 | | executing | 0.000018 | | User sleep | 2.999385 | | end | 0.000016 | | query end | 0.000009 | | closing tables | 0.000005 | | freeing items | 0.000115 | | cleaning up | 0.000023 | +----------------------+----------+ 12 rows in set, 1 warning (0.00 sec) 对系统分析查看执行sql中对系统的影响，例如，查看磁盘IO：123456789101112131415161718mysql&gt; show profile block io for query 2;+----------------------+----------+--------------+---------------+| Status | Duration | Block_ops_in | Block_ops_out |+----------------------+----------+--------------+---------------+| starting | 0.000103 | NULL | NULL || checking permissions | 0.000008 | NULL | NULL || Opening tables | 0.000006 | NULL | NULL || init | 0.000016 | NULL | NULL || optimizing | 0.000008 | NULL | NULL || executing | 0.000018 | NULL | NULL || User sleep | 2.999385 | NULL | NULL || end | 0.000016 | NULL | NULL || query end | 0.000009 | NULL | NULL || closing tables | 0.000005 | NULL | NULL || freeing items | 0.000115 | NULL | NULL || cleaning up | 0.000023 | NULL | NULL |+----------------------+----------+--------------+---------------+12 rows in set, 1 warning (0.00 sec) 可以完整的看出select sleep(3);该sql执行过程中对磁盘IO的影响。类似的还有：12345mysql&gt; show profile cpu for query 2;mysql&gt; show profile memory for query 2;mysql&gt; show profile swaps for query 2;mysql&gt; show profile context switches for query 2;mysql&gt; show profile all for query 2;]]></content>
      <categories>
        <category>MySQL-SQL优化</category>
      </categories>
      <tags>
        <tag>profiler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[loadruner日常总结]]></title>
    <url>%2F2018%2F04%2F18%2Floadruner%E6%97%A5%E5%B8%B8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[日常工作中遇到的loadrunner的相关问题的总结： 前言首先，使用的环境（版本）：123WIN7 企业版 Service Pack1loadrunner 12.50IE 11 环境说明本来用习惯了，到了新公司第一件事就是装了WIN10，loadrunner版本使用的也是loadrunner 12.50，然后，开始工作，录制脚本时候，开始了各种神坑问题，对了，先说一句，笔记本是Thinkpad T430（不是win 10系统的锅）。录制时候就开始了坑死人的经历，第一个是基本相当于不支持chrome，想用chrome录制，必须开代理或者fiddle，简直是愁；换成firefox，浏览器都打不开，用IE，各种的需要安全证书，或者就是压根浏览器直接未响应。好不容易开着代理，用chrome录制好了，回放，70%的概率电脑会蓝屏，无语至极。 艰难的环境搭建没办法，日常工作现在就是在性能测试上，只好放弃win10，转用win7了（再次再次提醒，T430千万别用win10来搭配loadrunner！！！）再次重装系统，这次用了什么鬼纯净版，也就是ghost版，是人为在官方原本基础上的优化版，唉，装是装好了，事又来了，众所周知，loadrunner和浏览器的兼容实在是个很深的坑尤其是64位的windows系统，更是能选用的很少。试了各种chrome，firefox，ie甚至什么遨游，世界之窗，基本是快奔溃的状态。实验半天，基本兼容性是:1IE &gt; firefox &gt; chrome IE最好，firefox网上基本是建议用25左右的版本，但是，没有64位的啊。。。chrome就别提了，老样子，要么是要开代理，要么是直接打开浏览器就未响应。所以，首选还是IE啊，但是，试了下，公司的测试网站，在IE8上压根就打不开（win7自带是IE8），版本太低了！必须要升级到IE11，升级是简单，找到windows update搜索下载，下载完更新即可，安装完成需要重启系统，然后坑来了：ghost版装的系统，直接帮你“优化了”权限，基本你是默认就是管理员，然后在安装windows更新时候，问题就来了，系统会在判断你权限时候，发现权限混乱，直接更新失败，返回还原点，windows——update failure，error code：80070005，唉，简直是半疯。在实验了其他n中手动更新IE的方法失败之后，只能放弃。直接上MSDN下载官方镜像，重新安装系统，这次终于是成功将IE8更新到IE11了。 常见问题CV证书在录制时候，经常会遇到不适用loadrunner录制，网页可以打开，使用loadrunner录制，网页打开显示“无法此页”；可能在浏览器显示该页面之前，已经弹出了一个类似该网站CV证书。。。的弹窗提示，意思很明显，该测试网站，在你的浏览器安全证书中没有它的证书，所以浏览器的安全策略就过滤了该浏览器的连接，页面就打不开了。 解决办法在录制时候：点击Recoding Oftions，在Network栏，点击Mapping and Filtering，Port mapping选择WinINet level data，点击确定，录制即可。 loadrunner未响应该问题，网上有很多解答，基本第一条就是1IE - Internet选项 - 高级 - 启用第三方软件扩展（取消勾选） 然后，我是直接用管理员登录的系统，再进行录制就可以了。附上网上有个很全的回答：loadrunner点击录制不响应 请求接口HTTP CODE 500在排除接口异常，使用其他如postman，soupui等工具直接请求可以成功返回数据情况下，查看使用loadrunner录制的脚本，是否在传参的时候将参数进行格式化，以JSON格式传参，我是遇到过很多次，直接使用loadrunner录制脚本，录制出来的脚本中缺少格式化:1&quot;EncType=application/json; charset=utf-8&quot;, 录制出来的脚本类似：12345678910web_custom_request(&quot;2018_1&quot;, &quot;URL=https://www.test.com/api/config/calendar/1/2018&quot;, &quot;Method=PUT&quot;, &quot;Resource=0&quot;, &quot;RecContentType=application/json&quot;, &quot;Referer=https://www.test.com/app&quot;, &quot;Snapshot=t16.inf&quot;, &quot;Mode=HTML&quot;, &quot;Body=&#123;\&quot;2018-11-01\&quot;:1&#125;&quot;, LAST); 这样请求，即使加上所有token，很可能还是会500，所以手工加上一句格式化json的即可。 后记loadrunner作为付费软件，限制其实还是挺多的，日常生活中遇到什么问题，还需要继续记录。P.S 做性能测试，真的是，能用Jmeter或者locust，真的，就转吧。。。破解个限制这么多的，实在是，唉。。。]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>loadrunner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOs7强制修改MySQL中root密码]]></title>
    <url>%2F2018%2F04%2F04%2FCentOs7%E5%BC%BA%E5%88%B6%E4%BF%AE%E6%94%B9MySQL%E4%B8%ADroot%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[centos7强制修改MySQL默认密码 前言最近需要搭建zabbix，需要在centos7上搭建MySQL服务器；这个很简单，直接命令：获取MySQL源：1sudo rpm -Uvh https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm 安装：1sudo yum install mysql-* --skip-broken 问题安装过程，由于公司网简直惨不忍睹，中间一度断掉了，都不知道哪边安装出错了。。。好不容易看着安装成功之后，查找默认的root密码：1grep &apos;temporary password&apos; /var/log/mysqld.log 然后就悲剧了，这个日志文件，压根就是空的，root密码跑哪玩去了！！！然后试了试，貌似好像可以起服务。。见鬼12systemctl start mysqldsystemctl status mysqld 不过这样还是进不了控制台啊，没密码啊，没办法，只有强制修改root密码。 强制修改密码首先强制修改配置文件，/etc/my.cnf添加：12[mysqld]skip-grant-tables=1 添加skip-grant-tables=1这行，然后重启MySQL服务。1systemctl restart mysqld 修改密码进入MySQL控制台：1mysql 打印：12345678910111213Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.21 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; 修改密码123use mysql;update user set authentication_string = password(&quot;xxxx&quot;) where user=&quot;root&quot;;flush privileges; 然后将/etc/my.cnf下skip-grant-tables=1注释掉，重启MySQL服务。 后续使用修改完成的root密码登录MySQL控制台之后，可以进入控制台：123456789101112131415mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.21Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; 但是有问题：12mysql&gt; show databases;ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. 按照提示，我们在修改root密码时候，应该使用的是alter而不是update来更新密码，所以，重新修改密码:12alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;QWEqwe+342&apos;;flush privileges; 再次重启服务即可。]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum安装软件失败]]></title>
    <url>%2F2018%2F04%2F04%2Fyum%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[centos运行yum报错解决办法 问题使用yum安装软件时，报错：12345Another app is currently holding the yum lock; waiting for it to exit... The other application is: PackageKit Memory : 130 M RSS (1.0 GB VSZ) Started: Wed Apr 4 10:44:50 2018 - 04:01 ago State : Sleeping, pid: 11199 解决该问题可能是由于系统目前处于自动升级状态，所以锁定了yum，只要强制关闭yum进程即可重新运行yum1rm -rf /var/run/yum.pid 优质yum源Remi repository 是包含最新版本 PHP 和 MySQL 包的 Linux 源，由 Remi 提供维护。有个这个源之后，使用 YUM 安装或更新 PHP、MySQL、phpMyAdmin 等服务器相关程序的时候就非常方便了。 12345wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmwget http://rpms.remirepo.net/enterprise/remi-release-7.rpmrpm -Uvh remi-release-7.rpm epel-release-latest-7.noarch.rpm# for RHEL onlysubscription-manager repos --enable=rhel-7-server-optional-rpms 参考文章]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos7</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之SQL优化系列（二）]]></title>
    <url>%2F2018%2F04%2F03%2FMySQL%E4%B9%8BSQL%E4%BC%98%E5%8C%96%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[通过explain分析低效SQL的执行计划 序言使用的数据库依然是mysql示例库sakila接着上篇的MySQL之SQL优化系列（一）当通过慢查询日志定位到执行效率较低的SQL之后，使用explain进行低效SQL的分析。 使用EXPLAIN分析低效SQL的执行计划使用EXPLAIN可以获取MySQL是如何执行SELECT语句的，包括在SELECT语句执行过程中表如何连接以及连接的顺序，如下示例SQL执行：12345678910111213141516171819202122232425262728mysql&gt; explain select sum(amount) from customer a,payment b where 1=1 and a.customer_id = b.customer_id and email=&apos;JANE.BENNETT@sakilacustomer.org&apos;\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: a partitions: NULL type: ALLpossible_keys: PRIMARY key: NULL key_len: NULL ref: NULL rows: 599 filtered: 10.00 Extra: Using where*************************** 2. row *************************** id: 1 select_type: SIMPLE table: b partitions: NULL type: ref possible_keys: idx_fk_customer_id key: idx_fk_customer_id key_len: 2 ref: sakila.a.customer_id rows: 26 filtered: 100.00 Extra: NULL 2 rows in set, 1 warning (0.01 sec) 字段解释： select_type:表示select的类型，常见取值有SIMPLE(简单表，不使用表连接或子查询)、PRIMARY(主查询，外层的查询)、UNION(UNION中的第二个或者后面的查询语句)、SUBQUERY(子查询中的第一个SELECT) table:输出结果集的表 type:表示MySQL在表中找到所需行的方法，或者称为访问类型，常见的有：1ALL —— index —— range —— ref —— eq_ref —— const,system —— NULL 从做到右，性能由最差到最好。示例： type=ALL，全表扫描，MySQL遍历全表来找到匹配行：123456789101112131415mysql&gt; explain select * from film limit 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: film partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 1000 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 2.type=index，索引全扫描，MySQL遍历整个索引来查询匹配的行：1mysql&gt; show index from film; 获取得到film表的索引：film_id(主键),title,language_id,original_language_id123456789101112131415mysql&gt; explain select title from film\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: film partitions: NULL type: index possible_keys: NULL key: idx_title key_len: 767 ref: NULL rows: 1000 filtered: 100.00 Extra: Using index 1 row in set, 1 warning (0.00 sec) 3.type=range,索引范围扫描，常见的有between,&gt;,&lt;等。4.type=ref，使用非唯一索引扫描或唯一索引的前缀扫描，返回匹配单独值得记录行，例如：123456789101112131415mysql&gt; explain select * from payment where customer_id=24\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: payment partitions: NULL type: ref possible_keys: idx_fk_customer_id key: idx_fk_customer_id key_len: 2 ref: const rows: 25 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 索引idx_fk_customer_id是非唯一索引，查询条件为等值查询条件customer_id=24，所以扫描索引的类型为ref。ref还经常出现在join操作中。5.type=eq_ref，类似ref，区别在于使用的索引是唯一索引，对于每一个索引的键值，表中只有一条记录匹配。换句换说，就是在进行多表连接时，使用得失primary key或者unique index作为关联条件。12345678910111213141516171819202122232425262728mysql&gt; explain select * from film a,film_text b where a.film_id = b.film_id\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: b partitions: NULL type: ALL possible_keys: PRIMARY key: NULL key_len: NULL ref: NULL rows: 1000 filtered: 100.00 Extra: NULL *************************** 2. row *************************** id: 1 select_type: SIMPLE table: a partitions: NULL type: eq_ref possible_keys: PRIMARY key: PRIMARY key_len: 2 ref: sakila.b.film_id rows: 1 filtered: 100.00 Extra: Using where 2 rows in set, 1 warning (0.00 sec) 6.type=const/system，表单中有最多一个匹配行，查询起来非常迅速，所以这个匹配行中的其他列的值可以被优化器在当前查询中当做常量来处理，例如，根据主键primary key或者唯一索引unique index进行的查询。12345678910111213141516alter table customer add unique index uk_email(email);mysql&gt; explain select * from (select * from customer where email=&apos;LINDA.WILLIAMS@sakilacustomer.org&apos;) a\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: customer partitions: NULL type: const possible_keys: uk_email key: uk_email key_len: 153 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 通过唯一索引uk_email访问的时候，类型type为const。 possible_keys：表示查询时可能使用的索引 key：表示实际使用的索引 key_len：使用到索引字段的长度、 rows：扫描行的数量 Extra：执行情况的说明和描述，包含不适合在其他列中显示但是对执行计划非常重要的额外信息。]]></content>
      <categories>
        <category>MySQL-SQL优化</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>explain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python性能测试框架locust（一）]]></title>
    <url>%2F2018%2F03%2F30%2Fpython%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6locust%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[基于python的性能测试框架LOCUST系列一 简介首先，这个框架是做性能测试的，然后，基于python编写！！！所以，不可能不研究研究啊。LOCUST英文意思是“蝗虫”，感受感受使用locust进行性能测试，并发请求就像铺天盖地的蝗虫一样攻击你的系统，嗯，想想都可怕。 在Locust测试框架中，测试场景是由纯python脚本编写，对于http以及https协议，可以使用python的requests库作为客户端。对于其他协议，locust也提供有接口。也就是说，只要我们使用python编写对应的请求，就能方便的用locust进行压力测试。 安装安装locust很简单，日常操作：1pip install locustio demo示例官方demo：12345678910111213141516171819202122232425262728293031#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle shi@time: 2018/3/30/030 16:59&quot;&quot;&quot;from locust import HttpLocust, TaskSet, taskclass UserBehavior(TaskSet): def on_start(self): &quot;&quot;&quot; on_start is called when a Locust start before any task is scheduled &quot;&quot;&quot; self.login() def login(self): self.client.post(&quot;/login&quot;, &#123;&quot;username&quot;: &quot;ellen_key&quot;, &quot;password&quot;: &quot;education&quot;&#125;) @task(2) def index(self): self.client.get(&quot;/&quot;) @task(1) def profile(self): self.client.get(&quot;/profile&quot;)class WebsiteUser(HttpLocust): task_set = UserBehavior host = &apos;http://example.com&apos; min_wait = 5000 max_wait = 9000 cmd进入该文件所在路径下，执行locust命令，即可开启locust web服务，默认端口808912345678E:\py_workspace\LocustTest\codings\TestScripts &#123;git&#125;&#123;lamb&#125; ls__init__.py __pycache__ locustfile.pyE:\py_workspace\LocustTest\codings\TestScripts &#123;git&#125;&#123;lamb&#125; locust[2018-03-30 17:22:44,919] 3HET0MVY93LITXF/INFO/locust.main: Starting web monitor at *:8089[2018-03-30 17:22:44,920] 3HET0MVY93LITXF/INFO/locust.main: Starting Locust 0.8.1 打开浏览器，输入url:http://localhost:8089即可访问locust web。 tips：使用locust打开服务前提是脚本名称是locustfile.py；否则需要执行指定脚本的命令：locust -f mylocustFile.py -P 7070指定文件和端口 demo简单分析官方的demo对于http://example.com进行压测，随机访问首页（/）以及页面（/profile）比例为2:1，每次请求间隔为5~9s。 后记locust现在还是刚刚开始接触，看着官方介绍的，功能相当齐全，尤其是我还是一个只有python编码能力的菜鸡。。。太对胃口了。。。好好研究！ 官网]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Locust</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[loadrunner监控Mysql]]></title>
    <url>%2F2018%2F03%2F30%2Floadrunner%E7%9B%91%E6%8E%A7Mysql%2F</url>
    <content type="text"><![CDATA[使用loadrunner监控mysql 前言最近工作需要研究怎么深度性能测试，使用的工具基本是loadrunner，jmeter或者基于python的框架locust。近期一段时间应该和lr打交道会比较多，lr最为一个收费的专业性能测试软件，功能是毋庸置疑的相当强大，但是，貌似我没有找到监控mysql的模块。。sql server倒是有，也可能是我远离lr太长时间了。 mysql性能监控在日常性能测试过程中，除了需要对系统TPS，RT这样的参数进行监控以及各服务器的CPU，MEMORY，IO之外，还要实时对数据库进行监控，因为接触的多的是mysql，就以MySQL为例。 当mysql出现运行缓慢，或者出于某种原因无法响应查询，可以监控以下几个指标来获取解决： 查询吞吐量 查询执行性能 连接情况 数据库缓冲池 吞吐量由于本篇重点是介绍监控MySQL，对于mysql的性能指标就只解释一种，以吞吐量为例：MySQL中有一个Questions的内部计数器，客户端每发送一个查询，改值加一。1234567mysql&gt; show global status like &quot;Questions&quot;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Questions | 665 |+---------------+-------+1 row in set (0.00 sec) 所以对Questions该指标进行监控，当该指标发生突变，如骤降或者骤增，很可能数据库出现了问题。 HP SiteScopeWIKIPEDIA给的解释：1HP SiteScope is agentless monitoring software focused on monitoring the availability and performance of distributed IT infrastructures, including Servers, Network devices and services, Applications and application components, operating systems and various IT enterprise components. 大致意思是：HP SiteScope是无代理监控软件，专注于监控分布式IT基础架构的可用性和性能，包括服务器，网络设备和服务，应用程序和应用程序组件，操作系统和各种IT企业组件。所以，HP SiteScope很适合用来监控MySQL。 安装网上找一圈硬是没找到安装包，很怀疑对于mysql的监控有更简单的方法，或者就是压根没人做开源的。。直接梯子到官网下了个11.3的版本： 度娘盘连接 密码：7l99mysql驱动密码：y9i8 安装很简单，压缩包打开，找到HPSiteScope_11.30_setup.exe一路next即可，mysql驱动放在D:\HP\SiteScope\java\lib\ext下。 LR监控MySQL操作安装完成HP SiteScope后，在浏览器输入url：http://127.0.0.1:8080/SiteScope即可打开主页 可能遇到的问题输入url之后，可能会遇见页面是空白的情况（我就遇到过），首先，别用chrome和firefox，这玩意貌似只能在IE上面打开；其次，你本地需要JDK环境（java -version）要求JDK1.6以上。最后，IE的internet选项中，把局域网设置里的代理勾掉。以上就是我解决的页面空白的三个办法（我全中过，折腾老半天） 进入HP SiteScope首页，在SiteScope上右键，新建组，输入组名之后，右键创建的组，新建监控器，选择数据库计数器，只需要配置几项：12345678910数据库连接URL: jdbc:mysql://localhost/sakila查询： show status数据库驱动程序： org.gjt.mm.mysql.Driver凭据：输入数据库用户名及密码计数器：选择计数器：Com_insert_select/Value Com_select/Value counters in error Questions/Value Select_scan/Value 点击验证保存，完成保存。 lr配置监控打开LR Contraller，配置完场景，在run页面，可用图，选择SiteScope图，右键SiteScope，点击打开，右击打开的SiteScope图，点击添加度量，弹出的窗口有两个添加，上面一个是添加服务器，我添加的是localhost端口8888，下一个添加是选择添加的组件，选择需要的添加组件，点击确定，即可完成配置。（没办法，图床都太坑了，所以全程无图。。。请原谅。。。） 后记官网下载的HP SiteScope是未破解版，有时间还是需要折腾个破解版的研究研究。工具是会用了，原理根本没去看，这是病，不懂原理就直接使用，总感觉不踏实。 参考地址]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>loadrunner</tag>
        <tag>SiteScope</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之SQL优化系列（一）]]></title>
    <url>%2F2018%2F03%2F09%2FMySQL%E4%B9%8BSQL%E4%BC%98%E5%8C%96%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[作为一个不知道几分之几的程序员，日常性能测试的关注点之一就是SQL的执行效率，SQL优化。 案例库mysql提供有类似oracle的scott库（root/tiger，至今记得接触oracle时候这个趣闻，创始人是库名，猫的名字是密码）的案例库sakila，基本可以使用来完成SQL优化的测试。 sakila库下载地址 压缩包中有三个文件：sakila-schema.sql，sakila-data.sql，sakila.mwb；sakila-schema.sql建库及表，sakila-data.sql插数据，sakila.mwb可以使用mysql workbench打开，是sakila的数据模型（MySQL Mode） MySQL workbench官方下载地址度娘盘地址&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;密码：25y4 安装完成：12345678910111213141516171819202122232425262728293031mysql&gt; use sakila;Database changedmysql&gt; show tables;+----------------------------+| Tables_in_sakila |+----------------------------+| actor || actor_info || address || category || city || country || customer || customer_list || film || film_actor || film_category || film_list || film_text || inventory || language || nicer_but_slower_film_list || payment || rental || sales_by_film_category || sales_by_store || staff || staff_list || store |+----------------------------+23 rows in set (0.00 sec) show status查看SQL执行频率MySQL可以通过show [session|global] status命令来查看服务器状态信息；其中session，global为可选参数，session表示显示当前连接的统计结果，global表示统计自数据库上次启动至今的信息，不写默认为session。示例：12345678910111213141516171819202122232425262728mysql&gt; show status like &apos;Com_%&apos;; +-----------------------------+-------+ | Variable_name | Value | +-----------------------------+-------+ | Com_admin_commands | 0 | | Com_assign_to_keycache | 0 | | Com_alter_db | 0 | | Com_alter_db_upgrade | 0 | | Com_alter_event | 0 | | Com_alter_function | 0 | | Com_alter_instance | 0 | | Com_alter_procedure | 0 | | Com_alter_server | 0 | | Com_alter_table | 2 | | Com_alter_tablespace | 0 | | Com_alter_user | 0 | | Com_analyze | 0 | | Com_begin | 0 | | Com_binlog | 0 | | Com_call_procedure | 0 | | Com_change_db | 3 | | Com_change_master | 0 | | Com_change_repl_filter | 0 | | Com_check | 0 | | Com_checksum | 0 | | Com_commit | 15 | | Com_create_db | 1 | ... 统计当前连接下的信息。 参数解释Com_xxx表示每个xxx语句执行的次数，通常比较关注的是以下几个：◆&ensp;Com_select：&ensp;执行SELECT操作的次数，执行一次累加1；◆&ensp;Com_insert：&ensp;执行INSERT操作的次数，对于批量插入的INSERT操作，只累加一次；◆&ensp;Com_update：&ensp;执行UPDATE操作的次数。◆&ensp;Com_delete：&ensp;执行DELETE操作的次数。上述参数对于所有的存储引擎的表操作都会进行累计，下面的参数，只针对InnoDB存储引擎：◆&ensp;Innodb_read：SELECT查询返回的行数。◆&ensp;Innodb_rows_inserted：执行INSERT操作插入的行数。◆&ensp;Innodb_rows_updated：执行UPDATE操作更新的行数。◆&ensp;Innodb_rows_deleted：执行DELETE操作删除的行数。通过以上参数，比较容易得出当前数据库的应用是插入更新为主还是查询操作为主，以及各种类型的SQL大致执行的比例是多少。（对于更新操作的技术，是对执行次数的技术，不论commit还是rollback都会累加）。对于事务型应用，通过Com_commit和Com_rollback可以了解事务提交和回滚的情况，对于回滚操作很频繁的数据库，可能意味着应用编写存在问题。另外，一下几个参数便于了解数据库的基本情况：◆&ensp;Connections：尝试连接MySQL服务器的次数。◆&ensp;Uptime：服务器工作时间。◆&ensp;Slow_queried：慢查询次数 定位执行效率低的SQL我在工作中，使用过两种方式来查看当前执行效率低的SQL：一：查看线程：show processlist示例：1234567891011mysql&gt; show processlist;+----+------+-----------------+--------+---------+-------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------------+--------+---------+-------+----------+------------------+| 6 | root | localhost:16830 | test1 | Sleep | 18721 | | NULL || 7 | root | localhost:17154 | test1 | Sleep | 18721 | | NULL || 18 | root | localhost:47691 | sakila | Query | 0 | starting | show processlist || 19 | root | localhost:49737 | NULL | Sleep | 393 | | NULL || 20 | root | localhost:49738 | sakila | Sleep | 393 | | NULL |+----+------+-----------------+--------+---------+-------+----------+------------------+5 rows in set (0.00 sec) 该命令可以查看当前MySQL在进行的线程，包括状态，信息（是否锁表）等，便于实时查看SQL执行情况 二：慢查询日志定位MySQL的慢查询日志位置可以命令查看：12345678mysql&gt; show variables like &apos;%slow_query_log%&apos;;+---------------------+-----------------------------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------------------------+| slow_query_log | OFF || slow_query_log_file | /home/data/mysql/centos7-db-slow.log |+---------------------+-----------------------------------------------------------+2 rows in set, 1 warning (0.00 sec) 默认情况下慢查询是关闭的，慢查询日志保存路径可以看见。只需要给slow_query_log设置值即可开启慢查询：1234567891011mysql&gt; set global slow_query_log=1;Query OK, 0 rows affected (0.01 sec)mysql&gt; show variables like &apos;%slow_query_log%&apos;;+---------------------+-----------------------------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------------------------+| slow_query_log | ON || slow_query_log_file | /home/data/mysql/centos7-db-slow.log |+---------------------+-----------------------------------------------------------+2 rows in set, 1 warning (0.00 sec) 同时，可以配置慢查询时间，以及慢查询日志保存路径：在mysql安装路径下找到my.cnf文件，在其中增加或者修改long_query_time和slow_query_log_file即可完成配置。或者命令行更改也可以：123456789101112131415161718mysql&gt; show variables like &apos;%long_query_time%&apos;;+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+1 row in set, 1 warning (0.00 sec)mysql&gt; set long_query_time=2;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &apos;long_query_time&apos;;+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 2.000000 |+-----------------+----------+1 row in set, 1 warning (0.00 sec) 慢查询示例当MySQL开启了慢查询，并且慢查询时间也根据自己情况进行了更改，下面实验下：12345678mysql&gt; show variables like &apos;%slow_query_log%&apos;;+---------------------+-----------------------------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------------------------+| slow_query_log | ON || slow_query_log_file | /home/data/mysql/centos7-db-slow.log |+---------------------+-----------------------------------------------------------+2 rows in set, 1 warning (0.00 sec) 可以看见，当前系统慢查询是开启状态，且一旦出现慢查询，会记录日志在/home/data/mysql/centos7-db-slow.log中。1234567mysql&gt; show variables like &apos;long_query_time&apos;;+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 2.000000 |+-----------------+----------+1 row in set, 1 warning (0.00 sec) 慢查询时间设置为2s，一旦有SQL执行时间超过2s，就会被认为是慢查询，记录在慢查询日志中。 执行4s查询：1234567mysql&gt; select sleep(4);+----------+| sleep(4) |+----------+| 0 |+----------+1 row in set (4.00 sec) 该SQL执行时间为固定的4s，按照设置，肯定是慢查询了，进入日志文件，查看日志：123456789MySQL, Version: 5.7.21 (MySQL Community Server (GPL)). started with:TCP Port: 3306, Named Pipe: MySQLTime Id Command Argument# Time: 2018-03-09T08:34:16.502235Z# User@Host: root[root] @ localhost [::1] Id: 2# Query_time: 4.000101 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use sakila;SET timestamp=1520584456;select sleep(4); 以上就是慢查询内容，包含数据库，SQL执行时间，具体SQL，即定位到执行效率低的SQL，进行优化。 后记定位到慢查询的SQL之后，接下来就是对低效SQL进行分析，后序再说…]]></content>
      <categories>
        <category>MySQL-SQL优化</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础之*args与**kwargs]]></title>
    <url>%2F2018%2F03%2F08%2Fpython%E5%9F%BA%E7%A1%80%E4%B9%8B-args%E4%B8%8E-kwargs%2F</url>
    <content type="text"><![CDATA[python基础之*args和**kwargs简单介绍 认识 *args和 **kwargs首先，看看*args和**kwargs到底是个什么：代码示例：123456789def foo(*args, **kwargs): print(u&quot;args = &quot;, args) print(u&quot;kwargs = &quot;, kwargs) print(&quot;==============我是分割线==================&quot;)if __name__ == &apos;__main__&apos;: foo(1, 2, 3, 4) foo(a=1, b=2, c=3) 输出结果为：123456args = (1, 2, 3, 4)kwargs = &#123;&#125;==============我是分割线==================args = ()kwargs = &#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3&#125;==============我是分割线================== 可以看出，这俩其实就是python的两个变量，*args是个元组（tuple）,**kwargs是个字典（dictionary）。 原理通过google各种解释，差不多是理解了，其实*args和**kwargs真正起作用的是*和**，而args以及kwargs其实就类似于var和vars；当python需要传递多个参数时，就将参数放在一个元组里，按照参数位置传递，以*开头；当需要传递多个键值对时，就把这些键值对放在一个字典里，按照关键字传递，以**开头。 示例一：1234567def foo(x, *args): print(x) print(args)if __name__ == &apos;__main__&apos;: foo(1, 2, 3, 4) 输出结果：121(2, 3, 4) 可以看出，python将（1,2,3,4），其中1，赋给默认参数x，（2,3,4）作为一个元组赋给args； 示例二：1234567def foo(x, **kwargs): print(x) print(kwargs)if __name__ == &apos;__main__&apos;: foo(1, a=2, b=3, c=4) 输出结果：121&#123;&apos;a&apos;: 2, &apos;b&apos;: 3, &apos;c&apos;: 4&#125; python将(1, a=2, b=3, c=4)，其中1，赋值给默认参数x；(a=2, b=3, c=4)作为字典赋给kwargs。 实参角度或者从实参角度来理解：*args示例：12345678def foo(x, y, z): print(x) print(y) print(z)if __name__ == &apos;__main__&apos;: foo(*(1, 2, 3)) 输出结果：123123 可以看出python将*(1, 2, 3)，按照位置将值赋给了x, y, z； **kwargs示例：12345678def foo(x, y, z): print(x) print(y) print(z)if __name__ == &apos;__main__&apos;: foo(**&#123;&quot;x&quot;:1,&quot;y&quot;:2,&quot;z&quot;:3&#125;) 输出结果：123123 python将**{&quot;x&quot;:1,&quot;y&quot;:2,&quot;z&quot;:3}，按照关键字x,y,z赋值给了x,y,z。 *args其实可以理解为python需要调用的任意个没有关键字的参数（无名参数）组成的元组，称之为Non-keyword Variable Arguments；**kwargs是python需要调用的任意个关键字参数（键值对）组成的字典，称之为keyword Variable Arguments 注意事项位置参数，*args，**kwargs混合使用顺序当函数参数中同时拥有位置参数，*args以及**kwargs时，顺序必须是位置参数，*args，**kwargs，否则会报错。示例：12345678def foo(x, *args, **kwargs): print(x) print(args) print(kwargs)if __name__ == &apos;__main__&apos;: foo(1,2,3,4,a=1, b=2, c=3) 输出结果：1231(2, 3, 4)&#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3&#125; 位置参数，默认参数，**kwargs混合使用顺序当需要同时使用位置参数，默认参数以及**kwargs时，顺序必须为位置参数，默认参数，**kwargs，否则会报错。示例：12345678def foo(x, y=2, **kwargs): print(x) print(y) print(kwargs)if __name__ == &apos;__main__&apos;: foo(1,3,a=1,b=2,c=3) 输出结果：12313&#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3&#125; 其中，3将赋给y，替换默认值2。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker使用简介]]></title>
    <url>%2F2018%2F03%2F05%2Fdocker%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[日常docker使用简介 由于日常测试的项目都是在云端，阿里云，AWS上，基本也都是使用了虚拟化技术，项目放在docker或者k8s中。我现在所在的公司，是把项目放在docker中，挂在阿里云上，所以日常使用比较多的就是docker了。 常用操作查看服务从跳转机进入指定的docker所在服务器中，想要查看目前运行的服务：查看所有服务:1docker ps -a 和在linux下查看服务差不多，只是前面加了个docker；查看指定的服务，例如想查看服务名为boss的服务:1docker ps -a |grep boss 看着还是和linux下查看服务一样。。 查看日志一般进行测试时，习惯是开着日志，动态查看，因为有的错误，页面不会全部展示出来，我的习惯是进行测试时，浏览器开启开发者模式（F12），后台开启动态日志，执行操作之后进行数据库查询验证；那么docker下进行动态日志展示：1docker logs -f --tail=300 ContainerId 解释：首先在服务所在的服务器下，查询得到该服务当前开启的容器ID（containerId）docker ps -a该命令执行完成，会展示服务的基础信息：12[root@test-docker2 anmavadmin]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 即可以获取得到指定服务的containerid，动态查看日志和linux下类似，linux下普通的查看日志：1tail -f -n 300 xxx.log 即可动态显示日志文件后300行的日志，同样的，在docker下查看也是使用-f动态显示，显示行数用--tail=行数，再加上指定的Container Id即可1docker logs -f --tail=300 boss_container_id 进入Docker容器docker说到底，其实就是个小型的linux环境，所以，和普通linux一样，也是可以直接进入docker内部，进入docker内部有四种方法，方法很多，日常熟练的掌握一l两种即可。: 进入docker内部的四种方法 我日常使用的是docker exec进入docker内部：1docker exec -it ContainerId /bin/bash 即可进入容器内部，之后就可以和普通linux下一样操作。 K8S（Kubernetes） + Docker当前很多环境的搭建方案选择都是k8s+docker的混合搭建，这样的环境，进行测试工作的常用操作： 查看服务所在节点首先是进入k8s所在的服务器，查看需要查看日志的服务所在docker节点（正常情况下都不会只有一台docker，负载均衡，都知道。。。）：1kubectl get pods -o wide 即可显示所有服务的基础信息，包括服务名称，状态，IP，docker节点：123[root@centos7-k8s1 xxx]# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEtest-boss-server-060b3cf86fa24bd7c9ce2548015e9b38-07qn1 1/1 Running 0 12h 172.17.46.3 centos7-k8s1 此时即可获取到服务所在节点，例如上述示例，服务在centos7-k8s1，即节点1上，所以进入节点1所在服务器，即可动态查看服务日志:123进入节点1，sudo su root(或者就是sudo 命令)docker ps -a |grep bossdocker logs -f --tail=300 containerid 查看服务状态测试中也会遇见点击页面无响应，后台报服务连接超时的错误，此时，可以查看当前服务运行状态：1kubectl get rc -o wide 获取到的信息：123[root@centos7-k8s1 xxx]# kubectl get rc -o wideNAME DESIRED CURRENT READY AGE CONTAINER(S) IMAGE(S) SELECTORtest-boss-server 2 2 2 12h test-boss-server registry.docker.test.cn:5000/test-dev/test-boss-server:20180304_215608 deployment=060b3cf86fa24bd7c9ce2548015e9b38,name=test-boss-server,version=test 可以看出boss服务，期望运行节点数是2，当前运行节点数也是2，所以该服务当前是正常状态。一旦出现DESIRED和CURRENT的值不一致，表明有服务出现问题。出现问题之后就需要对服务进行问题定位，重启等操作，就不多说了。 后记自己对于虚拟化技术的掌握度基本是皮毛都算不上，现在还是满足最基本工作需要范围o(╥﹏╥)o，后期看来得好好补。。 3月3号时候，突然有个冲动，步行到西山岛上去，然后就说走就走。。。从渔洋山一直到西山岛-金庭游客中心,一个人默默的暴走了近1个小时40分钟，9.5km，走完全程3段太湖大桥，穿过岛两座，可惜天公不作美啊，太湖湖面上雾有点大，桥上风景还是有点朦胧，得找个天气晴朗的日志再走一遭！（再也不穿登山鞋去了，原本想爬山才穿的登山鞋，结果徒步差点没把脚走废掉。。。） 生命在于运动，恰逢一年一度的跑步黄金时期，该走出去，走走，跑跑，爬爬山~~~(大早上来发现VPS又挂了，哎我的hexo可以搭在VPS上的，进不去还写个鬼博客，只好又重搭了一个，愁)]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
        <tag>Linux运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新年伊始-开年记]]></title>
    <url>%2F2018%2F02%2F28%2F%E6%96%B0%E5%B9%B4%E4%BC%8A%E5%A7%8B-%E5%BC%80%E5%B9%B4%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[随波逐流，还是不停的瞎折腾~ 新年伊始过年来上班第一天就发现，SSR又登不上了，也就意味着，google啊，又离我远去。。。搞啥啊，查了下黄历，没啥问题啊，翻了下新华社新闻，好吧，开会了。。不出所料，被墙了。 周二时候有点不服，把vultr上几乎所有VPS都重搭了下，好吧，居然IP全挂，这么多台都全挂，有点服。。今天早上过来，感觉还是有点不爽，主要是每次打开浏览器，由于我设置的Chrome主页就是google，每次进来都是空荡荡的，感觉很难受，抱着不死就折腾的心态，又开始搭，结果还真找到个漏网之鱼，苍天啊，真的是泪流满面o(╥﹏╥)o 立刻重建，还好有这个经历： VPS重建记 一台新机器，花了半个小时就完成了，终于，又可以科学上网，hexo又可以更博了！！ 日常记忆随手记下昨天遇到的小白问题：在搭建自动化框架时，基本会把页面元素的定位信息放在类似于example.ini的配置文件中，然后从文件中获取定位方式以及定位表达式，这样方便维护。读取example.ini文件配置内容，我是使用的configparser，用法：12cf = configparser.ConfigParser()cf.read(&apos;example.ini&apos;) 这样就会把配置文件中的配置信息加载到内存中，获取信息一般使用两种方式： 获取特定的optionValue使用cf.get(section, option)即可获取特定的option的值例如，有一个example.ini内容如下：12345[126mail_login]loginPage.frame = id &gt; x-URS-iframeloginPage.username = xpath &gt; //input[@name=&quot;email&quot;]loginPage.password = xpath &gt; //input[@name=&quot;password&quot;]loginPage.loginbutton = id &gt; dologin 想要获取切换到登录frame的定位方式及表达式，只需要：12frame126 = cf.get(&quot;126mail_login&quot;, &quot;loginPage.frame&quot;)print(frame126) 打印出定位方式及表达式：1id &gt; x-URS-iframe 获取指定section下的所有option使用cf.items(section)即可获取该section下的所有option，返回的是一个列表，包含option以及对应的value示例：12options = cf.items(&quot;126mail_login&quot;)print(options) 返回结果：1[(&apos;loginpage.frame&apos;, &apos;id &gt; x-URS-iframe&apos;), (&apos;loginpage.username&apos;, &apos;xpath &gt; //input[@name=&quot;email&quot;]&apos;), (&apos;loginpage.password&apos;, &apos;xpath &gt; //input[@name=&quot;password&quot;]&apos;), (&apos;loginpage.loginbutton&apos;, &apos;id &gt; dologin&apos;)] 问题由于日常的开发环境是windows，系统的默认编码是gbk，所有在windows下使用configparser来读取配置文件时，有的时候会报编码错误：1UnicodeDecodeError: &apos;gbk&apos; codec can&apos;t decode byte 0xae in position 272: illegal multibyte sequence 解决解决方法很简单，直接看cf.read()的源码，源码是这样的：1234567891011121314151617181920212223def read(self, filenames, encoding=None): &quot;&quot;&quot;Read and parse a filename or a list of filenames. Files that cannot be opened are silently ignored; this is designed so that you can specify a list of potential configuration file locations (e.g. current directory, user&apos;s home directory, systemwide directory), and all existing configuration files in the list will be read. A single filename may also be given. Return list of successfully read files. &quot;&quot;&quot; if isinstance(filenames, str): filenames = [filenames] read_ok = [] for filename in filenames: try: with open(filename, encoding=encoding) as fp: self._read(fp, filename) except OSError: continue read_ok.append(filename) return read_ok 默认的read()是没有指定编码的encoding=None，所以只需要指定编码为utf-8即可解决：1cf.read(pageElementLocatorPath, encoding=&apos;utf-8&apos;) 其中pageElementLocatorPath为example.ini文件 后记生活不就是不断的折腾嘛，墙了继续试，大不了你再墙嘛~]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>自动化测试</tag>
        <tag>lives</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在2018新年来临]]></title>
    <url>%2F2018%2F02%2F12%2F%E5%86%99%E5%9C%A82018%E6%96%B0%E5%B9%B4%E6%9D%A5%E4%B8%B4%2F</url>
    <content type="text"><![CDATA[写在春节来临之际农历2017年最后一个工作日，明天就要回家过春节了，想想，2017，好像过去的挺快的。来篇流水账，写写，我的2017。 活在苏州： 工作篇有苦有甜才是生活，作为占据我一天一半时间的大头，首先还是想看看在这上面，我的2017到底发生了些什么。工作内容还是日常的做个行走的BUG，以做一个开发及其烦躁的tester为荣，并在这条道上，坚定的走到黑！ 安硕生涯2016年7月来到安硕，工作了也有段时间，工作方式，好歹是从个外人眼中看来，测试就是定点点的工作转换成了性能测试做的多一点的，入门级性能测试工程师。日常工作，积累了一套性能需求分析-脚本编写-结果分析-瓶颈定位-性能调优的性能测试步骤，说起来，做的还是有点乐此不疲的，就是记忆力有点差，mysql性能调优经常忘。。（(ಥ_ಥ) ）同时，接触到了大数据相关，虽然和我的关联不是特别大，最多就是帮着测测规则，测测数据，好歹是打开了另一扇窗；眼界不是来自于期刊杂志，有真正自己去接触了，才是有自己的感受，所以，还是挺感激这段经历。然后2017年9月，离开了安硕。 新的开始2017年9月21日，正式从安硕来到了这，正式开始了测试带队（虽然手下就一人~~~），也正式捡起了放下一年半的python。刚毕业那会，和舍友选语言，他选了python做爬虫，我选了java，后来兜兜转转，我的java技术还是那么菜，压根入门都没达到就半路夭折，好在，还有补牢的机会，重新拿起python，做起了自动化。9月至今，python书籍看完两本，简陋自动化框架搭建完成一个，算是还对的起自己。路还在脚下，当慢慢走。 生活篇2017年的生活，不再那么浑浑噩噩，上班下班，周末宅；生活中发生了好几件大事。2017年5月13日，在苏州买了房，从此开始房奴生涯（o(╥﹏╥)o）2017年5月23日，回句容领了证，从此告别一个人的时光（(｀・ω・´)）7月，失去了一位亲人..总的来说，2017，算是翻天覆地的一年，本命年的我，经历了也就这些。人间烟火，不过是比落叶还轻的生活；该开的开，山野鲜花依然澎湃；该来的来，路上精彩还在等待。 玩乐篇换个心情，回忆点轻松的，作为一个从小就喜欢满田野疯的“野孩子”，整年不出门去看看那是不现实的。3月，的确是个赏樱花的季节，无锡-鼋头渚 原谅手残，技术不到家，樱花实在没拍的好，照片只能待在自己手机没事用来傻笑~4月，好像是万条垂下绿丝绦的时节了，杭州-西湖九溪烟树，云栖竹径，苏堤春晓，柳浪闻莺，梅坞春早，钱塘江，龙井村等等，带着个小胖子，也有过一天翻越无数山头，暴走30公里的经历。（杭州之行，照片太丑，不拿出来丢人。。。）8月，拿着婚假，怀着点点感伤，踏上了川藏线的朝圣之路，成都-&gt;拉萨成都遇上海燕和莉儿，一行，10天，成都出发，终点拉萨。南方的孩子，还是应该在8月到雪山上去看看雪的，不是吗~感芸芸众生，人世无常，茫茫大海，谁可争流；不如步入山野，凭栏远眺，闲庭信步，观云卷云舒。 竺法渐传三界远，盛音近绕佛堂前。达布拉宫，只有亲眼看见，才知道，眼前，真的就是一幅画。 然后，12月，前往丽江拍婚纱照，天和西藏一样蓝，就是商业气息过于浓重了点，小憩可以，不宜久居。时间有限，没去成泸沽湖，没机会去洱海，都算是遗憾，谁说不是呢，有遗憾，才是真正的活着嘛。（照片，在相机，忘了传手机了。。。） 后记不大不小，24周岁，不多不少，两个人了；愿能够笑看沧桑，轻盈过往；淡看流年烟火，细品岁月静好。花有花的灿烂，云有云的诗意，淡然的面对生命的一切逝去，在似水流年间细细品味每一个过往，每一种滋味，每一份流逝。 最后，最后一天了，祝所有，在未来的日子里，恬然，静候花开。 （原谅通篇流水账~~~太久不会写文字了￣□￣｜｜）]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>lives</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3完成mysql操作]]></title>
    <url>%2F2018%2F02%2F11%2Fpython3%E5%AE%8C%E6%88%90mysql%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[python3使用pymysql操作mysql5.7 版本信息：1234MYSQL 5.7.21PYTHON 3.6pymysql 0.8.0WIN 10 安装首先，老样子，安装。windows控制台直接执行：1pip install pymysql 即可，pipenv进行类包管理，控制台中进入工程所在目录下，执行：1pipenv install pymysql SQLsql.py文件，包含初始化数据库，创建库，创建表所有sql：1234567891011# 创建gloryroad数据库create_database = &apos;CREATE DATABASE IF NOT EXISTS gloryroad DEFAULT CHARSET utf8 COLLATE utf8_general_ci;&apos;# 创建testdata表drop_table = &apos;drop table if exists TESTDATA;&apos;create_table = &quot;&quot;&quot;CREATE TABLE TESTDATA ( id INT NOT NULL, bookname VARCHAR(40) NOT NULL UNIQUE, author VARCHAR(30) NOT NULL)&quot;&quot;&quot;primary_sql = &apos;alter table testdata add primary key(id);&apos;alter_id = &apos;alter table testdata change id id int AUTO_INCREMENT NOT NULL;&apos; 创建表时候，我们在mysql控制台，或者在类似Navicat for mysql这样的数据库连接工具中直接执行1234567CREATE TABLE `testdata` ( `id` int(11) NOT NULL AUTO_INCREMENT, `bookname` varchar(40) NOT NULL, `author` varchar(30) NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `bookname` (`bookname`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 即可创建包含主键，唯一键，自增字段等属性的testdata表，但是不知道为啥，我直接在pycharm中执行，一直报错，又不想耗在这上面，就拆开来了，先创建表，再增加主键，修改字段等操作。 pymysql创建数据库及表创建库和表pymysql对mysql的操作，基本可以总结为几步：123456建立连接（connect）打开游标（cursor）执行sql（execute）提交事务（commit）关闭游标（close cursor）关闭连接（connect close） 所以进行创建数据库和表操作时，一步一步执行即可：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/11 13:06&quot;&quot;&quot;from SQL import *import pymysqlclass DataBaseInit(object): &quot;&quot;&quot; 1、数据库初始化 2、创建数据库及表，并向表中插入测试数据 &quot;&quot;&quot; def __init__(self, host, port, dbName, username, password, charset): self.host = host self.port = port self.db = dbName self.username = username self.password = password self.charset = charset def creaete(self): # 建库及表 try: # 连接mysql数据库 conn = pymysql.connect( host = self.host, port = self.port, user = self.username, passwd = self.password, charset = self.charset ) # 获取数据库游标 cur = conn.cursor() # 创建数据库 cur.execute(create_database) # 选择创建好的数据库 conn.select_db(&quot;gloryroad&quot;) # 建表并更改字段 cur.execute(drop_table) cur.execute(create_table) cur.execute(primary_sql) cur.execute(alter_id) except pymysql.Error as e: raise e else: # 关闭游标 cur.close() # commit conn.commit() # 关闭连接 conn.close() print(u&quot;创建数据库及表成功&quot;) 插入数据插入数据也是正常步骤即可，当插入不止一条数据，可以使用executemany()来一次插入多条数据，配合insert into table (col1, col2) values (%s, %s)可以完成参数化一次插入大量数据；插入数据方法：1234567891011121314151617181920212223242526272829303132def insertData(self): # 插入数据 try: # 连接具体某个库 conn = pymysql.connect( host=self.host, port=self.port, db=self.db, user=self.username, passwd=self.password, charset=self.charset ) # 打开游标 cur = conn.cursor() # 插入数据 sql = &quot;insert into testdata (bookname, author) values (%s, %s)&quot; cur.executemany(sql, [ [&apos;FACE TO FACE WITH FARE&apos;, &apos;Amana Trobe&apos;], [&apos;Relationship&apos;, &apos;Christopher benas Meng&apos;], [&apos;ZOO&apos;, &apos;Yiyi&apos;] ]) except pymysql.Error as e: raise e else: conn.commit() print(u&quot;初始化数据插入成功&quot;) # 确认插入成功 # cur.execute(&quot;select * from testdata;&quot;) # for i in cur.fetchall(): # print(i[1], i[2]) cur.close() conn.close() 从mysql获取数据很简单，一步一步走即可：12345678910111213def getDataFromDataBases(self): # 从testdata表获取测试数据 # bookname作为testdata，author作为expectdata self.cur.execute(&quot;select bookname, author from testdata;&quot;) # 取查询结果 datasTuple = self.cur.fetchall() return datasTupledef closeDatabase(self): # 数据库后续操作 self.cur.close() self.conn.commit() self.conn.close() 至此，就可以完成测试数据存在mysql中，从数据库表中完成测试数据的读取以及断言判断等操作。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>python3</tag>
        <tag>pymysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于python3的UI自动化框架搭建系列（二）]]></title>
    <url>%2F2018%2F02%2F09%2F%E5%9F%BA%E4%BA%8Epython3%E7%9A%84UI%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[自动化测试框架雏形搭建完成 小结框架终于差不多完成了，包含了123自定义日志自定义测试报告实时邮件发送 等模块。目前可以实现：12345测试过程中控制台实时打印日志测试过程中实时写日志入自定义log文件测试过程中发生断言失败，实时截图，并且将堆栈日志打印到指定log文件测试完成自动生成html格式测试报告测试完成自动发送邮件 实例以下是实现的简单的从excel中读取数据进行自动化测试的实例（测试用例使用excel编写）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/9 15:30&quot;&quot;&quot;from selenium import webdriverfrom ExcelUtil import GetDataFromExcelfrom selenium.common.exceptions import NoSuchElementExceptionfrom Log import *from MailSend import MailSendfrom ReportTemplate import htmlTemplatefrom nose.tools import assert_truefrom MakeDirs import *import time,tracebackimport sys,ddt# excel路径，sheet名path = &quot;G:/workstation/py_workstation/DataDriverTest/DdtData/testData.xlsx&quot;sheetname = &quot;search_data&quot;excel = GetDataFromExcel(path, sheetname)@ddt.ddtclass TestDdtByExcel(): @classmethod def setUpClass(cls): TestDdtByExcel.trStr = &quot;&quot; def setUp(self): self.browser = webdriver.Chrome() # 设置测试状态及结果标志 self.status = None self.flag = 0 @ddt.data(* excel.getData()) def test_ddtbyexcel(self, data): # 声明全局变量 global start, starttime # 定义执行结果的颜色 flagDict = &#123;0: &apos;red&apos;, 1: &apos;00AC4E&apos;&#125; # 获取测试用例名称 casename = sys._getframe().f_code.co_name testdata, expectdata = tuple(data) url = &quot;https://www.baidu.com&quot; self.browser.get(url) self.browser.implicitly_wait(10) try: # 获取当前时间戳 start = time.time() # 获取当前时间 starttime = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) # 搜索 self.browser.find_element_by_id(&apos;kw&apos;).send_keys(testdata) self.browser.find_element_by_id(&apos;su&apos;).click() # 休眠3s time.sleep(3) # 断言 assert_true(expectdata in self.browser.page_source) except NoSuchElementException as e: error(u&quot;页面元素不存在：&quot; + str(traceback.print_exc( file=open(&quot;G:/workstation/py_workstation/DataDriverTest/Logs/Error/DdtTest.log&quot;, &quot;a&quot;)))) self.flag = 0 self.status = &apos;fail&apos; takeScreenShot(self.browser) except AssertionError as e: error(u&quot;搜索“&#123;0&#125;，期望“&#123;1&#125;”，失败”&quot;.format(testdata, expectdata) + str(traceback.print_exc( file=open(&quot;G:/workstation/py_workstation/DataDriverTest/Logs/Error/DdtTest.log&quot;, &quot;a&quot;)))) self.flag = 0 self.status = &apos;fail&apos; takeScreenShot(self.browser) except Exception as e: error(u&quot;未知错误：&quot; + str(traceback.print_exc( file=open(&quot;G:/workstation/py_workstation/DataDriverTest/Logs/Error/DdtTest.log&quot;, &quot;a&quot;)))) self.flag = 0 self.status = &apos;fail&apos; takeScreenShot(self.browser) else: info(u&quot;搜索“&#123;0&#125;，期望“&#123;1&#125;”，通过”&quot;.format(testdata, expectdata)) self.status = &apos;pass&apos; self.flag = 1 # 计算消耗时间 # 10位时间戳，单位为s spends = time.time() - start - 3 # 取两位小数 spendtime = &quot;%.2f&quot; %spends # 报告中添加数据 TestDdtByExcel.trStr += u&apos;&apos;&apos; &lt;tr&gt; &lt;td&gt;&#123;0&#125;&lt;/td&gt; &lt;td&gt;&#123;1&#125;&lt;/td&gt; &lt;td&gt;&#123;2&#125;&lt;/td&gt; &lt;td&gt;&#123;3&#125;&lt;/td&gt; &lt;td&gt;&#123;4&#125;&lt;/td&gt; &lt;td style=&quot;color: &#123;5&#125;&quot;&gt;&#123;6&#125;&lt;/td&gt; &lt;/tr&gt; &apos;&apos;&apos;.format(casename, testdata, expectdata, starttime, spendtime, flagDict[self.flag], self.status) def tearDown(self): self.browser.quit() @classmethod def tearDownClass(cls): # 写自定义报告 htmlTemplate(TestDdtByExcel.trStr)if __name__ == &apos;__main__&apos;: os.system(&quot;nosetests -s -v &#123;0&#125;&quot;.format(__file__)) info(u&quot;*****测试报告开始发送*****&quot;) report_file = &quot;G:/workstation/py_workstation/DataDriverTest/Report/DDTByExcel.html&quot; mail_subject = &quot;NoseTest测试报告_&#123;0&#125;&quot;.format(dt.now().strftime(&quot;%Y%m%d&quot;)) mailsend = MailSend(mail_subject, report_file) mailsend.sendMail() info(u&quot;~~~测试报告发送完成，请注意查收~~~&quot;) 结构粗略结构：12345678910project|—— coding（主要代码）|—— DdtConf（一些配置，包括邮箱（.ini），日志(logger.conf)等）|—— DdtData（测试数据（excel，xml，json）等）|—— DdtTools（工具类（生成html文件，创建文件夹，截图，邮件发送，从文件读数据））等）|—— Logs（日志） |—— Info |—— Error|—— Pictures（断言失败的截图）|—— Report（测试报告） 后期再慢慢改进，可以修改的地方还有很多！]]></content>
      <categories>
        <category>自动化测试框架</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>自动化测试</tag>
        <tag>nose</tag>
        <tag>python3</tag>
        <tag>ddt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows安装mysql5.7]]></title>
    <url>%2F2018%2F02%2F09%2Fwindows%E5%AE%89%E8%A3%85mysql5-7%2F</url>
    <content type="text"><![CDATA[winwods环境安装配置mysql5.7 版本信息12win 10mysql 5.7.21 下载直接上官网下载： mysql下载官网 以前官网上的下载是有.msi格式的安装包的，现在好像没怎么找到（也可能是眼睛花了。。），现在下载的是.zip压缩包，也就是直接解压缩就可以了。 安装及配置安装将压缩包下载到本地，解压缩到你自定义的目录下，如我下载的是mysql-5.7.21-winx64.zip文件，解压缩到我本地软件安装盘：E:\Test\ 环境变量解压完成之后，进行日常操作，配置环境变量，将你解压完成之后的mysql的bin目录所在路径添加到系统环境变量path中，另外可以新建一个MYSQL_HOME的环境变量，变量值也是你的bin目录所在路径，例如我的配置：1234pathE:\Test\mysql-5.7.21-winx64\binMYSQL_HOMEE:\Test\mysql-5.7.21-winx64\bin 配置服务注册在你的mysql目录下，新建my.ini文件，来完成windows系统服务的注册，内容可参考我的：1234567891011121314151617181920[client]port=3306default-character-set=utf8[mysqld]#解压目录basedir=E:\Test\mysql-5.7.21-winx64#解压目录下data目录datadir=E:\Test\mysql-5.7.21-winx64\dataport=3306character_set_server=utf8#导出mysql数据的目录secure_file_priv =E:\Test\mysql-5.7.21-winx64\datasql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES#开启查询缓存explicit_defaults_for_timestamp=true#skip-grant-tables[WinMySQLAdmin]E:\Test\mysql-5.7.21-winx64\bin\mysql.exe DATA文件夹在mysql 5.6版本之前，默认就是在E:\Test\mysql-5.7.21-winx64下就有data文件夹，现在没有了，需要自己手动新建E:\Test\mysql-5.7.21-winx64\data新建完成之后，右键管理员打开cmd，进入mysql的bin目录下（E:\Test\mysql-5.7.21-winx64\bin），执行命令：1mysqld --initialize 运行完成之后，在data目录下就有生成一些初始化的文件，里面有个你的机器.err格式的文件，用文本编辑器打开之后，可以看见随机生成的root的密码：12018-02-09T01:51:43.117196Z 1 [Note] A temporary password is generated for root@localhost: PaFe#w##v6zD 安装mysql管理员模式打开的cmd中，进入\mysql\bin目录下，输入服务安装命令：1mysqld -install 启动服务安装没有报错情况下，可以选择在windows的服务中手动起服务，也可以命令行起：1net start mysql 打印信息：123&#123;lamb&#125; net start mysqlMySQL 服务正在启动 .MySQL 服务已经启动成功。 表明mysql服务已经成功启动。 mysql操作mysql服务启动之后，用root用户登录(密码在前步生成的xxx.err文件中)：1mysql -uroot -p密码 进入mysql控制台。1234567891011121314mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.7.21 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; 表示成功进入控制台。 修改root密码控制台下执行:1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;新密码&apos;; 回车即可。用新密码重新登录进控制台，随意看看mysql吧（关于数据库的操作就不提了，教程一大堆，用多了就熟悉了）~12345678910mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec) 12345678910mysql&gt; use sys;Database changedmysql&gt; show tables;+-----------------------------------------------+| Tables_in_sys |+-----------------------------------------------+| host_summary || host_summary_by_file_io || host_summary_by_file_io_type || host_summary_by_stages 慢查询及版本信息123456789101112131415161718192021222324252627mysql&gt;mysql&gt; show variables like &quot;%slow%&quot;;+---------------------------+-----------------------------------------------------------+| Variable_name | Value |+---------------------------+-----------------------------------------------------------+| log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | E:\Test\mysql-5.7.21-winx64\data\DESKTOP-PBQIU7V-slow.log |+---------------------------+-----------------------------------------------------------+5 rows in set, 1 warning (0.00 sec)mysql&gt; show variables like &quot;%version%&quot;;+-------------------------+------------------------------+| Variable_name | Value |+-------------------------+------------------------------+| innodb_version | 5.7.21 || protocol_version | 10 || slave_type_conversions | || tls_version | TLSv1,TLSv1.1 || version | 5.7.21 || version_comment | MySQL Community Server (GPL) || version_compile_machine | x86_64 || version_compile_os | Win64 |+-------------------------+------------------------------+8 rows in set, 1 warning (0.00 sec)]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3操作excel]]></title>
    <url>%2F2018%2F02%2F09%2Fpython3%E6%93%8D%E4%BD%9Cexcel%2F</url>
    <content type="text"><![CDATA[python3使用openpyxl完成excel数据读和写 工具python3操作excel数据，对于excel 2007及以上版本，一般使用openpyxl来进行操作；windows下，只需要控制台执行1pip install openpyxl 即可，若是使用pipenv进行类库管理的，控制台下进入工程所在目录（Pipfile所在路径），执行1pipenv install openpyxl 即可。对于pipenv在之前的一篇博客中有提及： python项目依赖管理工具 安装完成之后，执行命令python进入python交互环境，引包：1import openpyxl 不报错则安装成功 常用操作1234567891011121314151617181920212223# 引包import openpyxl# excel文件路径file = &quot;G:\workstation\py_workstation\DataDriverTest\DdtData\testData.xlsx&quot;# 打开excelwb = openpyxl.load_workbook(file)# 获取指定sheet页，名称：“search_data”sheet = wb[&quot;search_data&quot;]# 获取所有sheet的名称sheets = wb.sheetnames# 获取行数nrow = sheet.max_row# 获取列数ncol = sheet.max_column# 获取单元格值cell_1 = sheet.cell(row=2, column=2).value# 单元格赋值cell_2 = sheet.cell(row=2, column=2, value=&quot;YIDA&quot;)# 保存excelwb.save(file) 读写excel进行ddt时，有的时候测试数据，甚至测试用例是在excel中，如下表，标示出了测试数据，预期结果。 number&emsp;&emsp;testdata &emsp;&emsp;&emsp;expectdata1&emsp;&emsp;&emsp;&emsp;&ensp;Jordan&emsp;&emsp;&emsp;&emsp;&ensp;DRFSA2&emsp;&emsp;&emsp;&emsp;&ensp;Garnett&emsp;&emsp;&emsp;&emsp;&ensp;Kevin3&emsp;&emsp;&emsp;&emsp;&ensp;Oneal&emsp;&emsp;&emsp;&emsp;&emsp;Shaquille4&emsp;&emsp;&emsp;&emsp;&ensp;Nowitzki&emsp;&emsp;&emsp;&emsp;rsdffd5&emsp;&emsp;&emsp;&emsp;&ensp;Duncan&emsp;&emsp;&emsp;&emsp;Tim 首先是尝试使用python3 把数据写入excel 写数据直接上代码12345678910111213141516171819202122#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/9 13:25&quot;&quot;&quot;import openpyxlfile = &quot;G:/workstation/py_workstation/DataDriverTest/DdtData/test.xlsx&quot;wb = openpyxl.load_workbook(file)sheet = wb.activesheet.title = &quot;search_data&quot;value = [ [&quot;number&quot;, &quot;testdata&quot;, &quot;expectdata&quot;], [&quot;1&quot;, &quot;Jordan&quot;, &quot;DRFSA&quot;], [&quot;2&quot;, &quot;Garnett&quot;, &quot;Kevin&quot;]]for i in range(0, 3): for j in range(0, len(value[i])): sheet.cell(row=i+1, column=j+1, value=str(value[i][j]))wb.save(file) 读数据代码：1234567891011121314151617181920212223242526#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/9 14:15&quot;&quot;&quot;import openpyxl# 打开excelwb = openpyxl.load_workbook(&quot;G:/workstation/py_workstation/DataDriverTest/DdtData/testData.xlsx&quot;)# 获取指定sheet页sheet = wb[&quot;search_data&quot;]# 获取列表中最大行数和最大列数nrows = sheet.max_rowncol = sheet.max_columntestdata = []# 获取2到6行for i in list(range(2,nrows+1)): tmplist = [] tmplist.append(sheet.cell(row=i, column=2).value) #2,2 tmplist.append(sheet.cell(row=i, column=3).value) #2,3 testdata.append(tmplist)print(testdata) 完成！！！ 后记估计是快过年，快放假了，都没什么心思敲了；真的是弄了好久才读出数据。。。python3操作excel是真的跟python2很不一样，网上的教程很多都不能用，最明显的就是:python2可以遍历工作表区域每一行，跳过第一行，直接写成1for row in sheet.rows[1:]: 但是python3实现不了。。不过自己能折腾出来，感觉还是有点小小的成就感的~ 附环境版本：1234python 3.6openpyxl 2.5.0win 10office 2013]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>openpyxl</tag>
        <tag>ddt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义测试报告]]></title>
    <url>%2F2018%2F02%2F08%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[解决自动化测试中捕获断言之后，测试报告展示为ok无法查看具体哪条用例执行失败的问题 问题来自之前博客中折腾的单元测试异常捕获问题：自动化测试断言捕获当时折腾出的解决方案是自定义测试报告的模板，定义status状态位，作为测试用例执行结果的状态标志，一旦发生断言异常捕获，将status状态为置为fail，最后体现在测试报告上。 自定义报告自定义报告模块，参考nose生成的报告，又东拼西凑折腾出了这份最简单的测试报告，最终报告生成原理就是：首先html文件中创建表格，预留html的尾部，在后续执行自动化测试过程中，将生成的测试数据拼接到不完整的html文件中，最终生成完成的html文件作为测试报告。 ReportTemplate.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/8 11:21&quot;&quot;&quot;def htmlTemplate(trData): &quot;&quot;&quot;自定义测试报告样式&quot;&quot;&quot; htmlStr = u&apos;&apos;&apos; &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;Unit Test Report&lt;/title&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;/&gt; &lt;style&gt; body&#123; width: 80%; /* 整个body区域占浏览器百分比 */ margin: 40px auto; /* 整个body区域相对浏览器窗口摆放位置（左右，上下）*/、 font-weight: bold; /* 整个body区域字体加粗 */ font-family: Calibri, &quot;Trebuchet MS&quot;, sans-serif; /* 表格中文字的字体类型 */ font-size: 18px; /* 字体大小 */ color: #000; &#125; table&#123; border-spacing: 0; /* 表格边框宽度 */ width: 100%; /* 整个表格相对父元素的宽度 */ &#125; .tableStyle&#123; border-style: outset; /* 整个表格外边框样式 */ border-width: 2px; /* 整个表格外边框宽度 */ border-color: blue; /* 整个表格外边框颜色 */ &#125; .tableStyle tr:hover&#123; background: rgb(173,216,230); /* 鼠标滑过一行，动态显示的颜色 */ &#125; .tableStyle td&#123; border-left: solid 1px rgb(146,208,80); /* 表格的竖线颜色 */ border-top: 1px solid rgb(146,208,80); /* 表格的横线颜色 */ padding: 15px; /* 表格内边框尺寸 */ text-align: center; /* 表格内容显示位置 */ vertical-align: middle; &#125; .tableStyle th&#123; border-left: solid 1px rgb(146,208,80); border-top: 1px solid rgb(146,208,80); padding: 15px; text-align: center; vertical-align: middle; &#125; .tableStyle th&#123; padding: 15px; /* 表格标题栏，字体尺寸 */ background-color: rgb(146,208,80); /* 表格标题栏背景颜色 */ /* 标题栏设置渐变色 */ background-image: -webkit-gradient(linear, left top, left bottom, from(#92D050), to(#A2D668)); &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;center&gt;&lt;h1&gt;TestReport&lt;/h1&gt;&lt;/center&gt;&lt;br /&gt; &lt;table class=&quot;tableStyle&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;CaseName&lt;/th&gt; &lt;th&gt;TestData&lt;/th&gt; &lt;th&gt;ExpectData&lt;/th&gt; &lt;th&gt;StartTime&lt;/th&gt; &lt;th&gt;SpendTime&lt;/th&gt; &lt;th&gt;Result&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &apos;&apos;&apos; endStr = u&apos;&apos;&apos; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; &apos;&apos;&apos; # 拼接成完整html文件 htmlf_file = htmlStr + trData + endStr with open(r&quot;D:/bug_things/selenium/report/DDTByObj.html&quot;, &quot;w&quot;, encoding=&apos;utf-8&apos;) as f_obj: f_obj.write(htmlf_file) #f.close() ddt数据驱动使用ddt进行自动化测试，单元测试框架使用nose，实现如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/8 14:07&quot;&quot;&quot;from selenium import webdriverfrom ReportTemplate import htmlTemplatefrom selenium.common.exceptions import NoSuchElementExceptionfrom DdtTools.Log import *from DdtTools.MailSend import MailSendfrom datetime import datetime as dtfrom nose.tools import assert_trueimport sysimport ddtimport timeimport traceback@ddt.ddtclass TestDdtByJson(): @classmethod def setUpClass(cls): # 只调一次 TestDdtByJson.trStr = &quot;&quot; def setUp(self): self.browser = webdriver.Chrome() # 存放测试结果状态，失败为fail，成功为pass self.status = None # 数据驱动测试结果的标志，成功置1，失败置0 self.flag = 0 @ddt.file_data(&quot;G:/workstation/py_workstation/DataDriverTest/DdtData/test_data_list.json&quot;) def test_ddtbyjson(self, value): global start, starttime # 获取当前测试用例名 casename = sys._getframe().f_code.co_name # 确定报告中状态单元格中内容颜色 flagDict = &#123;0: &apos;red&apos;, 1: &apos;#00AC4E&apos;&#125; url = &quot;https://www.baidu.com&quot; self.browser.get(url) #self.browser.maximize_window() # 将json中测试数据用“||”分隔成测试数据及期望结果 testdata, expectdata = tuple(value.strip().split(&quot;||&quot;)) self.browser.implicitly_wait(10) try: # 获取当前时间时间戳，用于计算耗时 start = time.time() # 获取当前时间 starttime = time.strftime(&quot;%Y-%m-%d %H:%M%S&quot;, time.localtime()) # 开始搜索 self.browser.find_element_by_id(&apos;kw&apos;).send_keys(testdata) self.browser.find_element_by_id(&apos;su&apos;).click() time.sleep(3) # 断言 assert_true(expectdata in self.browser.page_source) except NoSuchElementException as e: error(u&quot;页面元素不存在：&quot; + str(traceback.print_exc(file=(open(&quot;D:/bug_things/selenium/logs/errors/DdtTest.log&quot;, &apos;a&apos;))))) self.status = &apos;fail&apos; self.flag = 0 except AssertionError as e: error(u&apos;搜索“&#123;0&#125;”，期望“&#123;1&#125;”，失败&apos;.format(testdata, expectdata) + str(traceback.print_exc(file=open(&quot;D:/bug_things/selenium/logs/errors/DdtTest.log&quot;, &apos;a&apos;)))) self.status = &apos;fail&apos; self.flag = 0 except Exception as e: error(u&quot;未知错误：&quot; + str(traceback.print_exc(file=open(&quot;D:/bug_things/selenium/logs/errors/DdtTest.log&quot;, &apos;a&apos;)))) self.status = &apos;fail&apos; self.flag = 0 else: info(u&apos;搜索“&#123;0&#125;”，期望“&#123;1&#125;”，通过&apos;.format(testdata, expectdata)) self.status = &apos;pass&apos; self.flag = 1 # 计算消耗时间 # 时间戳相减(10位时间戳单位为s) spends = time.time() - start - 3 # 取两位小数 spendtime = &quot;%.2f&quot; %spends # 报告中添加测试数据 TestDdtByJson.trStr += u&apos;&apos;&apos; &lt;tr&gt; &lt;td&gt;&#123;0&#125;&lt;/td&gt; &lt;td&gt;&#123;1&#125;&lt;/td&gt; &lt;td&gt;&#123;2&#125;&lt;/td&gt; &lt;td&gt;&#123;3&#125;&lt;/td&gt; &lt;td&gt;&#123;4&#125;&lt;/td&gt; &lt;td style=&quot;color: &#123;5&#125;&quot;&gt;&#123;6&#125;&lt;/td&gt; &lt;/tr&gt; &apos;&apos;&apos;.format(casename, testdata, expectdata, starttime, spendtime, flagDict[self.flag], self.status) def tearDown(self): self.browser.quit() @classmethod def tearDownClass(cls): # 写自定义测试报告 htmlTemplate(TestDdtByJson.trStr)if __name__ == &apos;__main__&apos;: os.system(&quot;nosetests -s -v &#123;0&#125;&quot;.format(__file__)) info(u&quot;测试报告开始发送&quot;) report_file = &quot;D:/bug_things/selenium/report/DDTByObj.html&quot; mail_subject = &quot;UnitTest测试报告_&#123;0&#125;&quot;.format(dt.now().strftime(&quot;%Y%m%d&quot;)) mailsend = MailSend(mail_subject, report_file) mailsend.sendMail() info(u&quot;测试报告发送完成&quot;) 其中涉及到的邮件发送模块和日志模块可以参照以前的博客： 邮件模块日志配置 其中日志模块增加了对error级别的日志的配置，很简单，和info级别类似，就不多说了。最终实现效果，测试过程中在控制台以及D:/bug_things/selenium/logs/info/AutoDDT.log中实时写入info以及error的日志，当出现堆栈错误，写入D:/bug_things/selenium/logs/errors/DdtTest.log文件中，两个日志文件的写入方式都是append，测试完成之后邮件发送包含html附件的测试报告到指定邮箱；同时邮件正文中展示包含测试结果的表格，出现fail状态，可直接前往D:/bug_things/selenium/logs/errors/DdtTest.log日志中查看具体出错，以及具体出错行。需要改进的是，D:/bug_things/selenium/logs/errors/DdtTest.log文件没有明显对各个用例的区分，甚至没有空格行来让显示更明确，还是需要自己去搜索。 后记现在终于是完成了自动化测试的基本模块，日志和测试报告真的是折腾了…后期自己前端知识丰富之后，还需要优化测试报告。接下来，除了完成从excel和数据库中读取测试数据之外，就真的开始搭建自己的框架了（这几天这牛角尖钻的，解决之后还是挺舒服的~）]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>nose</tag>
        <tag>python3</tag>
        <tag>ddt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单元测试异常捕获]]></title>
    <url>%2F2018%2F02%2F08%2F%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%BC%82%E5%B8%B8%E6%8D%95%E8%8E%B7%2F</url>
    <content type="text"><![CDATA[关于自动化测试执行期间断言的异常的选择迷茫 大概是这段时间有点压抑，昨天下午就不知道怎么钻在了单元测试断言失败需不需要捕获异常这个问题上。大家都知道，进行单元测试时，加入断言验证单元测试结果，断言失败会报错，通过会打印ok标识。 nose进行单元测试使用nose进行单元测试示例：123456789#!/usr/bin/env python3# -*- coding: utf-8 -*-from nose.tools import assert_equaldef test_sum(): a = 1 b = 2 res = 5 assert_equal(res, a+b) 控制台执行1nosetests -v -s Testexec.py 打印信息12345678910111213141516Testexec.test_sum ... FAIL======================================================================FAIL: Testexec.test_sum----------------------------------------------------------------------Traceback (most recent call last): File &quot;g:\skills\python36\lib\site-packages\nose\case.py&quot;, line 198, in runTest self.test(*self.arg) File &quot;G:\workstation\py_workstation\DataDriverTest\Testexec.py&quot;, line 17, in test_sum assert_equal(res, a+b)AssertionError: 5 != 3----------------------------------------------------------------------Ran 1 test in 0.007sFAILED (failures=1) 可以看出，断言失败了，控制台也打印出了断言失败的信息。但是在进行自动化测试过程中，如果你想加入日志模块，在执行过程中就在控制台或者文件中打印日志，例如：Testexec.test_sum ... 断言失败，3不等于5这样的信息，很明显，直接用上述写法是不会走到打印失败信息这一步，所以就需要将断言失败的异常捕获，类似这样：123456789101112#!/usr/bin/env python3# -*- coding: utf-8 -*-from nose.tools import assert_equaldef test_sum(): try: a = 1 b = 2 res = 5 assert_equal(res, a+b) except AssertionError as e: print(&quot;断言失败，&#123;0&#125;不等于&#123;1&#125;&quot;.format(a+b, res)) 这种写法执行单元测试，结果：12345678&#123;lamb&#125; nosetests -v -s Testexec.pyTestexec.test_sum ... 断言失败，3不等于5ok----------------------------------------------------------------------Ran 1 test in 0.002sOK 可以看见在断言失败的情况下，打印出了自定义的断言失败信息，这样也就满足进行自动化测试时，实时有日志生成，方便查看，但是这样有个问题，你一旦把断言失败的异常捕获了，那该条测试执行结果就是OK状态，到最后统计时候就不容易看出是哪条执行失败了，只能查看日志；而且日志中也没有展示具体在哪一行有报错，所以这样的方式需要改进。 打印堆栈信息在断言失败时，把异常捕获，此时不会展示具体断言错误的信息，所以就需要添加堆栈信息打印：123456789def test_sum(): try: a = 1 b = 2 res = 5 assert_equal(res, a+b) except AssertionError as e: logging.error(&quot;断言失败，&#123;0&#125;不等于&#123;1&#125;&quot;.format(a+b, res) + str(traceback.print_exc()) 这样就可以获取堆栈信息，可以查看具体哪一行有报错，但是，这样堆栈的日志也只会打印在控制台上，不利于查看，好traceback.print_exc()可以指定日志输出路径，所以只需要修改为：123456789def test_sum(): try: a = 1 b = 2 res = 5 assert_equal(res, a+b) except AssertionError as e: logging.error(&quot;断言失败，&#123;0&#125;不等于&#123;1&#125;&quot;.format(a+b, res) + str(traceback.print_exc(file=open(&apos;test.log&apos;, &apos;a&apos;)))) 这样就可以完成，错误日志打印到文件中，其中a表示append。 邮件附件在进行自动化测试时，我们经常不仅需要日志文件，更多用到的是测试报告，在自动化用例执行完成之后以邮件形式发送到指定邮箱，只需要查看邮件的附件，就可以知晓用例执行情况；但是使用unittest或者nose时，一旦把断言异常捕获，那该条用例结果就是ok状态，实际上我们知道这条用例其实是执行失败了，这样，使用HTMLTestRunner或者是nosetests --with-html --html-file生成的html文件中，用例执行状态就都是success状态，很显然是不正确的。 所以我考虑的是，自己写自定义的测试报告样式，定义一个状态标志status，初始状态为success，在用例执行过程中，一旦捕获了断言异常，就将状态更新为fail，在测试报告中，执行结果栏展示的是该状态，这样就可以实现结果查看了。 自定义测试报告样式。。现在还是只有这个想法，未完待续，待实现了再来更新！（前端知识匮乏啊，越来越觉得自己弱。。。） 断言捕获，可以生成日志，在屏幕和日志文件中打印显示，但是，这样，所有的单元测试都是通过状态，没有一条fail； 断言不捕获，直接邮件发送结果，可以在邮件中看出具体哪条用例执行失败，可以点开失败，查看具体失败信息]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
        <tag>单元测试</tag>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nose执行顺序]]></title>
    <url>%2F2018%2F02%2F07%2Fnose%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[nose单元测试执行顺序 nose和unittest一样，都可以在用例中指定setUp()和tearDown()（用户测试初始化以及测试结束后的操作），在nose中，package、module、class都可以设置setup()和teardown()； package中设置在package中设置，整个测试的运行期间只会执行一次（新建python package时，会生成一个init.py文件，在其中设置setUp()以及tearDown()即可） 用例中每次都执行setup及teardown在模块、类中执行顺序示例：新建Testexec.py文件，内容：1234567891011121314151617181920212223242526272829303132#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/7 10:39&quot;&quot;&quot;from nose.plugins.skip import SkipTestclass TestClass(): def setUp(self): print(&quot;=============-My Testcase is setup-===========&quot;) def tearDown(self): print(&quot;============My Testcase is teardown===========&quot;) def test_fun1(self): print(&quot;This is test_fun1*******&quot;) pass def test_fun2(self): print(&quot;This is test_fun2=====&quot;) pass def test_fun3(self): print(&quot;This is test_fun3~~~~~~~~~&quot;) raise SkipTest def test_Fun1(self): print(&quot;This is test_Fun1***====***&quot;) pass 命令行执行nosetests：1nosetests -v -s Testexec.py 执行结果：12345678910111213141516171819202122&#123;lamb&#125; nosetests -v -s Testexec.py Testexec.TestClass.test_Fun1 ... =============-My Testcase is setup-=========== This is test_Fun1***====*** ============My Testcase is teardown=========== ok Testexec.TestClass.test_fun1 ... =============-My Testcase is setup-=========== This is test_fun1******* ============My Testcase is teardown=========== ok Testexec.TestClass.test_fun2 ... =============-My Testcase is setup-=========== This is test_fun2===== ============My Testcase is teardown=========== ok Testexec.TestClass.test_fun3 ... =============-My Testcase is setup-=========== This is test_fun3~~~~~~~~~ ============My Testcase is teardown=========== SKIP ---------------------------------------------------------------------- Ran 4 tests in 0.005s OK (SKIP=1) 可以看见在对每一个函数进行测试时，都执行了一次setUp()以及tearDown()；且用例执行顺序是：1test_Fun1 -&gt; test_fun1 -&gt; test_fun2 -&gt; test_fun3 其中test_fun3跳过了测试，执行顺序是按照先大写字母，再小写字母，然后再按阿拉伯数字排列的。 用例中只执行一次setup及teardown只需要在setUpClass()及tearDownClass()前加修饰器@classmethod即可：12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/7 10:39&quot;&quot;&quot;from nose.plugins.skip import SkipTestclass TestClass(): @classmethod def setUpClass(cls): print(&quot;只初始化一次setup=======&quot;) @classmethod def tearDownClass(cls): print(&quot;只teardown一次***********&quot;) def setUp(self): print(&quot;=============-My Testcase is setup-===========&quot;) def tearDown(self): print(&quot;============My Testcase is teardown===========&quot;) def test_fun1(self): print(&quot;This is test_fun1*******&quot;) pass def test_fun2(self): print(&quot;This is test_fun2=====&quot;) pass def test_fun3(self): print(&quot;This is test_fun3~~~~~~~~~&quot;) raise SkipTest def test_Fun1(self): print(&quot;This is test_Fun1***====***&quot;) pass 执行测试：1nosetests -v -s Testexec.py 执行结果：123456789101112131415161718192021222324&#123;lamb&#125; nosetests -v -s Testexec.py 只初始化一次setup======= Testexec.TestClass.test_Fun1 ... =============-My Testcase is setup-=========== This is test_Fun1***====*** ============My Testcase is teardown=========== ok Testexec.TestClass.test_fun1 ... =============-My Testcase is setup-=========== This is test_fun1******* ============My Testcase is teardown=========== ok Testexec.TestClass.test_fun2 ... =============-My Testcase is setup-=========== This is test_fun2===== ============My Testcase is teardown=========== ok Testexec.TestClass.test_fun3 ... =============-My Testcase is setup-=========== This is test_fun3~~~~~~~~~ ============My Testcase is teardown=========== SKIP 只teardown一次*********** ---------------------------------------------------------------------- Ran 4 tests in 0.006s OK (SKIP=1) 可以看见，setUpClass()以及tearDownClass都只执行了一次。在自动化测试中，可用来加载配置信息，只需要加载一次即可。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>nose</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于python3的UI自动化框架搭建系列（一）]]></title>
    <url>%2F2018%2F02%2F07%2F%E5%9F%BA%E4%BA%8Epython3%E7%9A%84UI%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[基于python3搭建appium ui自动化测试框架尝试系列（一） 框架实现目标12345678910自动找设备，连接设备自动启动appium server使用yml编写用例配置信息储存在ini文件或conf文件中自定义log，断言失败截图用例框架使用unittest或者nose用例报告html，用例执行完成邮件发送，附件测试报告多线程执行用例，失败重跑机制android自动监控权限弹窗执行过程红性能捕获（adb或者其他形式） 基于ddt和nose的简单尝试当前我能实现的appium自动化测试还是需要手动去起appium server，这点后面需要改善，github上有很多已经实现了的框架，但是不是很想直接拿来用，还是希望能够自己去一点一点的搭建。 即使是简单的尝试，还是想尽量实现多模块。 配置模块邮箱配置：包含邮件收发件人，密码，服务器等信息配置；日志配置：包含日志级别，时间格式，流处理器等；文件夹创建：包含获取当前日期，时间，创建文件夹等； 其实在之前的博客中已经实现，就不再贴代码了： 邮箱配置日志配置 文件夹创建是为了在测试过程中，出现断言失败的场景进行截图保存，文件夹使用两层，上一层为当前日期，下一层为当前时间，截图保存名字为断言失败的名字：MakeDirs.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/usr/bin/env python3# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: kyle@time: 2018/2/7 10:17&quot;&quot;&quot;import time,osimport tracebackfrom datetime import datetime as dtdef getCurrentDate(): &quot;&quot;&quot;获取当前日期&quot;&quot;&quot; date = time.localtime() today = str(date.tm_year) + &quot;-&quot; + str(date.tm_mon) + &quot;-&quot; + str(date.tm_mday) return todaydef getCurrentTime(): &quot;&quot;&quot;获取当前时间&quot;&quot;&quot; time_str = dt.now() now = time_str.strftime(&apos;%H-%M-%S&apos;) return nowdef createDir(): &quot;&quot;&quot;获取当前文件所在路径绝对路径&quot;&quot;&quot; current_path = os.path.abspath(&apos;.&apos;) # 获取当前日期 today = getCurrentDate() # 构造以今天日期命名的目录的绝对路径 date_dir = os.path.join(current_path, today) print(date_dir) if not os.path.exists(date_dir): # 如果以今天日期命名的目录不存在则创建 os.mkdir(date_dir) # 获取当前时间字符串 now = getCurrentTime() # 构造以当前时间命名的目录的绝对路径 time_dir = os.path.join(date_dir, now) print(time_dir) if not os.path.exists(time_dir): # 如果以当前时间命名的目录不存在则创建 os.mkdir(time_dir) return time_dirdef takeScreenShot(driver, save_path, pic_name): &quot;&quot;&quot;截屏&quot;&quot;&quot; pic_path = os.path.join(save_path, str(pic_name) + &quot;.png&quot;) try: driver.get_screenshot_as_file(pic_path) except Exception as e: print(traceback.print_exc(), e) 执行模块实现思路是ddt获取数据对象，进行测试数据和代码分离，数据对象包含输入数据以及预期结果，对预期结果进行断言，实现测试实现。以百度搜索测试为例:DataDriverByObj.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#!/usr/bin/env python3# -*- coding: utf-8 -*-import ddt,timeimport traceback,loggingfrom DdtTools.Log import *from selenium import webdriverfrom nose.tools import assert_truefrom selenium.common.exceptions import NoSuchElementExceptionfrom datetime import datetime as dtfrom DdtTools.MailSend import MailSend@ddt.ddtclass TestDDTByObj(): &quot;&quot;&quot;数据驱动测试&quot;&quot;&quot; def __init__(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; self.browser = webdriver.Chrome() @ddt.data( [u&quot;龙猫&quot;, &quot;宫崎骏&quot;], [u&quot;大话西游之月光宝盒&quot;, &quot;周星驰&quot;], [u&quot;卧虎藏龙&quot;, &quot;李安&quot;] ) @ddt.unpack def test_dataDrivenByObj(self, testdata, expectdata): url = &quot;https://www.baidu.com&quot; self.browser.get(url) # 隐式等待10s self.browser.implicitly_wait(10) try: # 定位搜索输入框，并输入测试数据 self.browser.find_element_by_id(&apos;kw&apos;).send_keys(testdata) # 定位搜索按键，单击 self.browser.find_element_by_id(&apos;su&apos;).click() time.sleep(3) # 断言期望结果是否出现在页面源码中 assert_true(expectdata in self.browser.page_source) except NoSuchElementException as e: logging.error(u&quot;查找的页面元素不存在，异常堆栈信息：&quot; + str(traceback.print_exc())) except AssertionError as e: info(u&quot;搜索：&#123;0&#125;，期望：&#123;1&#125;，失败&quot;.format(testdata, expectdata)) except Exception as e: logging.error(u&quot;未知错误，错误信息：&quot; + str(traceback.print_exc())) else: info(u&quot;搜索：&#123;0&#125;，期望：&#123;1&#125;，通过&quot;.format(testdata, expectdata)) time.sleep(2) self.browser.quit()if __name__ == &apos;__main__&apos;: # mail_subject, report_file mail_subject = &apos;NoseTests_测试报告_&#123;0&#125;&apos;.format(dt.now().strftime(&apos;%Y%m%d&apos;)) report_file = &apos;D:/bug_things/selenium/report/DDTByObj.html&apos; mailsend = MailSend(mail_subject, report_file) print(&apos;开始执行自动化测试...&apos;) os.system(&apos;nosetests -v &#123;0&#125; --with-html --html-file=&#123;1&#125;&apos;.format(__file__, report_file)) # 发送测试报告邮件 print(&apos;开始发送测试报告...&apos;) mailsend.sendMail() print(&apos;测试报告发送完成...&apos;) 后记差不多现在还是实现到现在的程度，后面至少可以优化，测试数据从xls，xml，excel，mysql中读取。（感觉自己现在实现的还是好弱。。。） 附上github上已经实现的框架，供参考，建议还是自己去一点一点的搭建，直接用个人觉得是有点功利的做法了，写代码，还是慢慢来的好。 ATXAuto_AnalysisAPPIUM]]></content>
      <categories>
        <category>自动化测试框架</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
        <tag>appium</tag>
        <tag>nose</tag>
        <tag>python3</tag>
        <tag>ddt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】python实现chrome伪装成M站]]></title>
    <url>%2F2018%2F02%2F06%2F%E3%80%90%E8%BD%AC%E3%80%91python%E5%AE%9E%E7%8E%B0chrome%E4%BC%AA%E8%A3%85%E6%88%90M%E7%AB%99%2F</url>
    <content type="text"><![CDATA[selenium实现Chrome伪装成M站，模拟手机端浏览器，并完成页面操作 原理：通过--user-agent=&quot;xxx&quot;来修改HTTP请求头部的Agent字符串，设置个人代理，使得PC端的Chrome浏览器伪装成手机浏览器，可以在地址栏输入”about:version”查看修改效果。 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverfrom Log import *import timeclass TestMobile(): &quot;&quot;&quot;测试chrome伪装成手机M站&quot;&quot;&quot; def test_iPadChrome(self): # 添加chrome设置 info(u&quot;===========伪装成ipad==========&quot;) info(u&quot;=====开始设置ipad个人代理=====&quot;) options = webdriver.ChromeOptions() options.add_argument( &apos;--user-agent=Mozilla/5.0(iPad; CPU OS 5_0 like Mac OS X)&apos; &apos;AppleWebKit/534.46(KHTML, like Gecko) Version/5.1&apos; &apos;Mobile/9A334 Safari/7534.48.3&apos; ) browser = webdriver.Chrome(chrome_options=options) browser.get(&quot;https://www.baidu.com&quot;) time.sleep(3) browser.find_element_by_id(&apos;kw&apos;).send_keys(&quot;iPad&quot;) time.sleep(1) # 通过在Chrome浏览器地址栏输入about:version，查看伪装效果 browser.get(&quot;about:version&quot;) # 人工确认“用户代理”项配置信息是否和设置一致 time.sleep(10) info(u&quot;==========伪装ipad成功==========&quot;) browser.quit() def test_iPhoneChrome(self): # 添加chrome配置 info(u&quot;==========测伪装成iphone==========&quot;) info(u&quot;=====设置iphone个人代理=====&quot;) options = webdriver.ChromeOptions() options.add_argument( &apos;--user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 5_0 like Mac OS X)&apos; &apos;AppleWebKit/534.46(KHTML, like Gecko) Version/5.1&apos; &apos;Mobile/9A334 Safari/7534.48.3&apos; ) browser = webdriver.Chrome(chrome_options=options) browser.get(&quot;https://www.baidu.com&quot;) time.sleep(3) # 定位搜索框 browser.find_element_by_id(&quot;index-kw&quot;).send_keys(&quot;iPhone&quot;) time.sleep(1) browser.get(&quot;about:version&quot;) time.sleep(10) info(u&quot;==========伪装成iphone成功==========&quot;) browser.quit() def testAndroid236Chrome(self): info(u&quot;==========测试伪装成android2.3.6==========&quot;) info(u&quot;=====设置android2.3.6个人代理=====&quot;) options = webdriver.ChromeOptions() options.add_argument( &apos;--user-agent=Mozilla/5.0 (Linux; U; Android 2.3.5; en-us)&apos; &apos;Nexus S Build/GRK39F) AppleWebKit/533.1&apos; &apos;(KHTML, like Gecko) Version/4.0 Mobile Safari/533.1&apos; ) brower = webdriver.Chrome(chrome_options=options) brower.get(&quot;https://www.baidu.com&quot;) # 定位搜索输入框 brower.find_element_by_id(&quot;index-kw&quot;).send_keys(&quot;Android 2.3.6&quot;) time.sleep(1) brower.get(&quot;about:version&quot;) time.sleep(10) info(u&quot;==========伪装成android2.3.6成功==========&quot;) brower.quit() def testAndroid402Chrome(self): info(u&quot;==========测试伪装成android4.0.2==========&quot;) info(u&quot;=====设置android4.0.2个人代理&quot;) options = webdriver.ChromeOptions() options.add_argument( &apos;--user-agent=Mozilla/5.0 (Linux; U; Android 4.0.2;&apos; &apos;en-us; Galaxy Nexus Build/ICL53F) AppleWebKit/534.30&apos; &apos;(KHTML, like Gecko) Version/4.0 Mobile Safari/534.30&apos; ) browser = webdriver.Chrome(chrome_options=options) browser.get(&quot;http://www.baidu.com&quot;) time.sleep(3) browser.find_element_by_id(&quot;index-kw&quot;).send_keys(&quot;Android 4.0.2&quot;) time.sleep(1) browser.get(&quot;about:version&quot;) time.sleep(10) info(u&quot;==========伪装成android4.0.2成功==========&quot;) browser.quit()if __name__ == &apos;__main__&apos;: testmobile = TestMobile() testmobile.testAndroid402Chrome() testmobile.testAndroid236Chrome() testmobile.test_iPhoneChrome() testmobile.test_iPadChrome() 偶然看见这个实现，目前没想到应用场景。。直接使用appium进行移动自动化好像也能实现啊。。（可能工作中遇见的太少了）]]></content>
      <categories>
        <category>selenium</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logging模块使用简介]]></title>
    <url>%2F2018%2F02%2F02%2Flogging%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[python3日志模块，logging使用简介 日志打印python3使用logging进行日志打印，很简单，直接引logging包即可：123456789import logginglogging.warning(&quot;This is warning message&quot;)logging.critical(&quot;This is critical message&quot;)logging.error(&quot;This is error message&quot;)# 打印结果WARNING:root:This is warning messageCRITICAL:root:This is critical messageERROR:root:This is error message 默认情况下只显示了大于等于WARNING级别的日志。日志级别：1critical(50) &gt; error(40) &gt; warning(30) &gt; info(20) &gt; debug(10) 简单应用通过logging.basicConfig函数对日志的输出格式及方式做相关配置1234567891011121314151617#!/usr/bin/env python3# -*- coding: utf-8 -*-import logginglogging.basicConfig( filename=&apos;test.log&apos;, format=&apos;%(asctime)s - %(name)s - %(levelname)s - %(module)s: %(message)s&apos;, datefmt=&apos;%Y-%m-%d %H-%M-%S&apos;, level=logging.DEBUG, #level=10)logging.critical(&quot;This ia critical message&quot;)logging.error(&quot;This is error message&quot;)logging.warning(&quot;This is warning message&quot;)logging.info(&quot;This is info message&quot;)logging.debug(&quot;This is debug message&quot;) logging.basicConfig函数各参数 1.filename：指定日志文件名2.filemode：和file函数意义相同，指定日志文件的打开模式，’w’或’a’；默认为’a’表示“append”。3.format：指定输出的格式和内容，format可以输出很多有用信息： 12345678910111213141516format参数中可能用到的格式化串：%(name)s Logger的名字%(levelno)s 数字形式的日志级别%(levelname)s 文本形式的日志级别%(pathname)s 调用日志输出函数的模块的完整路径名，可能没有%(filename)s 调用日志输出函数的模块的文件名%(module)s 调用日志输出函数的模块名%(funcName)s 调用日志输出函数的函数名%(lineno)d 调用日志输出函数的语句所在的代码行%(created)f 当前时间，用UNIX标准的表示时间的浮 点数表示%(relativeCreated)d 输出日志信息时的，自Logger创建以 来的毫秒数%(asctime)s 字符串形式的当前时间。默认格式是 “2003-07-08 16:49:45,896”。逗号后面的是毫秒%(thread)d 线程ID。可能没有%(threadName)s 线程名。可能没有%(process)d 进程ID。可能没有%(message)s用户输出的消息 4.datefmt：指定时间格式，同time.strftime()5.level：设置日志级别，默认为logging.WARNING6.stream：指定将日志的输出流，可以指定输出到sys.stderr，sys.stdout或者文件，默认输出到sys.stderr，当stream和filename同时指定时，stream被忽略 模块介绍若要对logging进行更多灵活的控制，必须了解Logger，Handler，Formatter，Filter的概念：logger提供了应用程序可以直接使用的接口；handle将（logger创建的）日志记录发送到合适的目的输出；filter提供了细度设备来决定输出哪条日志记录；formatter决定日志记录的最终输出格式； Logger每个程序在输出信息之前都要获得一个Logger。Logger通常对应了程序的模块名，比如聊天工具的图形界面模块可以这样获得它的Logger：LOG=logging.getLogger(”chat.gui”)而核心模块可以这样：LOG=logging.getLogger(”chat.kernel”) Logger.setLevel(lel):指定最低的日志级别，低于lel的级别将被忽略。debug是最低的内置级别，critical为最高Logger.addFilter(filt)、Logger.removeFilter(filt):添加或删除指定的filterLogger.addHandler(hdlr)、Logger.removeHandler(hdlr)：增加或删除指定的handlerLogger.debug()、Logger.info()、Logger.warning()、Logger.error()、Logger.critical()：可以设置的日志级别 Handlerhandler对象负责发送相关的信息到指定目的地。Python的日志系统有多种Handler可以使用。有些Handler可以把信息输出到控制台，有些Logger可以把信息输出到文件，还有些Handler可以把信息发送到网络上。如果觉得不够用，还可以编写自己的Handler。可以通过addHandler()方法添加多个多handlerHandler.setLevel(lel):指定被处理的信息级别，低于lel级别的信息将被忽略Handler.setFormatter()：给这个handler选择一个格式Handler.addFilter(filt)、Handler.removeFilter(filt)：新增或删除一个filter对象 每个Logger可以附加多个Handler。接下来我们就来介绍一些常用的Handler： 1) logging.StreamHandler使用这个Handler可以向类似与sys.stdout或者sys.stderr的任何文件对象(file object)输出信息。它的构造函数是:StreamHandler([strm])其中strm参数是一个文件对象。默认是sys.stderr 2) logging.FileHandler和StreamHandler类似，用于向一个文件输出日志信息。不过FileHandler会帮你打开这个文件。它的构造函数是：FileHandler(filename[,mode])filename是文件名，必须指定一个文件名。mode是文件的打开方式。参见Python内置函数open()的用法。默认是’a’，即添加到文件末尾。 3) logging.handlers.RotatingFileHandler这个Handler类似于上面的FileHandler，但是它可以管理文件大小。当文件达到一定大小之后，它会自动将当前日志文件改名，然后创建 一个新的同名日志文件继续输出。比如日志文件是chat.log。当chat.log达到指定的大小之后，RotatingFileHandler自动把文件改名为chat.log.1。不过，如果chat.log.1已经存在，会先把chat.log.1重命名为chat.log.2。。。最后重新创建 chat.log，继续输出日志信息。它的构造函数是：RotatingFileHandler( filename[, mode[, maxBytes[, backupCount]]])其中filename和mode两个参数和FileHandler一样。maxBytes用于指定日志文件的最大文件大小。如果maxBytes为0，意味着日志文件可以无限大，这时上面描述的重命名过程就不会发生。backupCount用于指定保留的备份文件的个数。比如，如果指定为2，当上面描述的重命名过程发生时，原有的chat.log.2并不会被更名，而是被删除。 4) logging.handlers.TimedRotatingFileHandler这个Handler和RotatingFileHandler类似，不过，它没有通过判断文件大小来决定何时重新创建日志文件，而是间隔一定时间就 自动创建新的日志文件。重命名的过程与RotatingFileHandler类似，不过新的文件不是附加数字，而是当前时间。它的构造函数是：TimedRotatingFileHandler( filename [,when [,interval [,backupCount]]])其中filename参数和backupCount参数和RotatingFileHandler具有相同的意义。interval是时间间隔。when参数是一个字符串。表示时间间隔的单位，不区分大小写。它有以下取值：S 秒M 分H 小时D 天W 每星期（interval==0时代表星期一）midnight 每天凌晨 实例日志的一般操作顺序为：1.创建一个流类型handler用于输出日志到控制台(控制器)2.定义输出日志级别3.定义handler的输出格式formatter4.将handler添加到logging对象 同时输出日志到控制台和文件1234567891011121314151617181920212223242526#!/usr/bin/env python3# -*- coding: utf-8 -*-import logginglogging.basicConfig( filename=&apos;test.log&apos;, format=&apos;%(asctime)s - %(name)s - %(levelname)s -%(module)s: %(message)s&apos;, datefmt=&apos;%Y-%m-%d %H-%M-%S&apos;, level=10)# 定义一个StreamHandler(日志流处理器)，将INFO级别或更高的日志信息打印到标准错误，并将其添加到当前的日志处理对象console = logging.StreamHandler()console.setLevel(logging.INFO)# 格式化，设置控制台的日志输出格式formatter = logging.Formatter(&apos;%(name)-12s: %(levelname)-8s %(message)s&apos;)# 定义控制器的日志输出格式console.setFormatter(formatter)# 将控制器添加到logging对象logging.getLogger(&apos;&apos;).addHandler(console)logging.critical(&quot;This is critical message&quot;)logging.error(&quot;This is error message&quot;)logging.warning(&quot;This is warning message&quot;)logging.info(&quot;This is info message&quot;)logging.debug(&quot;This is debug message&quot;) 配置文件用法类似于java中的log4j的logging.config，我们也可以自己配置logger.conf文件： Logger.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950###############################################[loggers]keys=root,example01,example02[logger_root]level=DEBUGhandlers=hand01,hand02[logger_example01]handlers=hand01,hand02qualname=example01propagate=0[logger_example02]handlers=hand01,hand03qualname=example02propagate=0###############################################[handlers]keys=hand01,hand02,hand03[handler_hand01]class=StreamHandlerlevel=INFOformatter=form02args=(sys.stderr,)[handler_hand02]class=FileHandlerlevel=DEBUGformatter=form01args=(&apos;D:/bug_things/selenium/logs/AutoTest.log&apos;, &apos;a&apos;, &apos;utf-8&apos;)[handler_hand03]class=handlers.RotatingFileHandlerlevel=INFOformatter=form02args=(&apos;D:/bug_things/selenium/logs/AutoTest.log&apos;, &apos;a&apos;, 10*1024*1024, 5, &apos;utf-8&apos;)###############################################[formatters]keys=form01,form02[formatter_form01]format=%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)sdatefmt=%a, %d %b %Y %H:%M:%S[formatter_form02]format=%(name)-12s: %(levelname)-8s %(message)sdatefmt=%Y %m %d %H %M %S 封装方法将配置文件中定义的日志打印的配置进行封装，生成debug，info，message方法：Log.py1234567891011121314151617181920#!/usr/bin/env python3# -*- coding: utf-8 -*-import logging.configlogging.config.fileConfig(&quot;Logger.conf&quot;)def debug(message): # 打印debug级别的日志方法 logging.debug(message)def warning(message): # 打印warning级别的日志方法 logging.warning(message)def info(message): # 打印info级别的日志方法 logging.info(message) 应用以百度搜索为例:BaiDu.py1234567891011121314151617181920212223242526272829#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverfrom Log import *import timeclass TestBaiDuSearch(): def __init__(self): # 启动浏览器 self.browser = webdriver.Chrome() def test_baidu_search(self): info(u&quot;===================搜索====================&quot;) url = &quot;https://www.baidu.com&quot; self.browser.get(url) info(u&quot;访问百度首页&quot;) self.browser.find_element_by_id(&apos;kw&apos;).send_keys(u&quot;自动化测试&quot;) info(u&quot;在输入框中搜索关键字“自动化测试”&quot;) self.browser.find_element_by_id(&apos;su&apos;).click() info(u&quot;单击搜索按键&quot;) info(u&quot;=================测试执行结束================&quot;) time.sleep(3) self.browser.quit()if __name__ == &apos;__main__&apos;: testbaidu = TestBaiDuSearch() testbaidu.test_baidu_search() 执行BaiDu.py文件，在D:/bug_things/selenium/logs目录下会生成AutoTest.log日志文件，文件内容：12345Fri, 02 Feb 2018 17:10:52 Log.py[line:20] INFO ===================搜索====================Fri, 02 Feb 2018 17:10:53 Log.py[line:20] INFO 访问百度首页Fri, 02 Feb 2018 17:10:53 Log.py[line:20] INFO 在输入框中搜索关键字“自动化测试”Fri, 02 Feb 2018 17:10:53 Log.py[line:20] INFO 单击搜索按键Fri, 02 Feb 2018 17:10:53 Log.py[line:20] INFO =================测试执行结束================ 同时控制台打印信息：12345root : INFO ===================搜索====================root : INFO 访问百度首页root : INFO 在输入框中搜索关键字“自动化测试”root : INFO 单击搜索按键root : INFO =================测试执行结束================ 参考文章]]></content>
      <categories>
        <category>python黑科技</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>python3</tag>
        <tag>logging</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符编码简单总结]]></title>
    <url>%2F2018%2F02%2F02%2F%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[python字符串和编码 首先，字符串是一种数据类型，我们还经常会用到，然后，最常见的字符串问题就是字符编码问题，经常会看见文件打开一堆乱码，然后手工转utf-8啥的。 字符编码计算机基础计算机能够处理的只有数字，所以其他类型的数据想要被计算机识别并处理，首先要进行的就是字符编码，转换成数字之后处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是(11111111,二进制的255)，如果要表示更大的整数，就必须更多的字节，比如两个字节可以表示最大整数是65535。 上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为 ASCII 码，一直沿用至今。ASCII 码一共规定了128个字符的编码，比如空格SPACE是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的一位统一规定为0。 字库表字库表是一个相当于所有可读或者可显示字符的数据库，字库表决定了整个字符集能够展现表示的所有字符的范围。 字符集字符集是一个系统支持的所有抽象字符的集合。常见的字符集有ASCII，UTF-8，UTG-16，GB2313等。 字符编码字符编码可以看成是一套规则，目的就是在符号集合和数字系统直接建立对应关系。常见的字符编码有Unicode，ASCII，UTF-8等 三者关系字库表可以看成是一个全球统一的可读可用的字符库，但是实际使用过程中，很少需要用到这么多字符，例如，中文系统基本就用不到日文的字符，所以也就不需要日文字符的那一部分集合；因此就会诞生一个个的类似于定制的字符集合，这就是字符集，集合中包含了数据和字母的一个个对应关系，这就是字符编码。以ASCII为例： ASCIIASCII（American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。它主要用于显示现代英语，而其扩展版本EASCII则可以勉强显示其他西欧语言。它是现今最通用的单字节编码系统（但是有被Unicode追上的迹象），并等同于国际标准ISO/IEC 646。 ASCII字符集：主要包括控制字符（回车键、退格、换行键等）；可显示字符（英文大小写字符、阿拉伯数字和西文符号）。 ASCII编码：将ASCII字符集转换为计算机可以接受的数字系统的数的规则。使用7位（bits）表示一个字符，共128字符；但是7位编码的字符集只能支持128个字符，为了表示更多的欧洲常用字符对ASCII进行了扩展，ASCII扩展字符集使用8位（bits）表示一个字符，共256字符。 python字符编码ASCII是出现比较早的字符编码，但是其中只包含了数字和英文大小写字符，对于中文，日文等字符就不适用了，国内学者为了能够完成中文编码，就指定了GB2312编码，同样的，很多国家都有指定自己的编码，这样就会遇到一个问题，中文编码到日文编码的环境查看，会发生乱码，因为根本就不支持这样的字符，为了解决这个问题，一个统一的编码就诞生了Unicode，Unicode编码不同于ASCII的使用一个字节表示一个字符，它使用的是两个字节表示一个字符（中文至少需要两个字节），生僻字符就需要4个字符。字母’A’用ASCII编码，十进制是65，二进制是01000001；用Unicode编码结果是00000000 01000001。当全部都使用Unicode编码时，乱码问题肯定是得到解决了，但是有个问题，Unicode编码时连个字节表示的一个字符，那么就会比原来使用ASCII编码多出了至少一倍的内存空间占用，怎么都觉得很亏。所以，为了节约内存空间，又出现了把Unicode编码转换为“可变长编码”的utf-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间。 下面来弄清楚python的字符编码：在python3中，字符串是以Unicode编码的，也就是说，支持多语言。由于Python的字符串类型是str，在内存中以Unicode表示，一个字符对应若干个字节。如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。Python对bytes类型的数据用带b前缀的单引号或双引号表示：1x = b&apos;ABC&apos; 注意区分’ABC’和b’ABC’，前者是str，后者虽然内容显示得和前者一样，但bytes的每个字符都只占用一个字节。纯英文的str可以用ASCII编码为bytes，内容是一样的，含有中文的str可以用UTF-8编码为bytes。含有中文的str无法用ASCII编码，因为中文编码的范围超过了ASCII编码的范围，Python会报错。 编码及解码首先python使用的是Unicode编码，字符串进行网络或者磁盘存储时，需要先编码成指定类型bytes，使用encode()方法即可。例如：12print(&apos;中文&apos;.encode(&apos;utf-8&apos;))b&apos;\xe4\xb8\xad\xe6\x96\x87&apos; 反过来，从网络或者磁盘上读取字节流，那么读到的数据是bytes，要把bytes转换为str，就需要使用decode()方法进行解码，例如：12print(b&apos;\xe4\xb8\xad\xe6\x96\x87&apos;.decode(&apos;utf-8&apos;))中文 在进行日常python编程中，在操作字符串时，我们经常遇到str和bytes的互相转换。为了避免乱码问题，应当始终坚持使用UTF-8编码对str和bytes进行转换。 由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。当Python解释器读取源代码时，为了让它按UTF-8编码读取，我们通常在文件开头写上:12#!/usr/bin/env python3# -*- coding: utf-8 -*- pycharm设置方法：File-Settings-Editor-File and Code Templates-Python Script设置中添加上这两行即可。 以前曾经写过一篇博，关于设置python编码的:python编码 参考链接 廖雪峰的python教程字符集合字符编码 后记：由于昨天公司发生的很无语加无理取闹的一些事，整个办公室氛围都是压抑的，网上的教程资料也没怎么细致的看进去，写出来的总结也就是乱七八糟的，估计静下来之后我自己都看不懂。。。以后再来修改吧。唉，做技术的，干嘛不追求技术的进步，弄一些有的没的办公室政治呢，有意思吗？]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现断言失败截图]]></title>
    <url>%2F2018%2F02%2F02%2F%E5%AE%9E%E7%8E%B0%E6%96%AD%E8%A8%80%E5%A4%B1%E8%B4%A5%E6%88%AA%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[python基于selenium进行自动化测试，实现断言失败进行截图 进行自动化测试过程中，经常会遇见断言失败，时候补查失败的场景，要么是保存日志，要么就是保存失败的截图。尝试实现，在断言失败时候，加入实时截图： 编码出错遇到问题：截图文件名编码格式转换时候，会报错（以下写法在python 2.7可以使用）1pic_path = os.path.join(save_path, str(pic_name).decode(&quot;utf-8&quot;).encode(&quot;gbk&quot;) + &quot;.png&quot;) 报错：1AttributeError: &apos;str&apos; object has no attribute &apos;decode&apos; 查找原因：既然python 2.7可以正常执行，那就应该是python 3对于编码进行了变更。 Stack Overflow上大家好像都是经常踩我踩过的所有坑..又找到答案了：这位大哥的回答：1234Begin with Python 3, all string is unicode object. a = &apos;Happy New Year&apos; # Python 3 b = unicode(&apos;Happy New Year&apos;) # Python 2the code before are same. So I think you should remove the .decode(&apos;utf-8&apos;). Because you have already get the unicode object. python3的普通字符串是str，所以python3的str就相当于python2的Unicode。大致意思好像就是python3使用的str类型并不关心你最终是什么编码，无论是utf-8还是gb2312，它只是用Unicode字符集编码来表示每一个字符，直到输出到文件流，需要转换为bytes类型时，才用encode指定具体的编码实现方式。 python的中间编码是Unicode，所以python2就需要先进行解码（decode）到中间编码，再进行编码（encode）到指定编；，而python3直接可以转换到指定编码（encode）1在python3中，str-- encode -&gt; bytes-- decode -&gt; str python3编码系统编码123456789101112import sys# 系统默认编码print(sys.getdefaultencoding())# 字符串编码s = &quot;中文&quot;s_utf8 = s.encode(&apos;utf-8&apos;)print(type(s))print(type(s_utf8))utf-8&lt;class &apos;str&apos;&gt;&lt;class &apos;bytes&apos;&gt; 可以看到，python3的系统编码就是utf-8，为了避免自找麻烦，牢记使用utf-8即可！所以上述报错代码可以更改为：1pic_path = os.path.join(save_path, str(pic_name) + &quot;.png&quot;) 断言失败截图实例实现目标是在进行自动化测试过程中，一旦发生断言失败，就根据当前时间，在工程下创建名称为当前日期的目录，，目录下创建名称为当前时间的文件夹，文件夹中保存断言失败的屏幕截图 获取当前日期和时间123456789101112131415161718192021#!/usr/bin/env python3# -*- coding: utf-8 -*-import timefrom datetime import datetime as dt&quot;&quot;&quot;用于获取当前的日期以及时间用于生成保存截图文件目录名&quot;&quot;&quot;def current_date(): date = time.localtime() # 构造今天的日期字符串 today = str(date.tm_year) + &quot;-&quot; + str(date.tm_mon) + &quot;-&quot; + str(date.tm_mday) return todaydef current_time(): time_str = dt.now() # 构建当期时间字符串 now = time_str.strftime(&apos;%H-%M-%S&apos;) return now 创建目录和文件夹123456789101112131415161718192021222324252627282930#!/usr/bin/env python3# -*- coding: utf-8 -*-from DateUtil import current_time, current_dateimport os&quot;&quot;&quot;用于创建目录，用于存放异常截图&quot;&quot;&quot;def create_dir(): # 获得当前文件所在目录的绝对路径 current_path = os.path.abspath(&apos;.&apos;) # 获取今天的日期字符串 today = current_date() # 构造以今天日期命名的目录的绝对路径 date_dir = os.path.join(current_path, today) print(date_dir) if not os.path.exists(date_dir): # 如果以今天日期命名的目录不存在则创建 os.mkdir(date_dir) # 获取当前的时间字符串 now = current_time() # 构造以当前时间命名的目录的绝对路径 time_dir = os.path.join(date_dir, now) print(time_dir) if not os.path.exists(time_dir): # 如果以当前时间命名的目录不存在则创建 os.mkdir(time_dir) return time_dir 百度搜索示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverfrom FileUtil import create_dirfrom nose.tools import assert_trueimport time,osimport traceback# 创建存放异常截图的目录，并得到本次实例中存放图片目录的绝对路径，作为全局变量，供本次所有测试用例调用pic_dir = create_dir()def take_screenshot(driver, save_path, pic_name): # 封装截屏方法 # 构造屏幕截图路径及图片名 # 因为windows默认编码是GBK，而传入的图片名是utf-8编码，所以需要进行转码，以便让图片名中的中文字符能够正常显示 pic_path = os.path.join(save_path, str(pic_name) + &quot;.png&quot;) try: # 调用webdriver提供的get_screenshot_as_file()方法，将截取的屏幕图片保存为本地文件 driver.get_screenshot_as_file(pic_path) except Exception as e: print(traceback.print_exc(), e)class TestFailCaptureScreen(): def __init__(self): &quot;&quot;&quot;启动浏览器&quot;&quot;&quot; self.browser = webdriver.Chrome() def test_baidu_search(self): url = &quot;https://www.baidu.com&quot; self.browser.get(url) try: self.browser.find_element_by_id(&apos;kw&apos;).send_keys(u&quot;自动化测试&quot;) self.browser.find_element_by_id(&apos;su&apos;).click() time.sleep(3) # 断言页面的代码中是否存在“自动化测试框架_百度百科”这几个字 assert_true(u&quot;纯净方糖&quot; in self.browser.page_source) # 页面中没有断言的几个字，所以会触发except语句的执行，并触发截图操作 except AssertionError as e: take_screenshot(self.browser, pic_dir, e) except Exception as e: take_screenshot(self.browser, pic_dir, e) time.sleep(2) self.browser.quit()if __name__ == &apos;__main__&apos;: testfailscreen = TestFailCaptureScreen() testfailscreen.test_baidu_search() 感觉是时候研究一波python字符编码了…]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现自动化测试数据分离]]></title>
    <url>%2F2018%2F02%2F01%2F%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[使用数据分离自动化测试，测试执行完成自动邮件发送 配置文件配置文件中的内容为工程所有配置信息，各个模块的元素定位的方法以及值，服务器（应用服务器和数据库服务器）配置信息，用户账号密码等信息 实例，cashier.ini 1234567891011121314[login]storeNo = id &gt; com.anmav.cashierdesk:id/etStoreNousername = id &gt; com.anmav.cashierdesk:id/login_accountEdtpwd = id &gt; com.anmav.cashierdesk:id/login_paswEdtlogin = id &gt; com.anmav.cashierdesk:id/tvLoginlogin_store = ***login_user = ***login_pwd = ***[mailmsg]mail_user = ***mail_pwd = ***mail_to = ***mail_host = *** 该配置文件包含了login模块进行元素定位需要的方法以及值，在工程中进行元素定位值，只需要使用configparser模块完成配置文件读取即可。 邮件发送数据分离封装数据分离之后的邮件发送类(MailSend.py)：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python3# -*- coding: utf-8 -*-from email.mime.text import MIMETextfrom email.mime.multipart import MIMEMultipartimport smtplibimport configparserimport osclass MailSend(): &quot;&quot;&quot;邮件发送&quot;&quot;&quot; def __init__(self, mail_subject, report_file): self.mail_subject = mail_subject self.report_file = report_file self.settings = os.path.abspath(&apos;..&apos;) + &quot;\cashier_conf\cashier_setting.ini&quot; def send_mail(self): &quot;&quot;&quot;读取测试报告&quot;&quot;&quot; cf = configparser.ConfigParser() cf.read(self.settings) cf.sections() # 获取邮箱发件人，密码，收件人，邮件服务器 mail_user = cf.get(&apos;mailmsg&apos;, &apos;mail_user&apos;) mail_pwd = cf.get(&apos;mailmsg&apos;, &apos;mail_pwd&apos;) mail_to = cf.get(&apos;mailmsg&apos;, &apos;mail_to&apos;) mail_host = cf.get(&apos;mailmsg&apos;, &apos;mail_host&apos;) # 发送邮件配置 with open(self.report_file, &apos;r&apos;, encoding=&apos;utf-8&apos;) as f_obj: content = f_obj.read() msg = MIMEMultipart(&apos;mixed&apos;) # 添加邮件内容 msg_html = MIMEText(content, &apos;html&apos;, &apos;utf-8&apos;) msg.attach(msg_html) # 添加附件 msg_attachment = MIMEText(content, &apos;html&apos;, &apos;utf-8&apos;) msg_attachment[&quot;Content-Disposition&quot;] = &apos;attachment; filename=&#123;0&#125;&apos;.format(self.report_file) msg.attach(msg_attachment) msg[&apos;Subject&apos;] = self.mail_subject msg[&apos;Form&apos;] = mail_user msg[&apos;To&apos;] = mail_to try: # 连接邮箱服务器 s = smtplib.SMTP() s.connect(mail_host) # 登录 s.login(mail_user, mail_pwd) # 发送邮件 s.sendmail(mail_user, mail_to, msg.as_string()) s.quit() except Exception as e: print(&quot;发送邮件异常：&quot;, e) 元素定位数据分离封装了元素定位的方法（find_element_by…），实现在工程中进行元素定位时，直接调用方法(GetElement.py)：123456789101112131415161718192021222324252627282930#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium.webdriver.support.ui import WebDriverWaitimport osimport configparserimport tracebackclass GetElement(): &quot;&quot;&quot;获取元素定位方法和值&quot;&quot;&quot; def __init__(self): # 读取配置文件 self.settings = os.path.abspath(&apos;..&apos;) + &quot;/cashier_conf/cashier_setting.ini&quot; self.cf = configparser.ConfigParser() self.cf.read(self.settings) self.cf.sections() def get_elementId(self, driver, webSiteName, webelement): try: # 获取配置文件中的定位方法以及定位元素 webElemnt = self.cf.get(webSiteName, webelement).split(&apos;&gt;&apos;) webelement_method = webElemnt[0].strip() webelement_expression = webElemnt[1].strip() element = WebDriverWait(driver, 10).until\ (lambda x: x.find_element(webelement_method, webelement_expression)) except Exception as e: print(traceback.print_exc(), e) else: return element 自动化测试实现数据分离使用数据分离的方式完成系统登录的自动化测试，方便维护，后期只需要维护cashier_setting.ini文件即可(testlogin.py)。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#!/usr/bin/env python3# -*- coding: utf-8 -*-import configparser, osimport tracebackfrom datetime import datetime as dtfrom appium import webdriverfrom nose.tools import assert_truefrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.common.exceptions import NoSuchElementException,TimeoutExceptionfrom cashier_tools.GetElement import GetElementfrom cashier_tools.MailSend import MailSendclass Login(): &quot;&quot;&quot;登录&quot;&quot;&quot; def __init__(self): # 初始化，配置环境 self.desired_caps = &#123;&#125; self.desired_caps[&apos;platformName&apos;] = &apos;Android&apos; self.desired_caps[&apos;platformVersion&apos;] = &apos;5.1&apos; self.desired_caps[&apos;deviceName&apos;] = &apos;Android Emulator&apos; self.desired_caps[&apos;noReset&apos;] = True self.desired_caps[&apos;appPackage&apos;] = &apos;com.anmav.cashierdesk&apos; self.desired_caps[&apos;appActivity&apos;] = &apos;com.anmav.cashierdesk.login.activity.LoginActivity&apos; self.driver = webdriver.Remote(&apos;http://localhost:4723/wd/hub&apos;, self.desired_caps) self.elementid = GetElement() def test_login(self): settings = os.path.abspath(&apos;..&apos;) + &quot;/cashier_conf/cashier_setting.ini&quot; cf = configparser.ConfigParser() cf.read(settings) cf.sections() # 定位门店编号输入框 storeno = self.elementid.get_elementId(self.driver, &apos;login&apos;, &apos;storeNo&apos;) storeno.click() storeno.clear() store_no = cf.get(&apos;login&apos;, &apos;login_store&apos;) storeno.send_keys(store_no) self.driver.hide_keyboard() # 定位用户名 username = self.elementid.get_elementId(self.driver, &apos;login&apos;, &apos;username&apos;) username.click() username.clear() user = cf.get(&apos;login&apos;, &apos;login_user&apos;) username.send_keys(user) self.driver.hide_keyboard() # 定位密码 pwd = self.elementid.get_elementId(self.driver, &apos;login&apos;, &apos;pwd&apos;) pwd.click() pwd.clear() password = cf.get(&apos;login&apos;, &apos;login_pwd&apos;) pwd.send_keys(password) self.driver.hide_keyboard() # 登录 self.elementid.get_elementId(self.driver, &apos;login&apos;, &apos;login&apos;).click() try: # 显示等待，门店名称出现 WebDriverWait(self.driver, 10).until(lambda x:x.find_element_by_id(cf.get(&apos;order&apos;, &apos;store_name&apos;))) # 断言登录成功 assert_true(u&quot;点餐&quot; in self.driver.page_source) except NoSuchElementException as e: print(traceback.print_exc(), e) except TimeoutException as e: print(traceback.print_exc(), e)if __name__ == &apos;__main__&apos;: mail_subject = &apos;NoseTests_测试报告_&#123;0&#125;&apos;.format(dt.now().strftime(&apos;%Y%m%d&apos;)) report_file = &apos;Login.html&apos; mailsend = MailSend(mail_subject, report_file) print(&apos;开始执行自动化测试...&apos;) os.system(&apos;nosetests -v &#123;0&#125; --with-html --html-file=&#123;1&#125;&apos;.format(__file__, report_file)) # 发送测试报告邮件 print(&apos;开始发送测试报告...&apos;) mailsend.send_mail() print(&apos;测试报告发送成功&apos;) 单独的邮件发送模块可参照之前一篇：python实现自动化测试报告邮件实时发送]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
        <tag>python3</tag>
        <tag>数据分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】python元类介绍]]></title>
    <url>%2F2018%2F01%2F31%2F%E3%80%90%E8%BD%AC%E3%80%91python%E5%85%83%E7%B1%BB%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[python元类 转自stackoverflow 神级人物e-satis的神级回复，以及国内翻译组汉化结果： 写在前面：经常在stackoverflow上看见一些神一般的回答，也看到过很多次创建Foo类，特意上维基百科搜了，解释如下：123foobar是计算机程序领域里的术语炒作，并无实际用途和参考意义。 在计算机程序设计与计算机技术的相关文档中，术语foobar是一个常见的无名氏化名，常被作为“伪变量”使用。单词“foobar”或分离的“foo”与“bar”常出现于程序设计的案例中，如同Hello World程序一样，它们常被用于向学习者介绍某种程序语言。“foo”常被作为函数／方法的名称，而“bar”则常被用作变量名。 正题类也是对象（Classes as objects）在理解元类之前，需要先掌握Python中的类。Python中类的概念借鉴于Smalltalk，这显得有些奇特。在大多数编程语言中，类就是一组用来描述如何生成一个对象的代码段。在Python中这一点仍然成立：123456class ObjectCreator(object): passmy_object = ObjectCreator()print(my_object)&lt;__main__.ObjectCreator object at 0x000001899B36E550&gt; 但是python中的类远不止如此。类同样也是一种对象 这个对象（类）自身用创建对象（类实例）的能力，而这就是为什么它是一个类的原因。但是，它本质上仍然是一个对象，所以，你可以对它进行如下操作：1、将它赋值给一个变量2、拷贝它3、为它增加属性4、将它作为函数参数进行传递 示例：12345678910111213141516171819202122class ObjectCreator(object): pass# 打印一个类，因为它其实也是一个对象print(ObjectCreator)&lt;class &apos;__main__.ObjectCreator&apos;&gt;# 将类作为参数传给函数def echo(o): print(o)echo(ObjectCreator)&lt;class &apos;__main__.ObjectCreator&apos;&gt;# 为类增加属性print(hasattr(ObjectCreator, &apos;new_attribute&apos;))ObjectCreator.new_attribute = &apos;foo&apos;print(hasattr(ObjectCreator, &apos;new_attribute&apos;))print(ObjectCreator.new_attribute)FalseTruefoo# 将类赋值给一个变量ObjectCreatorMirror = ObjectCreatorprint(ObjectCreatorMirror())&lt;__main__.ObjectCreator object at 0x000002C21DF1E550&gt; 动态地创建类因为类也是对象，你可以在运行时动态地创建它们，就想其他任何时候一样。首先，你可以在函数中创建类，使用class关键字即可。1234567891011121314def choose_class(name): if name == &apos;foo&apos;: class Foo(object): pass return Foo else: class Bar(object): pass return BarMyClass = choose_class(&apos;foo&apos;)print(MyClass)print(MyClass())&lt;class &apos;__main__.choose_class.&lt;locals&gt;.Foo&apos;&gt;&lt;__main__.choose_class.&lt;locals&gt;.Foo object at 0x000002B57928B518&gt; 但这还不够动态，因为你仍然需要自己编写整个类的代码。由于类也是对象，所以它们必须是用过什么东西来生成的才对。当你使用class关键字时，Python解释器自动创建这个对象，但就和python中的大多数事情一样，python仍然提供给你手动处理的方法。內建函数type，可以让你知道一个对象的类型是什么：12345678print(type(1))print(type(&quot;1&quot;))print(type(ObjectCreator))print(type(ObjectCreator()))&lt;class &apos;int&apos;&gt;&lt;class &apos;str&apos;&gt;&lt;class &apos;type&apos;&gt;&lt;class &apos;__main__.ObjectCreator&apos;&gt; 这里，type有一种完全不同的能力，它也能动态的创建类。type可以接受一个类的描述作为参数，然后返回一个类（同一个函数拥有两种完全不同的用法是一件很傻的事情，但这在Python中是为了保持向后的兼容性） type可以像这样工作：1type(类名, 父类的元组（针对继承的情况，可以为空），包含属性的字典（名称知道）) 比如如下的代码：12class MyShinyClass(object): pass 可以手动像这样创建：123456# 返回一个对象MyShinyClass = type(&apos;MyShinyClASS&apos;, (), &#123;&#125;)print(MyShinyClass)print(MyShinyClass())&lt;class &apos;__main__.MyShinyClASS&apos;&gt;&lt;__main__.MyShinyClASS object at 0x00000214ED6FE5F8&gt; type接受一个字典来为类定义属性，因此12class Foo(object): bar = True 可以翻译为：1Foo = type(&apos;Foo&apos;, (), &#123;&apos;bar&apos;:True&#125;) 并且可以将Foo当做一个普通的类一样使用：123456789print(Foo)print(Foo.bar)f = Foo()print(f)print(f.bar)&lt;class &apos;__main__.Foo&apos;&gt;True&lt;__main__.Foo object at 0x000002C77F0FD4E0&gt;True 当然，你可以向这个类继承，所以，如下的代码：12class FooChild(Foo): pass 就可以写成：123FooChild = type(&apos;FooChild&apos;, (Foo,), &#123;&#125;)print(FooChild)print(FooChild.bar) 到底什么是元类元类就是用来创建类的“东西”，你创建类就是为了创建类的实例对象，但是我们知道python中的类也是对象，而元类就是用来创建这些类（对象）的，所以，元类就是类的类，可以这样理解：12MyClass = MetaClass()MyObject = MyClass() 你可以看到了type可以让你像这样做：1MyClass = type(&apos;MyClass&apos;, (), &#123;&#125;) 这是因为函数type实际上是一个元类，type就是python背后用来创建所有类的元类，所以type为什么不写成Type也就知道了吧，或许就是为了和str保持一致性，str是用来创建字符串对象的类，而int是用来创建整数对象的类。type即使创建类对象的类。你可以通过class属性来看到这一点。Python中的所有的东西，注意，所有的东西——都是对象。这包含整数、字符串、函数和类。它们都是对象，而且它们都是从一个类创建来的。 12345678910age = 24print(age.__class__)name = &apos;bob&apos;print(name.__class__)def foo(): passprint(foo.__class__)&lt;class &apos;int&apos;&gt;&lt;class &apos;str&apos;&gt;&lt;class &apos;function&apos;&gt; 现在，对于任何一个class的class属性又是什么呢？123456print(age.__class__.__class__)print(name.__class__.__class__)print(foo.__class__.__class__)&lt;class &apos;type&apos;&gt;&lt;class &apos;type&apos;&gt;&lt;class &apos;type&apos;&gt; 因此，元类就是窗累类这种对象的东西，如果你喜欢的话，可以把元类称谓”类工厂”（不是工厂类）,type就是python內建的元类，当然了，你也可以创建自己的元类。 __metaclass__属性你可以在写一个类的时候为其添加metaclass属性。 123class Foo(object): __metaclass__ = somethind,.,[...] 如果你这么做了，python就会用元类来创建类Foo。这里面有技巧，你首先写下class Foo(object)，但是类对象Foo还没有在内存中创建。Python会在类的定义中寻找__metaclass__属性，如果找到了，Python就会用它创建类Foo，如果没找到，就会用內建的type来创建这个类。 当你写下如下代码时：12class Foo(Bar): pass Python做了如下的操作： Foo中有__metaclass__这个属性吗？如果有，python会在内存中通过__metaclass__创建一个名字为Foo的类对象（注意是类对象）。如果python没有找到__metaclass__，它会继续在Bar（父类）中寻找__metaclass__属性，并尝试做和前面同样的操作。如果python在任何父类中都找不到__metaclass__，它就会在模块层面中去寻找__metaclass__，并尝试做同样的操作。如果还是找不到__metaclass__，python就会用内置的type来创建这个类对象。 现在的问题就是，你可以在__metaclass__中放置些什么代码呢？答案是：可以是可以创建一个类的东西。那什么可以用来创建一个类呢？type，或者任何使用到type或者子类化type的东西都可以。 自定义元类元类的主要目的就是为了当创建类时能够自动地改变类。通常，你会为API做这样的事情，你希望可以创建符合当前上下文的类。假想一个很傻的例子，你决定你的模块里所有的类的属性都应该是大写形式，有好几种方法可以实现，单其中一种就是通过在模块级别设定__metaclass__，采用这种方法，这个模块中的所有类都会通过这个元类来创建，我们只需要告诉元类把所有的属性都改写成大写形式就解决了。 幸运的是，__metaclass__实际上可以被任意调用，它并不需要是一个正式的类（我们都知道，名字里面带’class’的东西，并不一定是个class） 我们这里先以一个简单的函数作为例子开始：12345678910111213141516171819202122232425# 元类会自动将你通常传给&apos;type&apos;的参数作为自己的参数传入def upper_attr(future_class_name, future_class_parents, future_class_attr): &quot;&quot;&quot; 返回一个类对象，将属性都转为大写形式 &quot;&quot;&quot; # 识别所有不以&apos;__&apos;开头的属性，将它转换为大写 uppercase_attr = &#123;&#125; for name, val in future_class_attr.items(): if not name.startswith(&apos;__&apos;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val # type创建这个类 return type(future_class_name, future_class_parents, uppercase_attr)# 这行会影响模块中的所有类__metaclass__ = upper_attrclass Foo(): # 全局 __metaclass__不会和&apos;object&apos;一起生效，但是我们可以在这里定义__metaclass__来只对这个类生效 bar = &apos;bip&apos;print(hasattr(Foo, &apos;bar&apos;))print(hasattr(Foo, &apos;BAR&apos;)) 现在让我们再做一次，这一次用一个真正的class来当元类123456789101112131415161718192021# 请记住，&apos;type&apos;实际上是一个类，就像&apos;str&apos;和&apos;int&apos;一样# 所以，你可以从type继承class UpperAttrMetaclass(type): # __new__ 是在 __init__之前被调用的特殊方法 # __new__是用来创建对象并返回的方法 # __init__只是用来把传入的参数初始化给对象 # 你很少用到__new__，除非你希望能够控制对象的创建 # 这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__ # 如果你希望的话，你也可以在__init__中做些事情 # 还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用 def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): uppercase_attr = &#123;&#125; for name, val in future_class_attr.items(): if not name.startswith(&apos;__&apos;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val return type(future_class_name, future_class_parents, uppercase_at 但是这不是OOP（Object-oriented programming，面向对象编程）。我们直接调用了type，而且我们没有改写父类的new方法。现在，我们这样去处理：12345678910111213141516class UpperAttrMetaclass(type): def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): uppercase_attr = &#123;&#125; for name, val in future_class_attr.items(): if not name.startswith(&apos;__&apos;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val # 复用type.__new__方法 # 这就是基本的OOP编程，没什么魔法 return type.__new__(upperattr_metaclass, future_class_name, future_class_parents, uppercase_attr) 你可以已经注意到了有个额外的参数uppersttr_metaclass，这并没有什么特别的。类方法的第一个参数总是表示当前的实例，就想在普通的类方法中的self参数一样。当然了，为了清晰起见，这边将名字起的比较长。但是就想self一样，所有的参数都有它们的传统名称。因此，在真是的产品代码中一个元类应该像这样：123456789101112class UpperAttrMetaclass(type): def __new__(cls, clsname, bases, dct): uppercase_attr = &#123;&#125; for name, val in dct.items(): if not name.startswith(&apos;__&apos;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val return type.__new__(cls, clsname, bases, uppercase_attr) 如果使用super方法的话，我们还可以使它变得更清晰一些，这会缓解继承（是的，你可以拥有元类，从元类继承，从type继承）123456789101112class UpperAttrMetaclass(type): def __new__(cls, clsname, bases, dct): uppercase_attr = &#123;&#125; for name, val in dct.items(): if not name.startswith(&apos;__&apos;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val return super(UpperAttrMetaclass, cls).__new__(cls, clsname, bases, uppercase_attr) 就是这样，除此之外，关于元类真的没有别的可说的了。使用到元类的代码比较复杂，这背后的原因倒不是因为元类本身，二十因为你通常会使用元类去做一些晦涩的事情，依赖于自省，控制继承等等。确实，用元类来搞些“黑魔法”是特别有用的，因而会搞出些复杂的东西来。但是元类本身而言，它们其实是很简单的： 1，拦截类的创建2，修改类3，返回修改之后的类 为什么要用metaclass类而不是函数由于__metaclass__可以接受任何可调用的对象，那为什么还要使用类呢，因为很显然使用类会更加复杂，这里有好几个原因： 1，意图会更加清晰，当你读到UpperAttrMetaclass(type)时，你知道接下来要发生什么2，你可以使用OOP编程。元类可以从元类中继承，改写父类方法，甚至可以使用元类3，你可以把代码组织的更好，当你使用元类的时候肯定不会像上述的简单场景，通常都是针对比较复杂的问题。将多个方法归总到一个类中会很有帮助，也会使得代码更容易阅读。4，你可以使用__new__，__init__以及__call__这样的特殊方法。它们能帮你处理不同的任务。就算通常你可以把所有的东西都在__new__里处理掉，有些人还是觉得用__init__更舒服点。 究竟为什么要使用元类现在回到我们的大主题上来，究竟是为什么你会去使用这样一种容易出错且晦涩的特性？好吧，一般来说，根本用不上它： “元类就是深度的魔法，99%的用户根本不必为此操心。如果你想搞清楚究竟是否需要用来元类，那么你就不需要它。那么实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类” ——Python界的领袖Tim Peters 元类的主要用途是创建API，一个典型的例子是Django ORM。它允许你像这样定义：123class Person(models.Model): name = models.CharField(max_length=30) age = models.IntegerField() 但是如果你像这样做的话：12guy = Person(name=&apos;bob&apos;, age=&apos;35&apos;)print guy.age 这并不会返回一个IntegerFied对象，而是会放回一个int，甚至可以直接从数据库中取出数据。这是有可能的，因为models.Model定义了__metaclass__，并且使用了一些魔法能够将你刚刚定义的简单的Person类转变成对数据库的一个复杂hook。Django框架将这些看起来很复杂的东西通过暴露出一个简单的使用元类的API将其化简，通过这个API重新创建代码，在背后完成真正的工作。 结语首先，你知道了类其实是能够创建出类实例的对象。事实上，类本身也是实例，当然，它们是元类的实例：1234class Foo(object): passprint(id(Foo))1973075749880 Python中的一切都是对象，它们要么是类的实例，要么是元类的实例，除了type。type实际上是它自己的元类，在纯python环境中这可不是你能够做到的，这是通过在实现层面耍一些小手段做到的。其次，元类是很复杂的。对于非常简单的类，你可能不希望通过使用元类来对类做修改。你可以通过其他两种技术来修改类：12Monkey patchingclass decorators 当你需要动态修改类时，99%的时间里你最好使用上面这两种技术。当然，其实在99%的时间里你根本就不需要动态修改类。 原链接 stackoverflow原链接国内翻译站]]></content>
      <categories>
        <category>python黑科技</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VPS重建记]]></title>
    <url>%2F2018%2F01%2F24%2FVPS%E9%87%8D%E5%BB%BA%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[VPS重新部署日常环境，及hexo博客快速重建 VPS受灾记大早上来发现stackoverflow首页都打不开，对于天天科学上网的我来说，简直莫名其妙。 本地网络原因本地windows PC机，控制台ping IP：1ping VPS_IP 直接就超时了，匪夷所思。。VPS服务器 ping自己：1ping 127.0.0.1 好歹能通，那就是中间路由断了。 手机下载个网络工具，尝试在手机端ping VPS的IP（排除公司DNS搞的鬼），手机上ping也直接超时了，好吧，可以去检查是不是在某个不知名的时候自己把防火墙开了，还把22等端口关了。。 VPS排查我的VPS是在LA的CENTOS7主机，centos7查看防火墙状态：1firewall-cmd --state 发现是关着的。。。为了排除自己之前装过iptables的服务，查看iptables.service：1systemctl status iptables.service 这个果然是开着的，查看启用的端口：1cat /etc/sysconfig/iptables 该开的端口也都开了，好吧，无语了。 大环境排查基于大家都懂的网络环境，怀疑是IP被墙了，检测：1http://ping.chinaz.com 果然，除了香港和国外，其他都ping不通VPS，好吧，可以下结论了:IP被墙了… 真的很想骂人啊！到底是哪个JR没事瞎玩，搞出个异常流量，害的无辜躺枪！！！hexo还在VPS上，小飞机也在VPS上，没有梯子，科学上网个鬼啊！！！ 骂人几轮，该弄得还是得弄，方案嘛，无非就是换IP，还好Vultr重建台服务还是很方便的。 VPS重建Vultr重买服务器，这次比较幸运，居然有$2.5的，直接买：Vultr官网拿到IP之后，第一件事，肯定是ping IP，还好，可以ping通，就是你了！ VPS简单设置 防火墙设置xshell远程连接上VPS之后，习惯性操作，第一步，更新yum1yum update firewall设置由于centos7默认的防火墙服务时firewalld的，很不习惯，改！ 查看防火墙状态1firewall-cmd --state 关闭防火墙1systemctl stop firewalld.service 禁止开机启动启动防火墙1systemctl disable firewalld.service iptables设置安装iptables服务：1yum install iptables-services 开启iptables防火墙:1systemctl start iptables.service 开启特定端口：编辑文件：/etc/sysconfig/iptables，加入想要开放的端口即可，例如开放8090端口：1-A INPUT -p tcp -m tcp --dport 8090 -j ACCEPT 保存，退出之后，重启防火墙完成设置:1systemctl restart iptables.service ShadowsocksR（小飞机）配置科学上网必不可少的工具，ShadowsocksR 安装：123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.shchmod +x shadowsocksR.sh./shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log 完成配置：12345服务器端口：自己设定（如不设定，默认为 8989）密码：自己设定（如不设定，默认为 teddysun.com）加密方式：自己设定（如不设定，默认为 aes-256-cfb）协议（Protocol）：自己设定（如不设定，默认为 origin）混淆（obfs）：自己设定（如不设定，默认为 plain） 附上我的配置，仅供参考：123456Your Server IP : ***.***.***.*** Your Server Port : ***** Your Password : ******* Your Protocol : auth_sha1_v4 Your obfs : tls1.2_ticket_auth Your Encryption Method: aes-256-cfb 配置完成之后就可以在本地PC机使用客户端进行梯子配置，完了就可以科学上网啦！！！客户端度娘盘链接 Hexo重建预备动作：原来VPS上面的hexo所在目录，直接打成压缩包scp出来 安装node.js首先安装gcc用于编译：1yum -y install gcc gcc-c++ kernel-devel 开始安装node.js12wget https://nodejs.org/dist/v4.5.0/node-v4.5.0.tar.gztar -xf node-v4.5.0.tar.gz 解压缩之后，进入目录，编译：1234cd node-v4.5.0./configuremakemake install 完成！验证：12node -vnpm 安装完成的是4.5的版本，升级：12npm install -g nn stable 安装git由于买的VPS已经集成了git，所以怎么安装，怎么配置环境变量啥的就不废话了。1、VPS设置git：12git config --global user.email &quot;you@example.com&quot;git config --global user.name &quot;Your Name&quot; 邮箱和用户名都对应于github 2、生成ssh秘钥1ssh-keygen -t rsa -C example@163.com 默认保存路径是/root/.ssh下：1cat /root/.ssh/id_rsa.pub 获取秘钥，然后到github的web页面将秘钥配置进去，完成！ 安装hexo1、安装hexo创建目录1mkdir blog 安装1234cd blognpm install -g hexo-cli#初始化hexo init 2、安装插件12345678910111213npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked --savenpm install hexo-renderer-stylus --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --save 3、修改Hexo配置文件，完成！ 或者，直接把原来VPS上面hexo的压缩包解压，再配置安装hexo即可1npm install hexo --save 环境测试12hexo new &quot;安装测试&quot;hexo g -d 执行不报错，进入博客可以看见安装测试该文章，部署成功！ 真的是坑啊，又重布环境，国内的网络环境啊，ε=(´ο｀*)))唉~ 参考链接 centos搭建hexo博客]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python实现自动化测试报告邮件实时发送]]></title>
    <url>%2F2018%2F01%2F23%2Fpython%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A%E9%82%AE%E4%BB%B6%E5%AE%9E%E6%97%B6%E5%8F%91%E9%80%81%2F</url>
    <content type="text"><![CDATA[实现自动化用例执行完成之后，自动发送带html附件的邮件到邮箱 实现思路：读取html附件内容，添加到邮件正文中，添加html附件，实现用例执行完成，测试报告自动发送到邮箱。代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#!/usr/bin/env python3# -*- coding: utf-8 -*-import osimport smtplibfrom datetime import datetime as dtfrom email.mime.text import MIMETextfrom email.mime.multipart import MIMEMultipartfrom nose.tools import assert_equaldef send_mail(): &quot;&quot;&quot;读取测试报告&quot;&quot;&quot; with open(report_file, &apos;r&apos;, encoding=&apos;utf-8&apos;) as f_obj: content = f_obj.read() msg = MIMEMultipart(&apos;mixed&apos;) # 添加邮件内容 msg_html = MIMEText(content, &apos;html&apos;, &apos;utf-8&apos;) msg.attach(msg_html) #添加附件 msg_attachment = MIMEText(content, &apos;html&apos;, &apos;utf-8&apos;) msg_attachment[&quot;Content-Disposition&quot;] = &apos;attachment; filename=&quot;&#123;0&#125;&quot;&apos;.format(report_file) msg.attach(msg_attachment) msg[&apos;Subject&apos;] = mail_subject msg[&apos;Form&apos;] = mail_user msg[&apos;To&apos;] = mail_to try: # 连接邮件服务器 s = smtplib.SMTP() s.connect(mail_host) # 登录 s.login(mail_user, mail_pwd) # 发送邮件 s.sendmail(mail_user, mail_to, msg.as_string()) # 退出 s.quit() except Exception as e: print(&quot;Exception&quot;, e)class Mailsend(): def test_mul(self): a = 1 b = 2 res = 3 assert_equal(res, a+b)if __name__ == &apos;__main__&apos;: # 邮件服务器 mail_host = &apos;smtp.163.com&apos; # 发件人地址 mail_user = &apos;***&apos; # 发件人密码 mail_pwd = &apos;***&apos; # 邮件标题 mail_subject = u&apos;NoseTests_测试报告_&#123;0&#125;&apos;.format(dt.now().strftime(&apos;%Y%m%d&apos;)) # 收件人地址 mail_to = &apos;***&apos; # 测试报告名称 report_file = &apos;NoseTestReport.html&apos; # 运行nosetests进行自动化测试并生成测试报告 print(&apos;Run NoseTests Now...&apos;) os.system(&apos;nosetests -v mail_html.py:Mailsend --with-html --html-file=NoseTestReport.html&apos;) # 发送测试报告邮件 print(&apos;Send Test Report Mail Now...&apos;) send_mail() tips:123python客户端进行163,126邮箱邮件发送前，需要在web版邮箱中设置允许客户端访问，设置客户端授权码设置完授权码之后，此时的客户端登录密码为授权码，不是原来的邮箱密码]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>自动化测试</tag>
        <tag>smtplib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据分离]]></title>
    <url>%2F2018%2F01%2F20%2Fpython%E6%95%B0%E6%8D%AE%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[python数据分离——读取配置文件 版本：python 3.6 进行数据/配置和代码分离时，python3.6 可以使用configparser进行配置信息读取或创建。可以实现程序和数据的分离，便于后期维护程序，也能在一定程序上满足不会编码的人进行自动化测试（只需改配置文件。） 以创建/读取ini格式配置文件为例： 创建配置文件：每个ini文件都是有n个sections组成（可以理解为组成部分或者是段落。。我是这么理解的），每个sections包含若干个键值对（keys:values），所以某种程度上，你可以把每个section看成是个字典（dictionary），虽然这俩意义上完全无关。python3.6创建ini配置文件代码示例：1234567891011121314151617181920212223#!/usr/bin/env python3# -*- coding: utf-8 -*-import configparsercf = configparser.ConfigParser()cf[&apos;DEFAULT&apos;] = &#123;&quot;browser&quot; : &quot;Chrome&quot;, &quot;version&quot; : &quot;63.0.3239.132&quot;, &quot;driver&quot; : &quot;chromedriver.exe&quot;, &#125;cf[&apos;tokyle.com&apos;] = &#123;&#125;cf[&apos;tokyle.com&apos;][&apos;Author&apos;] = &apos;kyle&apos;cf[&apos;baidu.com&apos;] = &#123;&#125;baiduSearch = cf[&apos;baidu.com&apos;]baiduSearch[&apos;searchBox&apos;] = &apos;id &gt; kw&apos;baiduSearch[&apos;searchButton&apos;] = &apos;id &gt; su&apos;cf[&apos;DEFAULT&apos;][&apos;noRetry&apos;] = &apos;yes&apos;with open(&apos;test.ini&apos;, &apos;w&apos;) as configfile: cf.write(configfile) 上述代码执行完成之后会在该.py文件所在目录下创建一个test.ini的配置文件，内容如下：123456789101112[DEFAULT]browser = Chromeversion = 63.0.3239.132driver = chromedriver.exenoretry = yes[tokyle.com]author = kyle[baidu.com]searchbox = id &gt; kwsearchbutton = id &gt; su 每个ini文件可以包含一个[&#39;DEFAULT&#39;] section，也可以没有，[&#39;DEFAULT&#39;]部分定义了默认设置，例如默认使用的浏览器，浏览器版本等。 读取配置信息1234import configparsercf = configparser.ConfigParser()cf.read(&apos;test.ini&apos;) 获取所有sections使用1cf.sections() 即可，需要注意的是，这样，是默认不会获取都[‘DEFAULT’]的，可以实验一下：12section = cf.sections()print(section) 打印出的结果：1[&apos;tokyle.com&apos;, &apos;baidu.com&apos;] 可以看见默认不包含[‘DEFAULT’]。 其实读取配置信息就和读取字典里的数据做法一样，使用for循环就可以打印出全部信息，例如进行自动化测试时想获取[‘baidu.com’]里存的百度搜索输入框以及百度一下按键，可以：123baidu_msg = cf[&apos;baidu.com&apos;]for key,value in baidu_msg.items(): print(key + &apos; : &apos; + value) 打印出的信息：123456searchbox : id &gt; kwsearchbutton : id &gt; subrowser : Chromeversion : 63.0.3239.132driver : chromedriver.exenoretry : yes 可以看见，这样不仅会把[‘baidu.com’]模块的信息全部打印，[‘DEFAULT’]模块的信息也会被打印出来。 使用配置文件实例(简单的数据分离)：123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python3# -*- coding: utf-8 -*-import configparserimport traceback,timefrom selenium import webdriverfrom selenium.webdriver.support.ui import WebDriverWaitfrom nose.tools import assert_trueclass ElementId(): def __init__(self): #读取配置文件 self.cf = configparser.ConfigParser() self.cf.read(&apos;test.ini&apos;) self.cf.sections() def get_elementId(self, driver, webSiteName, webelement): try: #获取配置文件中的定位方法以及定位元素 webElemnt = self.cf.get(webSiteName, webelement).split(&apos;&gt;&apos;) webelement_method = webElemnt[0].strip() webelement_expression = webElemnt[1].strip() element = WebDriverWait(driver, 10).until\ (lambda x: x.find_element(webelement_method, webelement_expression)) except Exception as e: print(traceback.print_exc(), e) else: return elementif __name__ == &apos;__main__&apos;: &quot;&quot;&quot;测试百度搜索&quot;&quot;&quot; #打开百度首页 browser = webdriver.Chrome() browser.get(&quot;https://www.baidu.com&quot;) #获取定位元素 elementid = ElementId() searchBox = elementid.get_elementId(browser, &apos;baidu.com&apos;, &apos;searchbox&apos;) searchBox.send_keys(&apos;selenium&apos;) searchButton = elementid.get_elementId(browser, &apos;baidu.com&apos;, &apos;searchbutton&apos;) searchButton.click() time.sleep(3) #断言完成百度搜索&quot;selenium&quot; assert_true(u&quot;Selenium - Web Browser Automation&quot; in browser.page_source) browser.quit() （我在执行上述示例之前，把test.ini中的[‘DEFAULT’]注释掉了，此例不需要[‘DEFAULT’]中的信息）]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自娱自乐一]]></title>
    <url>%2F2018%2F01%2F20%2F%E8%87%AA%E5%A8%B1%E8%87%AA%E4%B9%90%E4%B8%80%2F</url>
    <content type="text"><![CDATA[自娱自乐系列一： 为了过年提前回家，周六过来加班调休，又不大想干活，就想着捣鼓点自娱自乐的东西： 输入年龄判断是否有投票资格：1234567891011121314151617def judge_age(): while True: try: age = int(input(&quot;\nPlease enter your age：&quot;)) except ValueError: print(&quot;Sorry,I can&apos;t understand what you entered.Please enter a correct number.&quot;) continue else: break if age &gt;= 18: print(&quot;You are able to vote in the United States!&quot;) else: print(&quot;You are too young to vote in the United States!&quot;)if __name__ == &apos;__main__&apos;: judge_age() 判断输入的正整数:12345678910111213141516171819202122232425262728293031#!/usr/bin/env python3# -*- coding: utf-8 -*-def get_non_negative_int(prompt): try: value = int(input(prompt)) except ValueError: print(&quot;Sorry,I can&apos;t understand that.&quot;) return get_non_negative_int(prompt) if value &lt; 0: print(&quot;Sorry,your response must not be negative.&quot;) return get_non_negative_int(prompt) else: return valuedef guess_number(): number = get_non_negative_int(&quot;Please enter a number to guess: (only positive integer can work,thanks!)&quot;) while True: guess = get_non_negative_int(&quot;guess the number.&quot;) if guess &gt; number: print(&quot;You could enter a lower one.&quot;) elif guess &lt; number: print(&quot;I think it could be higher.&quot;) else: print(&quot;Congratulations! You got it!&quot;) breakif __name__ == &apos;__main__&apos;: guess_number() 纯属自娱自乐，毫无技术含量 Thanks?(?ω?)? 顺便贴个常识坑：文件夹不能取名是code，否则pycharm的debug模式会报错！！！（stackoverflow真是个好网站！什么坑都能找到填的办法。。）原因：debug模式会引个包：1from code import InteractiveConsole 工程中有code文件夹，会找不到debug需要的方法]]></content>
      <categories>
        <category>just for fun</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>lives</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[appium应用简介]]></title>
    <url>%2F2018%2F01%2F19%2Fappium%E5%BA%94%E7%94%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[appium应用篇，简单介绍自己工作中用到的一些appium应用。 Appium等待类型固定时间等待123import timetime.sleep(3) 固定等待时间3秒，强制等待，必须等完3秒之后才会进行下一步操作。 隐式等待1driver.implicitly_wait(5) 隐式等待的好处是不用想固定时间（time.sleep()）一样死等固定时间，可以在一定程度上提高执行效率，但是这种等待方式也是需要等页面所有元素都加载完成才会去进行下一步操作，例如有的时候，页面你需要的元素已经加载完成，但是必须还是要等待个别资源加载完才会执行下一步，一定程度上来说还是效率降低。 显示等待1234from selenium.webdriver.support.ui import WebDriverWaitWebDriverWait(driver, 10).\ until(lambda x:x.find_element_by_id(&apos;com.anmav.cashierdesk:id/tvOpenTable&apos;)) 显示等待原理是每隔一段时间（默认0.5秒），执行一次判断条件，如果条件成立，就执行下一步，直到超过设定的最大等待时间，抛出TimeoutException异常 Appium定位弹窗切换webview原理和selenium一样，类似于selenium中先获取页面句柄，再切换。1234driver.contexts方法一：driver.switch_to.context(&quot;contextname&quot;) #contextname为想切换到的上下文方法二：driver.switch_to.context(contexts[1]) # 从contexts里取第二个参数 Appium连接真机使用真机作为测试机，进行app自动化测试（android）步骤： adb连接真机首先是本地PC连接到真机，保证真机所在网段PC可以ping通（局域网或者同一WiFi）12&#123;lamb&#125; adb connect 192.168.0.194:9555connected to 192.168.0.194:9555 进入cmd，输入adb连接命名，连接到真机 起appium服务本地PC装有appium-desktop，直接启动appium-desktop，即完成appium服务启动 运行自动化测试脚本配置：12345678910self.desired_caps = &#123;&#125;self.desired_caps[&apos;platformName&apos;] = &apos;Android&apos;self.desired_caps[&apos;platformVersion&apos;] = &apos;6.0.1&apos;self.desired_caps[&apos;deviceName&apos;] = &apos;Android Emulator&apos;self.desired_caps[&apos;app&apos;] = &apos;‪G:/apk/1.2.5/test_release_v1.2.5.apk&apos;self.desired_caps[&apos;noReset&apos;] = Trueself.desired_caps[&apos;appPackage&apos;] = &apos;com.anmav.test&apos;self.desired_caps[&apos;appActivity&apos;] = &apos;com.anmav.test.login.activity.LoginActivity&apos;self.driver = webdriver.Remote(&apos;http://localhost:4723/wd/hub&apos;, self.desired_caps) 之后再加上用户名，密码等信息输入，即可完成远程真机app自动安装，登录。]]></content>
      <categories>
        <category>appium</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>自动化测试</tag>
        <tag>appium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python项目依赖管理工具-pipenv]]></title>
    <url>%2F2018%2F01%2F18%2Fpython%E9%A1%B9%E7%9B%AE%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7-pipenv%2F</url>
    <content type="text"><![CDATA[偶然发现一个很好用的python项目包管理工具pipenv github上简介是一句话Pipenv: Python Development Workflow for Humans 现在已经是python.org官方推荐的工具。 具体功能：pipenv能够自动创建和管理你工程的虚拟环境，当你安装/卸载包时，会自动从你的Pipfile中添加/移除包；为啥要用这个工具，python的特点，python进行工程环境创建，一般是创建一个Virtualenv虚拟环境，然后列出所需要的工具包，pip安装，但是这样你就要手动去添加你需要的包，删除你已经不需要的包，并且由于工具包的更新，你可能还需要手动去更新你的工具包，而且，类似于单元测试这样的场景，需要安装nose包，但是生产环境又不需要该包，也就无法做到生产环境和开发环境安装包的分离，而以上这些，pipenv都可以解决。 使用简介首先安装pipenv使用pip安装pipenv及其依赖项1pip install pipenv macOS安装则使用1brew install pipenv 进入你项目所在文件夹，启动Pipenv12cd your_projectpipenv install 启动之后，项目文件夹下会多出两个文件Pipfile，Pipfile.lockPipfile文件包含项目的依赖包信息。 管理依赖包要为项目安装依赖包，跟pip类似1pipenv install nose 卸载1pipenv uninstall nose 可以通过更新Pipfile.lock来冻结软件包名称及其版本以及其自己的依赖关系的列表。 这是使用lock关键字完成:1pipenv lock 如果你同事或者朋友想clone你的依赖库，直接拿你的Pipfile，然后他本地安装pipenv之后，pipenv install即可完成依赖库安装 环境分离只为开发环境安装包：1pipenv install --dev nose 这样，在生产环境执行pipenv install是不会安装nose的，想要安装开发环境的依赖，执行：1pipenv install --dev 用法pipenv所有关键字及解释：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950$ pipenvUsage: pipenv [OPTIONS] COMMAND [ARGS]...Options: --update Update Pipenv &amp; pip to latest. --where Output project home information. --venv Output virtualenv information. --py Output Python interpreter information. --envs Output Environment Variable options. --rm Remove the virtualenv. --bare Minimal output. --completion Output completion (to be eval&apos;d). --man Display manpage. --three / --two Use Python 3/2 when creating virtualenv. --python TEXT Specify which version of Python virtualenv should use. --site-packages Enable site-packages for the virtualenv. --jumbotron An easter egg, effectively. --version Show the version and exit. -h, --help Show this message and exit.Usage Examples: Create a new project using Python 3.6, specifically: $ pipenv --python 3.6 Install all dependencies for a project (including dev): $ pipenv install --dev Create a lockfile containing pre-releases: $ pipenv lock --pre Show a graph of your installed dependencies: $ pipenv graph Check your installed dependencies for security vulnerabilities: $ pipenv check Install a local setup.py into your virtual environment/Pipfile: $ pipenv install -e .Commands: check Checks for security vulnerabilities and... graph Displays currently–installed dependency graph... install Installs provided packages and adds them to... lock Generates Pipfile.lock. open View a given module in your editor. run Spawns a command installed into the... shell Spawns a shell within the virtualenv. uninstall Un-installs a provided package and removes it... update Uninstalls all packages, and re-installs... 定位工程展示工程路径以及环境路径，进入工程(类似于linux)：1pipenv --where 1pipenv --venv 定位python解释器：1pipenv --py 其他使用激活工程环境1pipenv shell 运行python脚本1pipenv run python main.py 展示依赖关系图1pipenv graph 卸载所有1pipenv uninstall --all 参考地址 github项目地址python.org官网推荐地址]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pipenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cmder简介]]></title>
    <url>%2F2018%2F01%2F18%2Fcmder%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[windows小工具介绍 windows系统cmd工具，说实话，用的还是有点不舒服的，用习惯vim之后，真的是很想在windows上用类似的，还好，找到个小工具cmder。 下载地址：照旧，官方下载地址是托管在github上 github下载地址 但是不知道最近抽什么疯，github上n多项目下载页面直接404，索性提供本地度娘盘地址： 度娘盘地址 使用说明下载完成之后，解压缩，然后将cmder.exe所在目录添加到系统环境变量中，完成~双击打开即可使用。 简单设置解决中文乱码问题：类似于linux，alias文件中添加设置即可；alias文件位置：cmder/config/aliases添加：123l=ls --show-control-charsla=ls -aF --show-control-charsll=ls -alF --show-control-chars 中文字重叠在一起cmder进入设置（快捷键win+alt+p），找到main，取消monospace(固定宽度)勾选 基本就是设置完成了，可以进行使用了，后续再发现什么其他的好功能再更新。123456789#切换盘D:#展示文件lsll#查看文件内容cat xxx.txt#编辑文件内容vim xxx.txt]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>cmder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[appium键盘事件]]></title>
    <url>%2F2018%2F01%2F17%2Fappium%E9%94%AE%E7%9B%98%E4%BA%8B%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[appium键盘事件 语法：1driver.keyevent(keyCode) 电话键1234567891011121314KEYCODE_CALL 拨号键 5KEYCODE_ENDCALL 挂机键 6KEYCODE_HOME 按键Home 3KEYCODE_MENU 菜单键 82KEYCODE_BACK 返回键 4KEYCODE_SEARCH 搜索键 84KEYCODE_CAMERA 拍照键 27KEYCODE_FOCUS 拍照对焦键 80KEYCODE_POWER 电源键 26KEYCODE_NOTIFICATION 通知键 83KEYCODE_MUTE 话筒静音键 91KEYCODE_VOLUME_MUTE 扬声器静音键 164KEYCODE_VOLUME_UP 音量增加键 24KEYCODE_VOLUME_DOWN 音量减小键 25 控制键123456789101112131415161718192021KEYCODE_ENTER 回车键 66KEYCODE_ESCAPE ESC键 111KEYCODE_DPAD_CENTER 导航键 确定键 23KEYCODE_DPAD_UP 导航键 向上 19KEYCODE_DPAD_DOWN 导航键 向下 20KEYCODE_DPAD_LEFT 导航键 向左 21KEYCODE_DPAD_RIGHT 导航键 向右 22KEYCODE_MOVE_HOME 光标移动到开始键 122KEYCODE_MOVE_END 光标移动到末尾键 123KEYCODE_PAGE_UP 向上翻页键 92KEYCODE_PAGE_DOWN 向下翻页键 93KEYCODE_DEL 退格键 67KEYCODE_FORWARD_DEL 删除键 112KEYCODE_INSERT 插入键 124KEYCODE_TAB Tab键 61KEYCODE_NUM_LOCK 小键盘锁 143KEYCODE_CAPS_LOCK 大写锁定键 115KEYCODE_BREAK Break/Pause键 121KEYCODE_SCROLL_LOCK 滚动锁定键 116KEYCODE_ZOOM_IN 放大键 168KEYCODE_ZOOM_OUT 缩小键 169 组合键123456KEYCODE_ALT_LEFT Alt+LeftKEYCODE_ALT_RIGHT Alt+RightKEYCODE_CTRL_LEFT Control+LeftKEYCODE_CTRL_RIGHT Control+RightKEYCODE_SHIFT_LEFT Shift+LeftKEYCODE_SHIFT_RIGHT Shift+Right 基本123456789101112131415161718192021222324252627282930313233343536KEYCODE_0 按键&apos;0&apos; 7KEYCODE_1 按键&apos;1&apos; 8KEYCODE_2 按键&apos;2&apos; 9KEYCODE_3 按键&apos;3&apos; 10KEYCODE_4 按键&apos;4&apos; 11KEYCODE_5 按键&apos;5&apos; 12KEYCODE_6 按键&apos;6&apos; 13KEYCODE_7 按键&apos;7&apos; 14KEYCODE_8 按键&apos;8&apos; 15KEYCODE_9 按键&apos;9&apos; 16KEYCODE_A 按键&apos;A&apos; 29KEYCODE_B 按键&apos;B&apos; 30KEYCODE_C 按键&apos;C&apos; 31KEYCODE_D 按键&apos;D&apos; 32KEYCODE_E 按键&apos;E&apos; 33KEYCODE_F 按键&apos;F&apos; 34KEYCODE_G 按键&apos;G&apos; 35KEYCODE_H 按键&apos;H&apos; 36KEYCODE_I 按键&apos;I&apos; 37KEYCODE_J 按键&apos;J&apos; 38KEYCODE_K 按键&apos;K&apos; 39KEYCODE_L 按键&apos;L&apos; 40KEYCODE_M 按键&apos;M&apos; 41KEYCODE_N 按键&apos;N&apos; 42KEYCODE_O 按键&apos;O&apos; 43KEYCODE_P 按键&apos;P&apos; 44KEYCODE_Q 按键&apos;Q&apos; 45KEYCODE_R 按键&apos;R&apos; 46KEYCODE_S 按键&apos;S&apos; 47KEYCODE_T 按键&apos;T&apos; 48KEYCODE_U 按键&apos;U&apos; 49KEYCODE_V 按键&apos;V&apos; 50KEYCODE_W 按键&apos;W&apos; 51KEYCODE_X 按键&apos;X&apos; 52KEYCODE_Y 按键&apos;Y&apos; 53KEYCODE_Z 按键&apos;Z&apos; 54]]></content>
      <categories>
        <category>appium</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[appium定位]]></title>
    <url>%2F2018%2F01%2F17%2Fappium%E5%AE%9A%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[appium的常用操作以及元素定位的简单介绍 appium常用操作锁屏1driver.lock(5) 切换应用至后台123driver.background_app(5) # 置于后台，持续5秒driver.background_app(-1) # 持续置于后台driver.background_app(&#123;&apos;timeout&apos;: None&#125;) # 持续置于后台 收起键盘1driver.hide_keyboard() 启动Activity1driver.start_activity(&apos;com.example.android.apis&apos;, &apos;.Foo&apos;) 检测应用是否被安装1driver.is_app_installed(&apos;com.example.android.apis&apos;) 安装应用1driver.install_app(&apos;path/to/my.apk&apos;) 卸载应用1driver.remove_app(&apos;com.example.android.apis&apos;) 模拟设备摇一摇1driver.shake() 关闭应用1driver.close_app() 启动应用使用前提是desired capabilities设置了 autoLaunch=false 关键字1driver.launch_app() 操作上下文（Contexts）获取所有1driver.contexts 获取当前1driver.current_context 切换至默认1driver.switch_to.context(None) 按键事件1driver.keyevent(176) 具体键值 点击操作/多点触控操作12action = TouchAction(driver)action.press(element=el, x=10, y=10).release().perform() 滑动屏幕1driver.swipe(start_x=75, start_y=500, end_x=75, end_y=0, duration=800) 从设备拉去文件1driver.pull_file(&apos;Library/AddressBook/AddressBook.sqlitedb&apos;) 推送文件到设备123data = &quot;some data for the file&quot;path = &quot;/data/local/tmp/file.txt&quot;driver.push_file(path, data.encode(&apos;base64&apos;)) appium元素定位使用id，class等和selenium基本没差别的定位就不介绍了，主要介绍appium独有uiautomator UiSelector 页面class和id等都不能唯一确定元素，但是元素有text属性时，可以使用以下进行定位：1234driver.find_element_by_android_uiautomator(&apos;new UiSelector().text(&quot;Custom View&quot;)&apos;).click() #textdriver.find_element_by_android_uiautomator(&apos;new UiSelector().textContains(&quot;View&quot;)&apos;).click() #textContainsdriver.find_element_by_android_uiautomator(&apos;new UiSelector().textStartsWith(&quot;Custom&quot;)&apos;).click() #textStartsWithdriver.find_element_by_android_uiautomator(&apos;new UiSelector().textMatches(&quot;^Custom.*&quot;)&apos;).click() #textMatches 也可以加上class属性：12driver.find_element_by_android_uiautomator(&apos;new UiSelector().className(&quot;android.widget.TextView&quot;).text(&quot;Custom View&quot;)&apos;).click() #classNamedriver.find_element_by_android_uiautomator(&apos;new UiSelector().classNameMatches(&quot;.*TextView$&quot;).text(&quot;Custom View&quot;)&apos;).click() #classNameMatches 多条件精准定位1driver.find_element_by_android_uiautomator(&apos;new UiSelector().className(&quot;android.widget.EditText&quot;).resourceId(&quot;com.anmav.cashierdesk:id/etToPayPrice&quot;)&apos;) 操作坐标appium在进行元素定位时，定位不到唯一标志的元素，可以获取元素的坐标，使用坐标进行操作 appium以及uiautomatorviewer都可以很容易获取到坐标 appium操作坐标 1driver.tap([(100, 20), (100, 60), (100, 100)], 500) 三个坐标表示模拟三根手指，只需要一个手指，改成一个坐标即可，500表示持续时间500ms 或者使用adb命令也可实现同样效果：1os.popen(&quot;adb shell input tap &quot; + str(100) + &quot; &quot; + str(20)) 参考文章 appium 基础之键盘处理appium-bindings]]></content>
      <categories>
        <category>appium</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>自动化测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[app安装卸载]]></title>
    <url>%2F2018%2F01%2F17%2Fapp%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[appium-模拟器安装卸载app 模拟器安装apk1adb install XXX.apk 卸载apk1adb uninstall your_package 例子： 启动android模拟器，参数：12345desired_caps[&apos;platformName&apos;] = &apos;Android&apos;desired_caps[&apos;platformVersion&apos;] = &apos;7.1.1&apos;desired_caps[&apos;deviceName&apos;] = &apos;Android Emulator&apos;desired_caps[&apos;appPackage&apos;] = &apos;com.anmav.cashierdesk&apos;desired_caps[&apos;appActivity&apos;] = &apos;com.anmav.cashierdesk.view.LoginActivity&apos; win10打开控制台，进入apk文件所在目录，执行命令1adb install cashierdesk.apk 在模拟器中可以发现该app已完成安装。 控制台执行命令：1adb uninstall com.anmav.cashierdesk 模拟器中可以看见该app完成卸载]]></content>
      <categories>
        <category>appium</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
        <tag>appium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[appium入门篇]]></title>
    <url>%2F2018%2F01%2F16%2Fappium%E5%85%A5%E9%97%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[appium环境搭建及简单使用 测试人员进行app自动化测试的可选框架之一—— appium 平台说明：12WIN10_64python 3.6 appium环境安装安装Android Studio网上之前的教程基本都是安装SDK或者ADT来进行安装，开始我也是这么装的，在最后创建完虚拟机，开启虚拟机时候报错了，报错信息只记得是建议安装Android Studio，索性也就换成了Android Studio。 Android Studio下载链接 如果下载的是不包含SDK的版本，还需要另外下载SDK。安装Android Studio很简单，和Pycharm一模一样，有使用Pycharm经验或者IntelliJ IDEA的应该很熟悉，安装完成之后，找到SDK Manager1File-Settings-Appearance&amp;Behavior &gt; System Settings &gt; Android SDK 如果本地有SDK，可以在此选择本地的SDK路径，该设置页也支持下载各种SDK Platforms。对应的SDK安装完成之后就可以进行创建虚拟机，找到AVD Manager按键，点击创建。 安装Android SDK（和安装Android Studio任选一种方式即可）官方下载地址 但是由于国内众所周知的某种原因，不能科学上网貌似无法保证可以下载~ 国内优质android工具网站 搜索android-sdk找到对应系统版本，进行下载。 配置android环境变量与配置JAVA环境变量类似，新增系统变量123456变量名：ANDROID_HOME 变量值：D:\android\android-sdk-windows变量名：PATH变量值：;%ANDROID_HOME%\platform-tools;%ANDROID_HOME%\tools; SDK Manager安装模拟器在你本地解压完成之后的android-sdk-windows目录下找到SDK Manager.exe，双击打开； 配置参考 安装SDK Platform-Tools在AndroidDevTools.cn 网站上找到Android SDK Platform-tools下载链接，下载，解压，把解压出来的 platform-tools 文件夹放在android-sdk-windows目录下 安装Appium安装方式一： 使用NodeJS 安装1，首先到官网下载安装最新的NodeJS，Windows下属于傻瓜安装。安装完成验证npm或者node -v不报错表明安装完成 2，安装appium，npm install -g appium命令安装appium（个人实验的效果不好，太慢了，建议采用第二种，安装包安装） 安装方式二：安装包安装建议直接安装appium-desktop，appium server在2015年就不再更新，取而代之的是appium-desktop的出现。 Appium安装包托管在github上，下载地址 但是个人实验，很多版本都是跳转404页面。。。无语。。。 个人网盘地址，密码：v3lt（版本1.2.7） 下载完成后，安装即可。 appium环境检查可以使用appium-doctor工具进行环境检查，npm install -g appium-doctor进行安装。 Appium-desktop使用简介打开appium-desktop，点击“放大镜”图标进行设置， 设置完成后点击 Start Session 直接单击最左栏的元素，在中间和右边会显示该元素属性，找到对应的ID值等，定位方式和selenium类似。 查找appPackage和appActivityappium进行自动化测试，需要appPackage和appActivity两个参数，下面是从apk文件获取的方法： apk反编译apktool 地址： apktool 用法1java -jar apktool.jar d yourApkFile.apk 获取appPackage和appActivity打开apk反编译之后的文件夹，打开AndroidManifest.xml文件 package获取 appPackage，activity获取appActivity。 appium Demo实现计算器计算，代码：1234567891011121314151617181920212223242526#!/usr/bin/env python3# -*- coding: utf-8 -*-from appium import webdriverimport timedesired_caps = &#123;&#125;desired_caps[&apos;platformName&apos;] = &apos;Android&apos;desired_caps[&apos;platformVersion&apos;] = &apos;7.1.1&apos;desired_caps[&apos;deviceName&apos;] = &apos;Android Emulator&apos;desired_caps[&apos;appPackage&apos;] = &apos;com.android.calculator2&apos;desired_caps[&apos;appActivity&apos;] = &apos;.Calculator&apos;desired_caps[&apos;noReset&apos;] = Truedriver = webdriver.Remote(&apos;http://localhost:4723/wd/hub&apos;, desired_caps)driver.find_element_by_id(&apos;com.android.calculator2:id/digit_4&apos;).click()driver.find_element_by_accessibility_id(&apos;multiply&apos;).click()driver.find_element_by_id(&apos;com.android.calculator2:id/digit_9&apos;).click()driver.find_element_by_accessibility_id(&apos;plus&apos;).click()driver.find_element_by_id(&apos;com.android.calculator2:id/digit_1&apos;).click()driver.find_element_by_id(&apos;com.android.calculator2:id/digit_4&apos;).click()driver.find_element_by_accessibility_id(&apos;equals&apos;).click()time.sleep(3)driver.quit()]]></content>
      <categories>
        <category>appium</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>自动化测试</tag>
        <tag>appium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[smtp发邮件]]></title>
    <url>%2F2018%2F01%2F12%2Fsmtp%E5%8F%91%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[使用python3发送网易邮箱邮件 代码：12345678910111213141516import smtplibfrom email.mime.text import MIMETextfrom email.header import Headerdef send_email(mail_host, from_account, from_passwd, to_account, subject, content): mail = smtplib.SMTP() mail.connect(mail_host) mail.login(from_account, from_passwd) # 发送邮件 message = MIMEText(content, &apos;plain&apos;, &apos;utf-8&apos;) message[&apos;From&apos;] = from_account message[&apos;To&apos;] = to_account message[&apos;Subject&apos;] = Header(subject, &apos;utf-8&apos;) mail.sendmail(from_account, to_account, message.as_string()) 菜鸟教程上有一种写法12345678910111213141516171819202122232425262728293031#!/usr/bin/python3 import smtplibfrom email.mime.text import MIMETextfrom email.header import Header # 第三方 SMTP 服务mail_host=&quot;smtp.XXX.com&quot; #设置服务器mail_user=&quot;XXXX&quot; #用户名mail_pass=&quot;XXXXXX&quot; #口令 sender = &apos;from@runoob.com&apos;receivers = [&apos;429240967@qq.com&apos;] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱 message = MIMEText(&apos;Python 邮件发送测试...&apos;, &apos;plain&apos;, &apos;utf-8&apos;)message[&apos;From&apos;] = Header(&quot;菜鸟教程&quot;, &apos;utf-8&apos;)message[&apos;To&apos;] = Header(&quot;测试&quot;, &apos;utf-8&apos;) subject = &apos;Python SMTP 邮件测试&apos;message[&apos;Subject&apos;] = Header(subject, &apos;utf-8&apos;) try: smtpObj = smtplib.SMTP() smtpObj.connect(mail_host, 25) # 25 为 SMTP 端口号 smtpObj.login(mail_user,mail_pass) smtpObj.sendmail(sender, receivers, message.as_string()) print (&quot;邮件发送成功&quot;)except smtplib.SMTPException: print (&quot;Error: 无法发送邮件&quot;) 这样执行，会报错smtplib.SMTPDataError: (554, &#39;DT:SPM 126 smtp5,jtKowAD3MJz2c1JXLcK2AA--.52114S2 1465021431,please see http://mail.163.com/help/help_spam_16.htm?ip=123.114.121.110&amp;hostid=smtp5&amp;time=1465021431&#39;) 解决办法就是指定收发件人12message[&apos;From&apos;] = from_accountmessage[&apos;To&apos;] = to_account p.s 网易邮箱客户端默认授权码是关闭的，直接执行python调用会失败，要先进客户端，把客户授权码打开位置：设置-客户端授权密码设置完成之后，登录密码就使用你设置的授权码]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>smtplib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[selenium无干预下载]]></title>
    <url>%2F2018%2F01%2F10%2Fselenium%E6%97%A0%E5%B9%B2%E9%A2%84%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[selenium自带了无人工干预实现下载功能的模块，下载时不需要弹窗点击确定下载 代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverimport timeclass MacDownload(): def __init__(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; # 创建一个FirefoxProfile实例，用于存放自定义配置 profile = webdriver.FirefoxProfile() # 指定下载路径，默认自动创建一级目录 profile.set_preference(&apos;browser.download.dir&apos;, &apos;G:\idownload&apos;) # 将browser.download.folderLis设置为2，表示将文件下载到指定目录（0表示桌面，1表示默认路径） profile.set_preference(&quot;browser.download.folderList&quot;, 2) # browser.helperApps.alwaysAsk.force对于未知的MIME类型文件会弹出窗口 # 让用户处理，默认值为True，设定为False表示不会记录打开未知MIME类型文件的方式 profile.set_preference(&quot;browser.helperApps.alwaysAsk.force&quot;, False) # 在开始下载时是否显示下载管理器 profile.set_preference(&quot;browser.download.manager.showWhenStarting&quot;, False) # 设定为False会把下载狂隐藏 profile.set_preference(&quot;browser.download.manager.useWindow&quot;, False) # 默认为True，设定为False表示不获取焦点 profile.set_preference(&quot;browser.download.manager.focusWhenStarting&quot;, False) # 下载.exe文件弹出警告，默认值为True，设定为False则不会弹出警告 profile.set_preference(&quot;browser.download.manager.alertOnEXEOpen&quot;, False) # browser.helperApps.neverAsk.openFile表示直接打开下载文件，不显示确定框 # 默认值为空字符串，下行代码行设定了多种文件的MIME类型， # 例如application/exe,表示 .exe类型的文件；application/excel表示excel类型的文件 profile.set_preference(&quot;browser.helperApps.neverAsk.openFile&quot;, &quot;application/pdf&quot;) # 对所给出文件类型不在弹出提示框进行询问，直接保存到本地磁盘 profile.set_preference(&quot;browser.helperApps.neverAsk.saveToDisk&quot;, &quot;application/zip, application/octet-stream&quot;) # browser.download.manager.showAlertOnComplete设定下载文件结束后是否显示下载完成提示框 # 默认为True，设定为False表示下载完成后不显示下载完成提示框 profile.set_preference(&quot;browser.download.manager.showAlertOnComplete&quot;, False) # browser.download.manager.closeWhenDone设定下载结束后是都自动关闭下载框 # 默认为True，设定为False表示不关闭下载管理器 profile.set_preference(&quot;browser.download.manager.closeWhenDone&quot;, False) # 启动浏览器，通过firfox_profile参数将自动配置添加到FirefoxProfile对象中sef.driver = webdriver.Firefox(firefox_profile=profile) self.driver = webdriver.Firefox(firefox_profile=profile) def test_dataPicker(self): #访问WebDriver驱动firefox的驱动文件下载网址 # url1 = &quot;https://github.com/mozilla/geckodriver/releases&quot; # self.driver.get(url1) # #选择下载ZIP类型的文件，使用application/zip指代此类型文件 # self.driver.find_element_by_xpath(&apos;//strong[. = &quot;geckodriver-v0.19.1-win32.zip&quot;]&apos;).click() # time.sleep(10) #访问Python2.7.12文件下载页面，下载扩展名为msi的文件 #使用application/octet - stream来指明次文件类型 url = &quot;https://www.python.org/downloads/release/python-2712/&quot; self.driver.get(url) self.driver.find_element_by_link_text(&apos;Windows x86-64 MSI installer&apos;).click() time.sleep(100) self.driver.quit()]]></content>
      <categories>
        <category>selenium</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12306余票监控]]></title>
    <url>%2F2018%2F01%2F10%2F12306%E4%BD%99%E7%A5%A8%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[翻日历突然意识到，好像要放假了，又是一年春运时，就想着可不可以用selenium做个自己的监控12306余票的程序。 动手：思路也就是输入起点，终点，选择列车，选择座位，查询是否有余票。 代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverfrom selenium.webdriver.common.keys import Keysimport timeclass monitorTickets(): &quot;&quot;&quot; 查询12306硬座，硬卧，软卧余票 &quot;&quot;&quot; def __init__(self): &quot;&quot;&quot;初始化&quot;&quot;&quot; #使用chrome浏览器打开查询12306查询页面 self.browser = webdriver.Chrome() url = &apos;https://kyfw.12306.cn/otn/leftTicket/init&apos; self.browser.get(url) def search_tickets(self,train_name, start_stations, end_stations, ticket_id): &quot;&quot;&quot;循环获取余票&quot;&quot;&quot; print(&quot;开始查询【%s】次列车余票信息&quot; % train_name) for start_station in start_stations: try: for end_station in end_stations: #输入起点 starts = self.browser.find_element_by_id(&quot;fromStationText&quot;) starts.click() starts.clear() starts.send_keys(start_station) starts.send_keys(Keys.ENTER) #输入到站 ends = self.browser.find_element_by_id(&quot;toStationText&quot;) ends.click() ends.clear() ends.send_keys(end_station) ends.send_keys(Keys.ENTER) #选择时间 #使用js将只读属性去除，完成选择时间 js = &apos;document.getElementById(&quot;train_date&quot;).removeAttribute(&quot;readonly&quot;);&apos; self.browser.execute_script(js) date = self.browser.find_element_by_id(&apos;train_date&apos;) date.clear() date.send_keys(&apos;2018-02-10&apos;) date.click() self.browser.find_element_by_id(&quot;query_ticket&quot;).click() time.sleep(2) text = self.browser.find_element_by_id(ticket_id).text if text == u&quot;无&quot;: print(u&quot;【%s】到【%s】的余票为0，节哀～&quot; % (start_station, end_station)) time.sleep(1) elif text == u&quot;*&quot;: print(u&quot;【%s】到【%s】的车票还未开售，请耐心等待～&quot; % (start_station, end_station)) time.sleep(1) else: print(u&quot;发现【%s】到【%s】的余票，抢!&quot; % (start_station, end_station)) except: continue print(&quot;结束查询【%s】次列车余票信息&quot; % train_name) def close_browser(self): &quot;&quot;&quot;关浏览器&quot;&quot;&quot; time.sleep(3) self.browser.quit()if __name__ == &apos;__main__&apos;: #查票 time.sleep(1) search_ticket = monitorTickets() while True: print(&quot;监控硬座&quot;) search_ticket.search_tickets(&apos;T116&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;陇西&apos;], &apos;YZ_550000T11671&apos;) search_ticket.search_tickets(&apos;Z216&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;甘谷&apos;], &apos;YZ_550000Z21605&apos;) search_ticket.search_tickets(&apos;T112&apos;, [&apos;嘉兴&apos;, &apos;昆山&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;陇西&apos;], &apos;YZ_560000T11251&apos;) search_ticket.search_tickets(&apos;T204&apos;, [&apos;上海&apos;, &apos;昆山&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;兰州&apos;], &apos;YZ_550000T20450&apos;) search_ticket.search_tickets(&apos;Z40&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;兰州&apos;], &apos;YZ_5500000Z4061&apos;) print(&quot;监控硬座结束&quot;) # print(&quot;监控硬卧&quot;) # search_ticket.search_tickets(&apos;T116&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;陇西&apos;], &apos;YW_550000T11671&apos;) # search_ticket.search_tickets(&apos;Z216&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;甘谷&apos;], &apos;YW_550000Z21605&apos;) # search_ticket.search_tickets(&apos;T112&apos;, [&apos;嘉兴&apos;, &apos;昆山&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;陇西&apos;], &apos;YW_560000T11251&apos;) # search_ticket.search_tickets(&apos;T204&apos;, [&apos;上海&apos;, &apos;昆山&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;兰州&apos;], &apos;YW_550000T20450&apos;) # search_ticket.search_tickets(&apos;Z40&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;兰州&apos;], &apos;YW_5500000Z4061&apos;) # print(&quot;监控硬卧结束&quot;) # # print(&quot;监控软卧&quot;) # search_ticket.search_tickets(&apos;T116&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;陇西&apos;], &apos;RW_550000T11671&apos;) # search_ticket.search_tickets(&apos;Z216&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;甘谷&apos;], &apos;RW_550000Z21605&apos;) # search_ticket.search_tickets(&apos;T112&apos;, [&apos;嘉兴&apos;, &apos;昆山&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;陇西&apos;], &apos;RW_560000T11251&apos;) # search_ticket.search_tickets(&apos;T204&apos;, [&apos;上海&apos;, &apos;昆山&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;兰州&apos;], &apos;RW_550000T20450&apos;) # search_ticket.search_tickets(&apos;Z40&apos;, [&apos;上海&apos;, &apos;苏州&apos;], [&apos;宝鸡&apos;, &apos;天水&apos;, &apos;兰州&apos;], &apos;RW_5500000Z4061&apos;) # print(&quot;监控软卧结束&quot;) # msg = input(&quot;Enter &apos;q&apos; to quit&quot;) # if msg == &apos;q&apos;: # break # search_ticket.close_browser()]]></content>
      <categories>
        <category>selenium</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[登录网易邮箱]]></title>
    <url>%2F2018%2F01%2F05%2F%E7%99%BB%E5%BD%95%E7%BD%91%E6%98%93%E9%82%AE%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[基于python3的自动化测试框架selenium3实践 登录网易邮箱（126,163） 登录163123456789101112131415161718192021222324252627282930#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverfrom selenium.webdriver.common.keys import Keysimport timebrowser = webdriver.Chrome()browser.get(&apos;http://mail.163.com/&apos;)browser.maximize_window()#切换进iframebrowser.implicitly_wait(5)browser.switch_to.frame(&apos;x-URS-iframe&apos;)time.sleep(1)#定位账号username = browser.find_element_by_name(&apos;email&apos;)username.clear()username.send_keys(&apos;***&apos;)time.sleep(1)#定位密码pwd = browser.find_element_by_name(&apos;password&apos;)pwd.clear()pwd.send_keys(&apos;***&apos;)#登录pwd.send_keys(Keys.ENTER)time.sleep(3)browser.quit() 或者123456789101112131415#coding:utf-8from selenium import webdriverfrom selenium.webdriver.common.keys import Keysimport timedriver = webdriver.Firefox()driver.get(&apos;http://mail.163.com/&apos;)driver.implicitly_wait(10)#切换iframeiframe = driver.find_elements_by_tag_name(&apos;iframe&apos;)driver.switch_to_frame(iframe)#driver.switch_to.frame(&apos;x-URS-iframe&apos;)driver.find_element_by_name(&apos;email&apos;).send_keys(&apos;123&apos;)driver.find_element_by_name(&apos;password&apos;).send_keys(&apos;456&apos;)brower.find_element_by_name(&quot;password&quot;).send_keys(Keys.ENTER) 登录12612345678910111213141516171819202122232425262728293031#!/usr/bin/env python3# -*- coding: utf-8 -*-import timefrom selenium import webdriverfrom selenium.webdriver.common.keys import Keysbrowser = webdriver.Chrome()browser.get(&apos;http://mail.126.com/&apos;)browser.maximize_window()# 切换iframebrowser.implicitly_wait(5)browser.switch_to.frame(&apos;x-URS-iframe&apos;)time.sleep(1)# 定位用户名username = browser.find_element_by_name(&apos;email&apos;)username.clear()username.send_keys(&apos;***&apos;)time.sleep(1)#定位密码pwd = browser.find_element_by_name(&apos;password&apos;)pwd.clear()pwd.send_keys(&apos;***&apos;)#登录pwd.send_keys(Keys.ENTER)time.sleep(3)browser.quit() ~记小白入坑selenium]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nose跳过测试]]></title>
    <url>%2F2018%2F01%2F04%2Fnose%E8%B7%B3%E8%BF%87%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[nose进行单元测试，和unittest一样，有跳过某个方法，指定特定类进行测试的功能。 识别规则使用nose进行单元测试，测试用例识别规则如下：12345nosetests only_test_this.pynosetests test.modulenosetests another.test:TestCase.test_methodnosetests a.test:TestCasenosetests /path/to/test/file.py:test.function 示例执行全部测试直接代码示例：12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/env python3# -*- coding: utf-8 -*-import tracebackfrom nose.tools import eq_from nose.plugins.attrib import attrfrom nose.plugins.skip import SkipTestfrom functools import reduceclass test_nosetests(): #测试加法 def test_sum(self): a = 1 b = 2 res = 3 eq_(a+b,res) #测试乘法 def test_mul(self): a = 1 b = 2 res = 2 eq_(a*b, res) #测试除法 def test_div(self): a = 2 b = 0 res = 1 try: eq_(a/b, res) except ZeroDivisionError as e: print(traceback.print_exc()) #测试reduce函数 def test_reduce(self): req = range(1,6) a = 120 res = reduce(lambda x, y: x*y, req) eq_(a, res) 想要对test_nosetests该方法进行测试，可以： 121. nosetests -v NoseTestsexercise.py --with-html --html-file=G:/workstation/report/test_nosetests.html2. nosetests -v NoseTestsexercise.py:test_nosetests --with-html --html-file=G:/workstation/report/test_nosetests.html 由于该python文件只有这一个测试类，所以直接nosetests该python文件即可以进行测试，或者是指定该python文件的测试类如NoseTestsexercise.py:test_nosetests方式 测试结果： 执行指定方法的测试执行指定的一个方法：1nosetests -v NoseTestsexercise.py:test_nosetests.test_reduce --with-html --html-file=G:/workstation/report/test_nosetests.html 示例执行了test_nosetests类下的test_reduce方法的测试 测试结果： 跳过指定方法的测试有的时候，只需要跳过某个方法：例如想跳过test_mul该方法，只需要在代码上增加跳过标志即可1234567#测试乘法 def test_mul(self): a = 1 b = 2 res = 2 eq_(a*b, res) raise SkipTest 执行：1nosetests -v NoseTestsexercise.py:test_nosetests --with-html --html-file=G:/workstation/report/test_nosetests.html 测试结果： 其他另外，nosetests也有用例执行优先级的功能1234from nose.plugins.attrib import attr @attr(speed=&apos;slow&apos;) def test_big_download(self): print(&apos;pass&apos;) 执行只需要：nosetests -a speed=slow即可 参考用法]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>nose</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python单元测试框架-nose]]></title>
    <url>%2F2018%2F01%2F03%2Fpython%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6-nose%2F</url>
    <content type="text"><![CDATA[python单元测试框架 nose简介 简介nose是python单元测试的另一框架，nose可以自动识别继承于unittest.TestCase的测试单元，并执行测试，而且，nose也可以测试非继承于unittest.TestCase的测试单元。nose提供了丰富的API便于编写测试代码。 安装及使用安装：1pip install nose 基本语法：1nosetests [options] [(optional) test files or directories] 扩展使用nose自动收集单元测试，收集它当前工作目录下的源代码文件、目录以及包。任何的源代码文件、目录或者包只要匹配正则表达式，他们就会被自动收集。包的测试收集按照树的层级级别一级一级进行，因此package.tests、package.sub.tests、package.sub.sub2.tests将会被收集。 扩展插件nose支持多种插件，可完成基本大部分测试需要。nose拥有很多内置的插件帮助进行输出抓取、错误查找、代码覆盖、文档测试（doctest）等等。 命令行执行命令可查看插件：1nosetests –plugins 若想查看详细信息，可执行12nosetests –plugins -vnosetests –plugins -vv nose使用nose使用和unittest类似，unittest的断言，nose.tools中都可以选择使用使用示例：unittest：123456789101112131415161718import unittestclass NoseTest(unittest.TestCase): def setUp(self): print(&quot;=============setUp===============&quot;) def test_Pass(self): print(&quot;==========begin test=========&quot;) a = 1 b = 2 self.assertTrue(a == b, &apos;断言失败, %a != %a&apos;% (a, b)) def tearDown(self): print(&quot;==============tearDown===============&quot;)if __name__ == &apos;__main__&apos;: unittest.main() nose:12345678from nose.tools import eq_from nose.tools import assert_equalclass noseTest(): a = 1 b = 2 #assert_equal(a, b, &apos;%a != %a&apos;%(a,b)) eq_(a, b) nose也支持在代码中直接运行nose.main()或者nose.run()这样类似于unittest的方式，但是还是建议在命令行中运行nosetests来执行单元测试参考示例：1nosetests -v HandleFrameByPageSource.py:test_handleFrameByPageSource --with-html --html-file=G:\workstation\report\handleframe.html 说明：1234nosetests -v: 显示详细的运行信息和调试信息HandleFrameByPageSource.py:test_handleFrameByPageSource ：测试对象为该python文件下的test_handleFrameByPageSource类--with-html ：使用html插件,生成标准HTML格式测试报告--html-file=G:\workstation\report\handleframe.html ：测试结果输出为该路径下handleframe.html文件]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>nose</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win32api_VK_CODE]]></title>
    <url>%2F2018%2F01%2F02%2Fwin32api-VK-CODE%2F</url>
    <content type="text"><![CDATA[python使用win32api模块，可模拟键盘按键，应用于爬虫及自动化测试。 键盘按键对应的Vitual keystroke如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535#Giant dictonary to hold key name and VK valueVK_CODE = &#123;&apos;backspace&apos;:0x08, &apos;tab&apos;:0x09, &apos;clear&apos;:0x0C, &apos;enter&apos;:0x0D, &apos;shift&apos;:0x10, &apos;ctrl&apos;:0x11, &apos;alt&apos;:0x12, &apos;pause&apos;:0x13, &apos;caps_lock&apos;:0x14, &apos;esc&apos;:0x1B, &apos;spacebar&apos;:0x20, &apos;page_up&apos;:0x21, &apos;page_down&apos;:0x22, &apos;end&apos;:0x23, &apos;home&apos;:0x24, &apos;left_arrow&apos;:0x25, &apos;up_arrow&apos;:0x26, &apos;right_arrow&apos;:0x27, &apos;down_arrow&apos;:0x28, &apos;select&apos;:0x29, &apos;print&apos;:0x2A, &apos;execute&apos;:0x2B, &apos;print_screen&apos;:0x2C, &apos;ins&apos;:0x2D, &apos;del&apos;:0x2E, &apos;help&apos;:0x2F, &apos;0&apos;:0x30, &apos;1&apos;:0x31, &apos;2&apos;:0x32, &apos;3&apos;:0x33, &apos;4&apos;:0x34, &apos;5&apos;:0x35, &apos;6&apos;:0x36, &apos;7&apos;:0x37, &apos;8&apos;:0x38, &apos;9&apos;:0x39, &apos;a&apos;:0x41, &apos;b&apos;:0x42, &apos;c&apos;:0x43, &apos;d&apos;:0x44, &apos;e&apos;:0x45, &apos;f&apos;:0x46, &apos;g&apos;:0x47, &apos;h&apos;:0x48, &apos;i&apos;:0x49, &apos;j&apos;:0x4A, &apos;k&apos;:0x4B, &apos;l&apos;:0x4C, &apos;m&apos;:0x4D, &apos;n&apos;:0x4E, &apos;o&apos;:0x4F, &apos;p&apos;:0x50, &apos;q&apos;:0x51, &apos;r&apos;:0x52, &apos;s&apos;:0x53, &apos;t&apos;:0x54, &apos;u&apos;:0x55, &apos;v&apos;:0x56, &apos;w&apos;:0x57, &apos;x&apos;:0x58, &apos;y&apos;:0x59, &apos;z&apos;:0x5A, &apos;numpad_0&apos;:0x60, &apos;numpad_1&apos;:0x61, &apos;numpad_2&apos;:0x62, &apos;numpad_3&apos;:0x63, &apos;numpad_4&apos;:0x64, &apos;numpad_5&apos;:0x65, &apos;numpad_6&apos;:0x66, &apos;numpad_7&apos;:0x67, &apos;numpad_8&apos;:0x68, &apos;numpad_9&apos;:0x69, &apos;multiply_key&apos;:0x6A, &apos;add_key&apos;:0x6B, &apos;separator_key&apos;:0x6C, &apos;subtract_key&apos;:0x6D, &apos;decimal_key&apos;:0x6E, &apos;divide_key&apos;:0x6F, &apos;F1&apos;:0x70, &apos;F2&apos;:0x71, &apos;F3&apos;:0x72, &apos;F4&apos;:0x73, &apos;F5&apos;:0x74, &apos;F6&apos;:0x75, &apos;F7&apos;:0x76, &apos;F8&apos;:0x77, &apos;F9&apos;:0x78, &apos;F10&apos;:0x79, &apos;F11&apos;:0x7A, &apos;F12&apos;:0x7B, &apos;F13&apos;:0x7C, &apos;F14&apos;:0x7D, &apos;F15&apos;:0x7E, &apos;F16&apos;:0x7F, &apos;F17&apos;:0x80, &apos;F18&apos;:0x81, &apos;F19&apos;:0x82, &apos;F20&apos;:0x83, &apos;F21&apos;:0x84, &apos;F22&apos;:0x85, &apos;F23&apos;:0x86, &apos;F24&apos;:0x87, &apos;num_lock&apos;:0x90, &apos;scroll_lock&apos;:0x91, &apos;left_shift&apos;:0xA0, &apos;right_shift &apos;:0xA1, &apos;left_control&apos;:0xA2, &apos;right_control&apos;:0xA3, &apos;left_menu&apos;:0xA4, &apos;right_menu&apos;:0xA5, &apos;browser_back&apos;:0xA6, &apos;browser_forward&apos;:0xA7, &apos;browser_refresh&apos;:0xA8, &apos;browser_stop&apos;:0xA9, &apos;browser_search&apos;:0xAA, &apos;browser_favorites&apos;:0xAB, &apos;browser_start_and_home&apos;:0xAC, &apos;volume_mute&apos;:0xAD, &apos;volume_Down&apos;:0xAE, &apos;volume_up&apos;:0xAF, &apos;next_track&apos;:0xB0, &apos;previous_track&apos;:0xB1, &apos;stop_media&apos;:0xB2, &apos;play/pause_media&apos;:0xB3, &apos;start_mail&apos;:0xB4, &apos;select_media&apos;:0xB5, &apos;start_application_1&apos;:0xB6, &apos;start_application_2&apos;:0xB7, &apos;attn_key&apos;:0xF6, &apos;crsel_key&apos;:0xF7, &apos;exsel_key&apos;:0xF8, &apos;play_key&apos;:0xFA, &apos;zoom_key&apos;:0xFB, &apos;clear_key&apos;:0xFE, &apos;+&apos;:0xBB, &apos;,&apos;:0xBC, &apos;-&apos;:0xBD, &apos;.&apos;:0xBE, &apos;/&apos;:0xBF, &apos;`&apos;:0xC0, &apos;;&apos;:0xBA, &apos;[&apos;:0xDB, &apos;\\&apos;:0xDC, &apos;]&apos;:0xDD, &quot;&apos;&quot;:0xDE, &apos;`&apos;:0xC0&#125;def press(*args): &apos;&apos;&apos; one press, one release. accepts as many arguments as you want. e.g. press(&apos;left_arrow&apos;, &apos;a&apos;,&apos;b&apos;). &apos;&apos;&apos; for i in args: win32api.keybd_event(VK_CODE[i], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[i],0 ,win32con.KEYEVENTF_KEYUP ,0)def pressAndHold(*args): &apos;&apos;&apos; press and hold. Do NOT release. accepts as many arguments as you want. e.g. pressAndHold(&apos;left_arrow&apos;, &apos;a&apos;,&apos;b&apos;). &apos;&apos;&apos; for i in args: win32api.keybd_event(VK_CODE[i], 0,0,0) time.sleep(.05) def pressHoldRelease(*args): &apos;&apos;&apos; press and hold passed in strings. Once held, release accepts as many arguments as you want. e.g. pressAndHold(&apos;left_arrow&apos;, &apos;a&apos;,&apos;b&apos;). this is useful for issuing shortcut command or shift commands. e.g. pressHoldRelease(&apos;ctrl&apos;, &apos;alt&apos;, &apos;del&apos;), pressHoldRelease(&apos;shift&apos;,&apos;a&apos;) &apos;&apos;&apos; for i in args: win32api.keybd_event(VK_CODE[i], 0,0,0) time.sleep(.05) for i in args: win32api.keybd_event(VK_CODE[i],0 ,win32con.KEYEVENTF_KEYUP ,0) time.sleep(.1) def release(*args): &apos;&apos;&apos; release depressed keys accepts as many arguments as you want. e.g. release(&apos;left_arrow&apos;, &apos;a&apos;,&apos;b&apos;). &apos;&apos;&apos; for i in args: win32api.keybd_event(VK_CODE[i],0 ,win32con.KEYEVENTF_KEYUP ,0)def typer(string=None,*args):## time.sleep(4) for i in string: if i == &apos; &apos;: win32api.keybd_event(VK_CODE[&apos;spacebar&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;spacebar&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;!&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;1&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;1&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;@&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;2&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;2&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;&#123;&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;[&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;[&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;?&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;/&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;/&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;:&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;;&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;;&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;&quot;&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;\&apos;&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;\&apos;&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;&#125;&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;]&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;]&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;#&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;3&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;3&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;$&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;4&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;4&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;%&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;5&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;5&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;^&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;6&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;6&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;&amp;&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;7&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;7&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;*&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;8&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;8&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;(&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;9&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;9&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;)&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;0&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;0&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;_&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;-&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;-&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;=&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;+&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;+&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;~&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;`&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;`&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;&lt;&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;,&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;,&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;&gt;&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;.&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;.&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;A&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;a&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;a&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;B&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;b&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;b&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;C&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;c&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;c&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;D&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;d&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;d&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;E&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;e&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;e&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;F&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;f&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;f&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;G&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;g&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;g&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;H&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;h&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;h&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;I&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;i&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;i&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;J&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;j&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;j&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;K&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;k&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;k&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;L&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;l&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;l&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;M&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;m&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;m&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;N&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;n&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;n&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;O&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;o&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;o&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;P&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;p&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;p&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;Q&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;q&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;q&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;R&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;r&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;r&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;S&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;s&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;s&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;T&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;t&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;t&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;U&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;u&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;u&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;V&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;v&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;v&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;W&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;w&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;w&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;X&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;x&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;x&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;Y&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;y&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;y&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) elif i == &apos;Z&apos;: win32api.keybd_event(VK_CODE[&apos;left_shift&apos;], 0,0,0) win32api.keybd_event(VK_CODE[&apos;z&apos;], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[&apos;left_shift&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) win32api.keybd_event(VK_CODE[&apos;z&apos;],0 ,win32con.KEYEVENTF_KEYUP ,0) else: win32api.keybd_event(VK_CODE[i], 0,0,0) time.sleep(.05) win32api.keybd_event(VK_CODE[i],0 ,win32con.KEYEVENTF_KEYUP ,0) 参考地址]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>python</tag>
        <tag>win32api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3.6安装pywin32]]></title>
    <url>%2F2017%2F12%2F28%2Fpython3-6%E5%AE%89%E8%A3%85pywin32%2F</url>
    <content type="text"><![CDATA[python3.6装载win32api模块 使用pip安装win32报错 1Could not find a version that satisfies the requirement win32api (from versions: )No matching distribution found for win32api stack overflow上面有两种回答 pip install pypiwin32 从windowsapi官网下载安装程序，点击安装 首先尝试了第一种方式，没啥用，还是找不到win32api尝试第二种方法，直接报错：1Python version 3.6-32 required, which was not found in the registry. 找半天问题，首先本地python是64位版本，下载的也是64位安装包，报这莫名其妙的注册表错误。后来在注册表里加了个python3.6-32就能安装了，莫名其妙。。1HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\3.6-32 导入了个奇奇怪怪的win32api，貌似用不了12345#!/usr/bin/env python3# -*- coding: utf-8 -*-import win32.win32apiimport win32.win32clipboardimport win32com 根据以往踩坑经验，改注册表好像都没什么好下场，于是乎，把装好的win32全部删除，注册表还原，重新下载更新版本的pywin32：下载链接 重新安装之后，重启pycharm，这次好像是成功了。。123456import win32apiimport win32condef keyDown(keyName): win32api.keybd_event() win32con.KEYEVENTF_KEYUP 反正过程是挺无语的，莫名其妙的就好了。 附上环境信息：123WIN-10 64位python-3.6 64位pywin32-221.win-amd64-py3.6]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pywin32</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3_map()函数]]></title>
    <url>%2F2017%2F12%2F27%2Fpython3-map-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[坑爹python3改动之map()函数 做自动化测试，获取并校验下拉列表中所有值，由于实在不想先写个空列表，再来个for循环全部加到列表中，就想到了map()函数，折腾半天，各种报错，墙里墙外翻半天，终于找到跟我一样入坑的人。 map()函数，python3改动 在python2中，以下代码可输出一个列表[1, 2, 3, 4, 5]12a = map(lambda x:x, [1, 2, 3, 4, 5])print(a) 但是python3，这玩意只能输出个map对象：&lt;map object at 0x00000278CB45D4E0&gt; 遇到这玩意也很多次了，直接加list：12a = list(map(lambda x: x, [1, 2, 3, 4, 5]))print(a) 这样，在python3就可以输出[1, 2, 3, 4, 5] 附自动化测试比较下拉列表值是否符合预期示例代码（百度新闻高级设置-显示条数为例）：12345678910111213141516171819202122232425262728293031323334353637#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverfrom selenium.webdriver.support.ui import Selectimport unittestimport timeclass News_Baidu(unittest.TestCase): def setUp(self): #打开浏览器 self.brower = webdriver.Chrome() def test_Checklist(self): #打开百度新闻页面 self.brower.get(&quot;http://news.baidu.com/&quot;) #定位“高级设置”，并点击 self.brower.find_element_by_link_text(&quot;高级搜索&quot;).click() #定位“搜索结果显示条数” select_element = Select(self.brower.find_element_by_name(&apos;rn&apos;)) #获取下拉列表所有元素对象 select_options = select_element.options #声明一个期望下拉列表值的列表(百度也是够坑的，值前面还有一个空格) expect_optionlist = [&apos; 每页显示10条&apos;, &apos; 每页显示20条&apos;, &apos; 每页显示50条&apos;] #获取实际的下拉列表值的列表 actual_optionlist = list(map(lambda option:option.text, select_options)) #断言结果是否适合期望 self.assertListEqual(actual_optionlist, expect_optionlist) def tearDown(self): #休眠 time.sleep(5) #退出浏览器 self.brower.quit()if __name__ == &apos;__main__&apos;: unittest.main()]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[html报告乱码]]></title>
    <url>%2F2017%2F12%2F26%2Fhtml%E6%8A%A5%E5%91%8A%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[使用HTMLTestRunner进行测试报告输出时，错误说明，中午乱码，版本：12python3.6HTMLTestRunner 1.1.1 网上搜了一堆，全是用python2.x的，心痛，2.X到2020年不就不支持了嘛，为啥一个个的都在2.X上面，没办法，自己去捣鼓源码。 报告输出的html文件，使用类似于notepad的编辑器打开，编码格式改为UTF-8，重新在浏览器中打开，错误描述的中文显示就是正常文字。所以，只要在输出时，设置编码为“utf-8”应该就可以。 找到本地的HTMLTestRunner安装路径，一般都是在G:\skills\python36\Lib\site-packages\HtmlTestRunner类似这样的路径下，毕竟扩展包。下面有三个文件，和一个文件夹，文件夹里是报告的模板，不考虑，三个文件，一个是HtmlTestRunner的介绍，一个是runner.py，一个是result.py，输出报告，应该就在result.py文件中。 编辑器打开result.py，找到第350行1with open(path_file, &apos;w&apos;) as report_file: 只要修改成1with open(path_file, &apos;w&apos;,encoding=&apos;utf-8&apos;) as report_file: 即可。 附上百度搜索自动化测试代码 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python3# -*- coding: utf-8 -*-import unittestimport timefrom selenium import webdriverfrom HtmlTestRunner import HTMLTestRunnerclass GloryRoad(unittest.TestCase): def setUp(self): #启动chrome浏览器 self.brower = webdriver.Chrome() def test_baidu(self): #访问百度首页 self.brower.get(&quot;https://www.baidu.com&quot;) #清空输入框内容 self.brower.find_element_by_id(&apos;kw&apos;).clear() #搜索框输入“selenium3” self.brower.find_element_by_id(&apos;kw&apos;).send_keys(&apos;selenium3&apos;) #点击“百度一下”按键 self.brower.find_element_by_id(&apos;su&apos;).click() #休眠3s time.sleep(3) assert &quot;google&quot; in self.brower.page_source, &quot;页面中不存在要寻找的关键字！&quot; def tearDown(self): #退出浏览器 self.brower.quit()if __name__ == &apos;__main__&apos;: suite = unittest.TestLoader().loadTestsFromTestCase(GloryRoad) runner = HTMLTestRunner(output=&apos;G:/workstation/report&apos;, report_title=&apos;Test Result&apos;) runner.run(suite)]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pycharm单元测试]]></title>
    <url>%2F2017%2F12%2F25%2Fpycharm%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[使用pycharm编写/执行单元测试用例 python单元测试用例，调用方式使用1unittest.main() 该方式，在python shell中可执行成功，在pycharm中会一直报错，参考网上的写法，最后校验调用改为：12if _name_ == &apos;_main_&apos;: unittest.main() 结果一直报错，NameError: name &#39;_name_&#39; is not defined 简直了，找了半天，还是在墙外找到跟我有一样经历的哥们的求救，报错原因是_name_和_main都是双下划线，正确写法是： 12if __name__ == &apos;__main__&apos;: unittest.main() 真是日常坑自己…]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>pycharm</tag>
        <tag>unittest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[selenium3+python3.6搭建测试]]></title>
    <url>%2F2017%2F12%2F25%2Fselenium3-python3-6%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[python3.6selenium3chrome64firefox57 selenium3开始，需要浏览器驱动，加载驱动方式：121，驱动放在任意位置，代码中，引驱动，打开浏览器（webdriver.Chrome(executable_path=&quot;驱动路径&quot;）2，将驱动放到浏览器安装目录下，和浏览器启动程序同级，将浏览器安装路径加到环境变量Path中，重启pycharm 自动化测试示例： 12345678910111213141516171819202122232425262728#!/usr/bin/env python3# -*- coding: utf-8 -*-from selenium import webdriverimport time#加载驱动程序#firefox(驱动放到浏览器安装目录，目录加到Path)#driver = webdriver.Firefox()#chrome(驱动放到浏览器安装目录，目录加到Path)driver = webdriver.Chrome()#chrome默认安装路径，驱动指定路径#driver = webdriver.Chrome(executable_path=&quot;G:/Selenium/drivers/chromedriver.exe&quot;)#打开百度首页driver.get(&quot;https://www.baidu.com&quot;)#清空搜索输入框默认内容driver.find_element_by_id(&quot;kw&quot;).clear()#输入框中输入“自动化测试”driver.find_element_by_id(&quot;kw&quot;).send_keys(&quot;自动化测试&quot;)#单击搜索按钮driver.find_element_by_id(&quot;su&quot;).click()#等待3秒time.sleep(3)#退出浏览器driver.quit()]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[world_map]]></title>
    <url>%2F2017%2F12%2F21%2Fworld-map%2F</url>
    <content type="text"><![CDATA[pygal-2.4pygal-maps-world-1.0.2 世界地图模块位置变更 pygal内置世界地图模块，包括国别码模块COUNTRIES以及世界地图模块World。 当前版本下，绘制世界地图，需要从pygal_maps_world.i18n中引国别码，需要从pygal_maps_world.maps中引世界地图。 参考代码如下： countries.py12345678910#!/usr/bin/env python3# -*- coding: utf-8 -*-from pygal_maps_world.i18n import COUNTRIESdef get_country_code(country_name): &quot;&quot;&quot;根据指定国家，返回国别码&quot;&quot;&quot; for code, name in COUNTRIES.items(): if name == country_name or name == country_name.title(): return code return None population_data.py123456789101112131415161718192021222324252627282930313233343536373839404142#!/usr/bin/env python3# -*- coding: utf-8 -*-from settings import Settingsfrom countries import get_country_codefrom pygal.style import RotateStyle as RS,LightColorizedStyle as LCSimport pygal_maps_world.mapsimport jsondata_setting = Settings()filename = data_setting.json_populationwith open(filename) as f_obj: pop_data = json.load(f_obj)#打印每个国家2010年的人口cc_population = &#123;&#125;for pop_dict in pop_data: if pop_dict[&apos;Year&apos;] == &apos;2010&apos;: country_name = pop_dict[&apos;Country Name&apos;] population = int(float(pop_dict[&apos;Value&apos;])) code = get_country_code(country_name) if code: cc_population[code] = population#按人口给国家分组cc_pops_1, cc_pops_2, cc_pops_3 = &#123;&#125;, &#123;&#125;, &#123;&#125;for cc, pop in cc_population.items(): if pop &lt; 10000000: cc_pops_1[cc] = pop elif pop &lt; 1000000000: cc_pops_2[cc] = pop else: cc_pops_3[cc] = popwm_style = RS(&apos;#336699&apos;,base_style=LCS)wm = pygal_maps_world.maps.World(style=wm_style)wm.title = &quot;World Population in 2010.by Country&quot;wm.add(&apos;0-10m&apos;, cc_pops_1)wm.add(&apos;10m-1bn&apos;, cc_pops_2)wm.add(&apos;&gt;1bn&apos;, cc_pops_3)wm.render_to_file(&apos;world_population.svg&apos;)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pygal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[绘制随机漫步图]]></title>
    <url>%2F2017%2F12%2F20%2F%E7%BB%98%E5%88%B6%E9%9A%8F%E6%9C%BA%E6%BC%AB%E6%AD%A5%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[matplotlib可绘制随机漫步图，取随机X个数，在画布上绘制，并加入渐变颜色，效果还是挺好看的 代码如下： random_walk.py1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env python3# -*- coding: utf-8 -*-from random import choiceclass RandomWalk(): &quot;&quot;&quot;一个生成随机漫步数据的类&quot;&quot;&quot; def __init__(self,num_point=5000): &quot;&quot;&quot;初始化随机漫步的属性&quot;&quot;&quot; self.num_point = num_point #所有随机漫步的点都始于（0,0） self.x_values = [0] self.y_values = [0] def get_step(self): &quot;&quot;&quot;设置前进方向及距离&quot;&quot;&quot; direction = choice([1, -1]) distance = choice([0, 1, 2, 3, 4]) step = distance * direction return step def fill_walk(self): &quot;&quot;&quot;计算随机漫步的所有点&quot;&quot;&quot; while len(self.x_values) &lt; self.num_point: x_step = self.get_step() y_step = self.get_step() #排除原地踏步情况 if x_step == 0 and y_step == 0: continue #计算下一个点的位置 next_x = self.x_values[-1] + x_step next_y = self.y_values[-1] + y_step self.x_values.append(next_x) self.y_values.append(next_y) rw_visual.py123456789101112131415161718192021222324252627#!/usr/bin/env python3# -*- coding: utf-8 -*-import matplotlib.pyplot as pltfrom random_walk import RandomWalkwhile True: #创建一个随机漫步实例，并将所有包含的点绘制出 rw = RandomWalk(30000) rw.fill_walk() point_num = list(range(rw.num_point)) plt.scatter(rw.x_values, rw.y_values, c=point_num, cmap=plt.cm.Blues, s=5) #突出起点和终点 plt.scatter(0, 0, c=&apos;green&apos;, s=100) plt.scatter(rw.x_values[-1], rw.y_values[-1], c=&apos;red&apos;, s=100) #隐藏坐标轴 plt.axes().get_xaxis().set_visible(False) plt.axes().get_yaxis().set_visible(False) #plt.subplot().set_xticks([]) #plt.subplot().set_yticks([]) plt.show() keep_drawing = input(&quot;Make another walk?y/n&quot;) if keep_drawing == &apos;n&apos;: break 可成功绘制随机漫步图，然而有个警告报错：1MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.warnings.warn(message, mplDeprecation, stacklevel=1) 原因是matplotlib版本问题，出在隐藏坐标轴plt.axes().get_yaxis()处，尝试修改为：12plt.subplot().set_xticks([])plt.subplot().set_yticks([]) 然而没啥用，还是在警告，暂时没解决。。好在不影响功能，不是强迫症也就无视这红字了。。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matplotlib绘制渐变图]]></title>
    <url>%2F2017%2F12%2F20%2Fmatplotlib%E7%BB%98%E5%88%B6%E6%B8%90%E5%8F%98%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[使用matplotlib绘制1-1000所有整数立方值图形报错 绘制1~1000所有整数的立方图，颜色采用渐变蓝色，点越接近坐标原点，颜色越浅。代码：123456789101112131415161718import matplotlib.pyplot as pltx_values = list(range(1,1001))y_values = [x**3 for x in x_values]plt.scatter(x_values, y_values, c=y_values,cmap=plt.cm.Blues,s=40)#设置图表坐标并设置坐标标签plt.title(&quot;Square Numbers&quot;,fontsize=24)plt.xlabel(&quot;Values&quot;,fontsize=14)plt.ylabel(&quot;Square of Value&quot;,fontsize=14)#设置坐标轴刻度plt.tick_params(axis=&apos;both&apos;, labelsize=14)#设置坐标轴取值plt.axes([0,1100,0,1100000])plt.show() 可以成功绘制图形，但是有警告报错：1UserWarning: Unable to find pixel distance along axis for interval padding of ticks; assuming no interval padding needed.warnings.warn(&quot;Unable to find pixel distance along axis &quot; 原因：设置坐标轴取值时，使用的是plt.axes，该函数创建的是一个轴对象，并将输入解释为指定位置的矩形，绘制的坐标轴中取值0在绘制的图形之外，超出了限制范围，所以警告报错。 解决方案：使用plt.axis()代替plt.axes()123#设置坐标轴取值plt.axis([0,1100,0,1100000])plt.show()]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django2.0更新内容记录]]></title>
    <url>%2F2017%2F12%2F19%2FDjango2-0%E6%9B%B4%E6%96%B0%E5%86%85%E5%AE%B9%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[Django 2.0 变更内容(不按版本敲着实是有点坑o(╥﹏╥)o) 外键Django 1.9在创建models.ForeignKey外键时，可写成1topic = models.ForeignKey(Topic） Django 2.0需要多传一个字段on_delete，且可给定默认值models.CASCADE所以上述可写为：1topic = models.ForeignKey(Topic,on_delete=models.CASCADE) 指定app_nameDjango 1.9在映射URL时，工程的urls.py可写成：1234567from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path(&apos;admin/&apos;, admin.site.urls), path(&apos;&apos;,include(&apos;learning_logs.urls&apos;, namespace=&apos;learning_logs&apos;))] 应用的urls.py可写成：12345678&quot;&quot;&quot;定义learning_logs的URL模式&quot;&quot;&quot;from django.urls import pathfrom . import viewsurlpatterns = [ #主页 path(&apos;&apos;, views.index, name=&apos;index&apos;)] 该写法在Django 2.0中会出现报错：12&apos;Specifying a namespace in include() without providing an app_name &apos;django.core.exceptions.ImproperlyConfigured: Specifying a namespace in include() without providing an app_name is not supported. Set the app_name attribute in the included module, or pass a 2-tuple containing the list of patterns and app_name instead. 意思是缺少了app_name，所以需要指定app_name，我的做法是在应用的urls.py文件中指定app_name，也就是工程的urls.py保持不变，应用的urls.py增加app_name指定：123456789&quot;&quot;&quot;定义learning_logs的URL模式&quot;&quot;&quot;from django.urls import pathfrom . import viewsapp_name = &apos;learning_logs&apos;urlpatterns = [ #主页 path(&apos;&apos;, views.index, name=&apos;index&apos;)] 映射URL对于django.urls.path()函数，允许有简单的表示方法： 1url(r’^articles/(?P[0-9]&#123;4&#125;)/$’, views.year_archive), 可以写成： 1path(‘articles//‘, views.year_archive), 用法参见前博客记录]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能测试-理发师模型]]></title>
    <url>%2F2017%2F12%2F15%2F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95-%E7%90%86%E5%8F%91%E5%B8%88%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[性能测试有个有名的模型，理发店模型，理发店标配：一间或大或小的店面，一个或几个理发师，几张理发的椅子和顾客休息的椅子。本文介绍一下理发店模型（相关资料网上一堆，只是为了自己记录） 场景假设 1234该理发店：1. 理发店共有3名理发师；2. 每位理发师剪一个发的时间都是1小时；3. 我们顾客们都是很有时间观念的人而且非常挑剔，他们对于每次光顾理发店时所能容忍的等待时间+剪发时间是3小时，而且等待时间越长，顾客的满意度越低。如果3个小时还不能剪完头发，我们的顾客会立马生气的走人。 场景模拟1231. 当理发店内只有1位顾客时，只需要有1名理发师为他提供服务，其他两名理发师可能继续等着，也可能会帮忙打打杂。1小时后，这位顾客剪完头发出门走了。那么在这1个小时里，整个理发店只服务了1位顾客，这位顾客花费在这次剪发的时间是1小时；2. 当理发店内同时有两位顾客时，就会同时有两名理发师在为顾客服务，另外1位发呆或者打杂帮忙。仍然是1小时后，两位顾客剪完头发出门。在这1小时里，理发店服务了两位顾客，这两位顾客花费在剪发的时间均为1小时；3. 很容易理解，当理发店内同时有三位顾客时，理发店可以在1小时内同时服务三位顾客，每位顾客花费在这次剪发的时间仍然是均为1小时； 从上面几个场景中我们可以发现，在理发店同时服务的顾客数量从1位增加到3位的过程中，随着顾客数量的增多，理发店的整体工作效率在提高，但是每位顾客在理发店内所呆的时间并未延长。 当然，我们可以假设当只有1位顾客和2位顾客时，空闲的理发师可以帮忙打杂，使得其他理发师的工作效率提高，并使每位顾客的剪发时间小于1小时。不过即使根据这个假设，虽然随着顾客数量的增多，每位顾客的服务时间有所延长，但是这个时间始终还被控制在顾客可接受的范围之内，并且顾客是不需要等待的。 不过随着理发店的生意越来越好，顾客也越来越多，新的场景出现了。假设有一次顾客A、B、C刚进理发店准备剪发，外面一推门又进来了顾客D、E、F。因为A、B、C三位顾客先到，所以D、E、F三位只好坐在长板凳上等着。1小时后，A、B、C三位剪完头发走了，他们每个人这次剪发所花费的时间均为1小时。可是D、E、F三位就没有这么好运，因为他们要先等A、B、C三位剪完才能剪，所以他们每个人这次剪发所花费的时间均为2小时——包括等待1小时和剪发1小时。 通过上面这个场景我们可以发现，对于理发店来说，都是每小时服务三位顾客——第1个小时是A、B、C，第二个小时是D、E、F；但是对于顾客D、E、F来说，“响应时间”延长了。如果你可以理解上面的这些场景，就可以继续往下看了。 在新的场景中，我们假设这次理发店里一次来了9位顾客，根据我们上面的场景，相信你不难推断，这9位顾客中有3位的“响应时间”为1小时，有3位的“响应时间”为2小时（等待1小时+剪发1小时），还有3位的“响应时间”为3小时（等待2小时+剪发1小时）——已经到达用户所能忍受的极限。假如在把这个场景中的顾客数量改为10，那么我们已经可以断定，一定会有1位顾客因为“响应时间”过长而无法忍受，最终离开理发店走了。 抽象 这张图中展示的是1个标准的软件性能模型。在图中有三条曲线，分别表示资源的利用情况（Utilization，包括硬件资源和软件资源）、吞吐量（Throughput，这里是指每秒事务数）以及响应时间（Response Time）。图中坐标轴的横轴从左到右表现了并发用户数（Number of Concurrent Users）的不断增长。 在这张图中我们可以看到，最开始，随着并发用户数的增长，资源占用率和吞吐量会相应的增长，但是响应时间的变化不大；不过当并发用户数增长到一定程度后，资源占用达到饱和，吞吐量增长明显放缓甚至停止增长，而响应时间却进一步延长。如果并发用户数继续增长，你会发现软硬件资源占用继续维持在饱和状态，但是吞吐量开始下降，响应时间明显的超出了用户可接受的范围，并且最终导致用户放弃了这次请求甚至离开。 根据这种性能表现，图中划分了三个区域，分别是Light Load（较轻的压力）、Heavy Load（较重的压力）和Buckle Zone（用户无法忍受并放弃请求）。在Light Load和Heavy Load 两个区域交界处的并发用户数，我们称为“最佳并发用户数（The Optimum Number of Concurrent Users）”，而Heavy Load和Buckle Zone两个区域交界处的并发用户数则称为“最大并发用户数（The Maximum Number of Concurrent Users）”。 当系统的负载等于最佳并发用户数时，系统的整体效率最高，没有资源被浪费，用户也不需要等待；当系统负载处于最佳并发用户数和最大并发用户数之间时，系统可以继续工作，但是用户的等待时间延长，满意度开始降低，并且如果负载一直持续，将最终会导致有些用户无法忍受而放弃；而当系统负载大于最大并发用户数时，将注定会导致某些用户无法忍受超长的响应时间而放弃。 对应到我们上面理发店的例子，每小时3个顾客就是这个理发店的最佳并发用户数，而每小时9个顾客则是它的最大并发用户数。当每小时都有3个顾客到来时，理发店的整体工作效率最高；而当每小时都有9个顾客到来时，前几个小时来的顾客还可以忍受，但是随着等待的顾客人数越来越多，等待时间越来越长，最终还是会有顾客无法忍受而离开。同时，随着理发店里顾客人数的增多和理发师工作时间的延长，理发师会逐渐产生疲劳，还要多花一些时间来清理环境和维持秩序，这些因素将最终导致理发师的工作效率随着顾客人数的增多和工作的延长而逐渐的下降，到最后可能要1.5小时甚至2个小时才能剪完1个发了。当然，如果一开始就有10个顾客到来，则注定有1位顾客剪不到头发了。 大神原网址]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter系统监控配置]]></title>
    <url>%2F2017%2F12%2F15%2FJmeter%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Jmeter是测试人员经常会使用的一款压力测试工具，经常会使用来测试接口的性能；Jmeter同时具备监控服务器资源使用情况的功能。 主要介绍一下怎么使用Jmeter来监控服务器的CPU,内存,IO等信息。 下载使用Jmeter监控系统性能，实际上是插件的使用，可以认为是在Jmeter中装载了一个小型监控系统的客户端，同时在需要监控的系统内装载服务端，在允许Jmeter时，同时打开监控服务端，进行系统资源的监控。 12客户端：JMeterPlugins-Standard服务端：ServerAgent 下载地址： 官网下载 百度云链接： JMeterPlugins-Standard-1.4.0ServerAgent-2.2.1 配置说明将 JMeterPlugins-Standard-1.4.0.zip 中 lib\ext 目录下的 JmeterPlugins-Standard.jar 文件都放到apache-jmeter-2.13\lib\ext目录中。将 ServerAgent-2.2.1.zip 解压后放到要监控的服务器中待使用。 监控设置 启动Jmeter后，右击线程组，选择添加- 监听器- jp@gc-PerfMon Metrics Collector 打开jp@gc - PerfMon Metrics Collector，点击Add Row选择相应监控对象（服务器IP和监控内容），端口默认4444即可。 开启监控 设置永远循环，否则监控会运行一次就断开，设置方式：线程组-循环次数（选择永远） 服务端运行ServerAgent，Linux系统运行shell脚本，windows系统执行bat脚本（系统需事先完成jdk配置） 成功完成系统资源监控]]></content>
      <categories>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客中加入图片]]></title>
    <url>%2F2017%2F12%2F14%2FHexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8A%A0%E5%85%A5%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[好不容易搭好了hexo，插个图片各种错 本地引用绝对路径markdown语法实现 12source/images/image.jpg ![](/images/image.jpg) 这样，图片既可以在首页内容访问，也可以在文章正文中使用 相对路径首先在/blog/_config.yml 中设置 post_asset_folder: true ，这样在 hexo new “文章” 时会生成与文章标题一样的目录，将文章中需要使用的图片存在该目录下（source//_posts/文章） 12_posts/post_name/image.jpg ![](image.jpg) CDN引用现在大多数做法是使用图床，自己也看过七牛云之类的做为图床，但是，七牛云个流氓，还要手持身份证认证，所以暂时放弃。（该方法就是在图床中生成链接，直接引链接即可） Markdown 语法介绍]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python编码]]></title>
    <url>%2F2017%2F12%2F13%2Fpython%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[python日常踩坑系列（二） 日常编写python脚本，鉴于java各种坑编码经历，首先就会把pycharm编码设置成utf-8，但是不知道什么鬼，设置完成之后，编译还是会报编码gbk的错误 问题如下： “UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0x80 in position 34: illegal multibyte sequence” 解决方案： 1，设置所有文件编码默认为utf-8（文件最前面指定） 2，处理数据时进行转码： with open(“population.json”,encoding=’UTF-8’) as data: –完 (#^.^#)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django获取不到特定链接]]></title>
    <url>%2F2017%2F12%2F13%2FDjango%E8%8E%B7%E5%8F%96%E4%B8%8D%E5%88%B0%E7%89%B9%E5%AE%9A%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[python日常踩坑系列 按照教程方式打开本地特定链接报错源码如下： 12345678910111213from django.conf.urls import urlfrom . import viewsurlpatterns = [ # Home page. url(r'^$', views.index, name='index'), # Show all topics. url(r'^topics/$', views.topics, name='topics'), # Detail page for a single topic. url(r'^topics/(?P&lt;topic_id&gt;\d+)/$', views.topic, name='topic'),] 打开http://127.0.0.1:8000/topics/1/报错： 123456 Using the URLconf defined in learning_log.urls, Django tried these URL patterns, in this order: 1. admin/ 2. [name='index'] 3. topics [name='topics'] 4. topics/?P&lt;topic_id&gt;\d+/ [name='topic']The current path, topics/1/, didn't match any of these. 原因：Django2.0有更新对于django.urls.path()函数，允许有简单的表示方法： url(r’^articles/(?P[0-9]{4})/$’, views.year_archive), 可以写成： path(‘articles//‘, views.year_archive), 所以代码可更改为：12345678910111213from django.urls import pathfrom . import viewsapp_name = 'lerning_logs'urlpatterns = [ #主页 path('', views.index, name='index'), #显示所有主题 path('topics', views.topics, name='topics'), #特定主题的详细页面 #path('topics/?P&lt;topic_id&gt;\d+/', views.topic, name='topic'), path('topics/&lt;topic_id&gt;/', views.topic, name='topic'),]]]></content>
      <tags>
        <tag>python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
</search>
